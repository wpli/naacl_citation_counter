tions, others have developed weakly supervised approaches exploiting ambiguous representations of the context in which an utterance is produced instead of accurate and complete annotations (Chen et al., 2010; B¨ orschinger et al., 2011; Chen and Mooney, 2008). In this line, in this paper we explore how an approach that induces semantic parsers in the form of a (semantic) grammar from ambiguous training data can be applied to acquire a language model (LM) for speech recognition as well as a semantic parser for the understanding task at the same time. Making use of a semantic parser as a language model for speech recognition also comes with the advantage that no separate language model must be trained. In our experiments, we compare performance of the induced grammars to the performance of different language models, in particular n-gram models, and we investigate the impact of enhancing induced semantic grammars with weights based on the training data. We present empirical results showing that it is possible to induce semantic grammars with weak supervision that can be applied successfully both as an LM for a speech recognizer and for semantic parsing. We show that with respect to parsing performance, our joint approach in which the same grammar is used for parsing and as an LM yields a higher F1 (84.46%) compared to an approach in which a standard n-gram based model is used as an LM (78.36%). In addition, our results indicate that enhancing speech recognition grammar rules with weights based on occurrence frequencies can yield improved performance over unweighted grammars (84.46% vs 82.37% for weighted vs unweighted grammars, respectively).

2

Background & related work

In principle, two different types of language models can be applied with an ASR: stochastic LMs ­ typically n-gram models ­ and speech recognition grammars. While n-gram models estimate probabilities of word sequences, speech recognition grammars explicitly specify rules defining which words and patterns a user may utter. Further, semantic information can be directly included within the rules. Thus, when applied with an ASR, spoken utterances can be directly transformed into a corresponding semantic representation without producing

a sequence of words as intermediate step. This approach is typically taken when building commercial systems (Wang et al., 2011). Such grammars are, however, typically created manually, which is timeconsuming and error-prone. Hence, data-driven approaches to automatic grammar induction have been explored (Wang and Acero, 2006b; Wang and Acero, 2005; Wang and Acero, 2003). However, they often rely on fully supervised settings, requiring training data which is annotated at the utteranceor word level, which is costly and time-consuming to produce. In contrast, aiming to reduce the required manual effort, in this paper we explore the utility of weak supervision in the form of ambiguous context information for the induction of grammars applicable for both speech recognition and understanding. The utility of this kind of weak supervision has been explored previously in the field of semantic parsing (Chen et al., 2010; B¨ orschinger et al., 2011; Chen and Mooney, 2008), and unsupervised approaches to semantic parsing have been proposed as well (Poon and Domingos, 2009; Goldwasser et al., 2011). While such approaches may be applied as parsing components for SLU systems ­ notice though that the SLU task differs from parsing of written text in that recognition errors and phenomena of spoken language must be handled, and that not all SLU models can be applied as an LM (Wang et al., 2011) ­ we are not aware of work aiming to transform these parsers into speech recognition grammars or investigating their performance with respect to different LMs applied with an ASR. Semantic parsers applied in pipeline-based SLU systems are in general usually learned in a supervised fashion. Other than semantic grammar-based approaches, probabilistic models and machine learning techniques have been applied in SLU for conceptual tagging due to their robustness to noise, e.g. Conditional Random Fields (Lafferty et al., 2001) have been applied (e.g. Wang and Acero (2006a; Dinarelli et al. (2012)); He and Young (2005) present an approach based on Hidden Markos Models. However, evaluations have shown that even in case of applying machine learning techniques or probabilistic models, semantic parsing of ASR transcriptions is affected by much more errors compared to parsing of correct transcriptions (De Mori, 2011). In order to reduce annotation costs, work has,

873

