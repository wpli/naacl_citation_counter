Following this idea, the authors in (Mohammad et al., 2013) use features derived from the lexicons to build a state-of-the-art sentiment classifier for Twitter. They construct automatic lexicons using noisy labels automatically inferred from emoticons and hashtags present in the tweets. The wordsentiment association scores are estimated using pointwise mutual information (PMI) computed between a word and a tweet label. While the idea to model statistical correlations between the words and tweet labels using PMI or any other metric is rather intuitive, we believe there is a more effective way to exploit noisy labels for estimating the word-sentiment association scores. Our method relies on the idea of distant supervision (Marchetti-Bowick and Chambers, 2012). We use a large distantly supervised Twitter corpus, which contains noisy opinion labels (positive or negative) to learn a supervised polarity classifier. We encode tweets using words and multi-word expressions as features (which are also entries in our lexicon). The weights from the learned model are then used to define which lexicon items to keep, i.e., items that constitute a good sentiment lexicon. The scores for the lexicon items can be then directly used to encode new tweets or used to derive more advanced features. Using machine learning to induce the scores for the lexicon items has an advantage of learning the scores that are directly optimized for the classification task, where lexicon items with higher discriminative power tend to receive higher weights. To assess the effectiveness of our approach, we reimplemented the state-of-the-art system ranking 1st in Semeval-2013 Twitter Sentiment Analysis challenge and used it as our baseline. We show that adding features from our machine-learned sentiment lexicon yields better results than any of the automatic PMI lexicons used in the baseline and all of them combined together. Our system obtains new state-of-the-art results on the SemEval-2013 message level task with an F-score of 71.32 ­ a 2% of absolute improvement over the previous best system in SemEval-2013. We also evaluate the utility of the ML lexicon on the five test sets from a recent Semeval-2014 task showing significant improvement over a strong baseline. Finally, our system shows high accuracy among the 42 systems participating in the Semeval-2014 challenge ranking 1398

2nd best according to the average rank across all test sets.

2

Our model

We treat the task of sentiment analysis as a supervised learning problem, where we are given labeled data {(xi , yi )}n i=1 and the goal is to estimate a decision function f (x)  y that maps input examples to labels. In particular, we use a linear SVM model with the prediction function of the following form: f = sign(wT x + b), where the model weights w are estimated from the training set. In the following we describe our approach to construct sentiment lexicons by learning an SVM model on the the distant supervised dataset. Finally, we describe our baseline model. 2.1 Distant Supervision for Automatic Lexicon Construction

Our sentiment lexicon consists of words and word sequences (we only use word unigrams and bigrams). To select lexicon items from a set of all unigrams and bigrams, we propose the following process: 1. Collect a large unlabelled corpus of tweets C . 2. For each tweet ti  C use cues (hashtags or emoticons) to automatically infer its label (positive or negative): yi  {-1, +1}. For example, positive or negative emoticons, such as ':-)' or ':(' are good indicators of the general sentiment expressed by a tweet. 3. Extract unigram and bigram features to encode a tweet ti into a feature vector xi  R|L| , where the lexicon L is a set of unigrams and bigrams. 5. Train an SVM model w = i=1..N i yi xi on the encoded corpus C = {(xi , yi )}N i=1 . The model w  R|L| is a dense vector whose components are obtained from a weighted combination of training examples xi (support vectors) and their labels yi (only those instances with i > 0 contribute to the components of w). 6. Given that the each component wj of the model w directly corresponds to the lexicon entry lj  L its raw score is used as a sentiment association score. Different from manually constructed lexicons compiled by humans where each item is assigned

