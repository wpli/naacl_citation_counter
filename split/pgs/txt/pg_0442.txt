The generator, which starts from elementary predicate-argument lexico-structural structures as used in sentence planning by Stent et al. (2004), consists of a cascade of Support Vector Machines (SVM)-classifier based submodules that map the input structures onto sentences in a series of transitions. Following the idea presented in (Ballesteros et al., 2014b), a separate SVM-classifier is defined for the mapping of each linguistic category. The generator has been tested on Spanish with the multi-layered Ancora-UPF corpus (Mille et al., 2013) and on English with an extended version of the dependency Penn TreeBank (Johansson and Nugues, 2007). The remainder of the paper is structured as follows. In the next section, we briefly outline the fundamentals of sentence generation as we view it in our work, focusing in particular on the most challenging part of it: the transition between the non-isomorphic predicateargument lexico-structural structures and surfacesyntactic structures. Section 3 outlines the setup of our system. Section 4 discusses the experiments we carried out and the results we obtained. In Section 5, we briefly summarize related work, before in Section 6 some conclusions are drawn and future work is outlined.

the presentation of the DSyntSs and SSyntSs and the mapping between them. 2.1 2.1.1 DSyntSs and SSyntSs Input DSyntSs

2

The Fundamentals

Sentence generation realized in this paper is part of the sentence synthesis pipeline argued for by Mel' cuk (1988). It consists of a sequence of two mappings: 1. Predicate-argument lexico-structural structure  Syntactic structure 2. Syntactic Structure  Linearized structure Following the terminology in (Mel' cuk, 1988), we refer to the predicate-argument lexico-structural structures as "deep-syntactic structures" (DSyntSs) and to the syntactic structures as "surface-syntactic structures" (SSyntSs). While SSyntSs and linearized structures are isomorphic, the difference in the linguistic abstraction of the DSyntSs and SSyntSs leads to divergences that impede the isomorphy between the two and make the first mapping a challenge for statistical generation. Therefore, we focus in this section on 388

DSyntSs are very similar to the PropBank (Babko-Malaya, 2005) structures and the structures as used for the deep track of the First Surface Realization Shared Task (SRST, (Belz et al., 2011)) annotations. DSyntSs are connected trees that contain only meaning-bearing lexical items and both predicate-argument (indicated by Roman numbers: I, II, III, IV, . . . ) and lexico-structural, or deepsyntactic, (ATTR(ibutive), APPEND(itive) and COORD(inative)) relations. In other words, they do not contain any punctuation and functional nodes, i.e., governed elements, auxiliaries and determiners. Governed elements such governed prepositions and subordinating conjunctions are dropped because they are imposed by sub-categorization restrictions of the predicative head and void of own meaning-- as, for instance, to in give TO your friend or that in I know that you will come.3 Auxiliaries do not appear as nodes in DSyntSs. Rather, the information they encode is captured in terms of tense, aspect and voice attributes of the corresponding full verbal nodes. Equally, determiners are substituted by attribute­value pairs of givenness they encode, assigned to their governors. See Figure 1 (a) for a sample DSyntS.4 2.1.2 SSyntSs

SSyntSs are connected dependency trees in which the nodes are labeled by open or closed class lexical items and the edges by grammatical function relations of the type `subject', `oblique object', `adverbial', `modifier', etc. A SSyntS is thus a typical dependency tree as used in data-driven syntactic parsing (Haji c et al., 2009) and generation (Belz et al., 2011). See Figure 1 (b) for illustration of a SSyntS.
3 In contrast, on in the bottle is on the table is not dropped because it is semantic. 4 "That" is considered a kind of determiner (to be derived from the Information Structure). This is the reason to omit it in the deep structure.

