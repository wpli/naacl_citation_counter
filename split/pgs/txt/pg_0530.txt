billion word web corpus, as their learning corpus. We converted every word that occurs less than 100 times in the corpus to a special rare-word token, and all numbers to a special number token, obtaining a vocabulary of a little under 200K word types. 5.2.1 Substitute vector similarity We learned a 5-gram Kneser-Ney language model from our learning corpus using KenLM (Heafield et al., 2013). Following Yatbaz et al. (2012), we used FASTSUBS (Yuret, 2012) with this language model to efficiently generate substitute vectors pruned to their top-n substitutes, v1 ..vn , and normalized such that i=1..n p(vi |c) = 1. In order to make our substitute vectors compatible with the pseudo-word setting, for each substitute vector we replaced the entries of all of the pseudosense words with a single pseudo-word entry, and assigned it with the sum of the conditional probabilities of the pseudo-sense words. Next, we computed the Positive PMI weights for the substitutes, (vi |c) sc [vi ] = P P M I (vi , c) = max(0, log( pp (vi ) )), where p(vi ) is the unigram probability of the word vi in our learning corpus. The unigram probability of a pseudo-word is the sum of the probabilities of its pseudo-sense words. Finally, we computed context similarity as substitute vector Cosine. SUBweight,n denotes our similarity measure, where n is the pruning factor and weight  {cond, ppmi} denotes conditional probabilities and PPMI fitness weights, respectively. We note that by using a 5-gram language model we consider a context word window of 4 words on each side of the target word. 5.2.2 Bag-of-words similarity Bag-of-words similarity between two context word windows is computed as vector Cosine between their bag-of-words vector representations. We use BOW weight,l to denote these context similarity measures, where l is the size of the context word window on each side of the target word (we use sent to denote the entire sentence), and weight  {tf, tfidf } stands for term frequency and tf-idf weights, respectively. CBOW weight,l is used to denote the same for the continuous bag-of-words method, which is based on averaging the dense vector word representations. We used word2vec 476

Method SUB · CBOW SUBppmi,1000 SUBppmi,100 CBOW tf idf,8w SUBcond,1000 SUBcond,100 BOW tf idf,sent Random

P@1 80.6 73.1 74.5 68.4 63.6 63.1 62.8 30.4

P@1% 67.1 60.0 61.0 58.0 53.0 52.7 51.3 30.4

AvgPrec 44.5 44.0 42.8 43.5 38.6 38.5 34.6 30.4

Table 4: Precision values for compared context similarity measures. Only the best performing configurations for BOW and CBOW are shown.

(Mikolov et al., 2013) to learn these dense vectors.4 5.3 Results

The results presented in Table 4 support our hypothesis that our proposed substitute vector similarity measure is particularly suitable for measuring context similarity, at least in our setting. Our similarity measures outperform both CBOW and BOW baselines on P@1 and P@1%, with statistical significance at p < 0.01 for SUBppmi,100 , and p < 0.05 for SUBppmi,1000 , on a paired t-test. On average precision they perform similarly to CBOW. Within the substitute vector measures, our proposed PPMI weights significantly outperform the previously used conditional probabilities, and the choice of pruning factor has a small impact. Within the bag-of-words measures, the CBOW measure significantly outperforms the BOW measure, with an optimal window size of 8 (on each side). This suggests that CBOW's ability to capture context word similarities via its dense word representations is beneficial. Finally, SUB·CBOW denotes a combined similarity measure, which is the geometrical mean between the scores of the best configurations of the respective methods. We see that this combination yields substantial improvement, outperforming all other baselines across all precision categories, with p < 0.0001 for P@1 and P@1%. We hypothesize that this is due to the synergy between the word order sensitivity of SUB and the word similarities and larger window size captured by CBOW.
4 We experimented with various parameters of word2vec, observing small differences in performance. We report here the results with the best configuration (cbow 1, negative sampling 15, window size 8).

