nary is essentially a list of words in the two languages that are equivalent with respect to some task, e.g., English car and French maison (`house') are both nouns, and hence "equivalent" in POS tagging; English clerk and chauffeur are both persons, and hence "equivalent" in SuS tagging; house and maison are equivalent in machine translation. BARISTA has the advantage that it (a) is independent of the choice of embedding algorithm, (b) does not require parallel data, and (c) can be adapted to specific tasks by using appropriate dictionaries. We use the bilingual embeddings directly to train a target language POS tagger on source language training data. Instead of lexical features, we use the bilingual embeddings. We show our bilingual embedding method outperforms using off-the-shelf bilingual embeddings on this task, and that our system is competitive to state-of-the-art approaches for cross-language POS tagging. Finally, we show that the same embeddings also lead to significantly better performance in semi-supervised cross-language SuS tagging. The code will be made publicly available at https: //github.com/gouwsmeister/barista.

2

Our approach

Standard monolingual neural language models are unsupervised models that train on raw text, learning word features that enable the model to predict the next word (the target) from a sequence of words (the context). In the process, the model learns to cluster words into soft equivalence classes (words that have similar distributions). Several authors have proposed bilingual clustering and embedding algorithms based on parallel data (T¨ ackstr¨ om et al., 2012; Klementiev et al., 2012; Zou et al., 2013; Kocisky et al., 2014; Hermann and Blunsom, 2014b). These authors have all evaluated their embeddings on document classification and machine translation, and not yet structured prediction tasks like POS/SuS tagging or syntactic parsing. A notable exception is Hermann and Blunsom (2014a), who do not rely on parallel data and do not use word alignments, but they still use comparable data and sentence alignments, and they only evaluate their embeddings in document classification. The assumption that large amounts of parallel data exists for a language pair of interest is sometimes too strong (Hermann and Blunsom, 2014a). 1387

On the other hand, we often have access to small samples of near-equivalences from knowledge bases of various forms. For example, for POS tagging, we often have access to small-to-sizeable crowdsourced tag dictionaries (e.g. Wiktionary). For SuS tagging, which is the other example considered in this paper, we sometimes have access to WordNets or similar resources. If we have such resources for both source and target language, we can extract word-equivalences from them and use these to learn bilingual embeddings using our proposed method. In this paper, we experiment with using both equivalences based on word alignments (e.g., house  maison), and equivalences based on knowledge bases (e.g., car  maison). Crucially, our approach to learning bilingual embeddings only assumes a small seed of equivalences, no parallel data. It then uses these to produce a set of mixed contexttarget pairs. Our input is a source corpus Cs and a target corpus Ct , as well as a set of bilingual equivalences R . We begin by shuffling the concatenation of Cs and Ct . We then pass over this mixed corpus, and for each word w, if {w | w, w  R } is non-empty and of cardinality k , i.e., w is in the seed list of equivalences, we replace w with w with probability 1/2k . In other words, we flip a coin whether to replace w, and then randomly choose one of its equivalences as our replacement. For example, using translation equivalence classes, one could generate any of the following mixed texts from the English sentence build the house: construire the house, build la maison, build the maison, etc., or any other combination of English and French words with the English word order. With POS equivalence classes, any of the words in build the house can be replaced with words with overlapping syntactic categories, e.g., build the voiture.

3

Experiments

In our experiments we balance the source and target corpora, by subsampling from the bigger corpus. The vocabularies for all models are kept unrestricted, and result in around 1M words per language pair. We train with a window of 4 words on either side of the target word, using linear discounting of the initial learning rate of 0.1. These parameters were set on the Spanish POS data (see §3.2). We

