assume that the demographics of Twitter users from a county match those of all people from a county. While it may be possible to directly adjust for these mismatches using techniques from survey reweighting (Gelman, 2007), it is difficult to precisely quantify the proper weights in this context. Instead, we propose a search-based approach inspired by feature selection algorithms commonly used in machine learning (Guyon and Elisseeff, 2003). The idea is to select the subset of constraints that result in the most accurate model. We first assume the presence of a small set of labeled data L = {(x1 , y1 ) . . . (xn , yn )}. Given a set of constraints C = {(U1 , p ~1 ) . . . (Uk , p ~k )}, the search objective is to select a subset of constraints C   C to minimize error on L: C   argmin E (pC (y |x), L)
C C

We run each selection algorithm for 140 iterations (as we discuss below, accuracy plateaus well before then). Then, we select the constraint set that results in the highest accuracy. While this search procedure is computationally expensive, it is fortunately easily parallelizable (by partitioning by constraint), which we take advantage of in our implementation. All constraint selection algorithms use the 40% of the labeled data reserved for training/tuning. After we finalized all models using the tuning data, we then used them to classify the 60% of labeled data reserved for testing.

5

Baselines

We compare label regularization with standard logistic regression (logistic) trained using the 40% of labeled data reserved for training/tuning. We also consider several heuristic baselines:  Name heuristic, race classification: We implement the method proposed by (Mohammady and Culotta, 2014), using the top 1000 most popular last names with their race distribution from the U.S. Census Bureau to infer race/ethnicity of users based of most probable race according last name. If the last name is not among the top 1000 most popular for a given race, we simply predict White (the most frequent class).  Name heuristic, age classification: We use the heuristic described in Section 3.3 that estimates a person's age by their first name. Given the age distribution of a first name, we classify the user according to the more probable class.  Follower heuristic, political classification: We reuse the exemplar accounts used in the follower constraint in Section 3.3. That is, rather than using the fact that a user follows "dennis kucinich" as a soft constraint, we classify such a user as a Democrat. If a user follows more than one of the exemplar accounts, we select the more frequent party.6 In case of ties (or if the user does not follow any of the accounts), we classify at random.
For the politician-follower data the heuristic does not use "thedemocrats" and "gop," because these were used for the original annotation.
6

where E () is a classification error function, and pC (y |x) is the model fit by label regularization using constraint set C . In our experiments, |C | is in the hundreds, so exhaustive, exponential search is impractical. Instead, we consider the following greedy and pseudogreedy forward-selection algorithms:  Greedy (grdy): Standard greedy search. At each iteration, we select the constraint that leads to the greatest accuracy improvement on L.  Semi-greedy (semi): Rather than selecting the constraint that improves accuracy the most, we randomly select from the top three constraints (Hart and Shogan, 1987).  Improved-greedy (imp): The same as grdy, but after each iteration, optionally remove a single constraint. We consider each currently selected constraint, and compute the accuracy attained by removing this constraint from the set. We remove the constraint that improves accuracy the most (if any exists). This constraint is removed from consideration in future iterations.  Grasp (grsp): Greedy Randomized Adaptive Search Procedures (Feo and Resende, 1995) combines semi and imp. 190

