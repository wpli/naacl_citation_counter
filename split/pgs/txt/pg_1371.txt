Improving Update Summarization via Supervised ILP and Sentence Reranking
1

Chen Li1 , Yang Liu1 , Lin Zhao2 Computer Science Department, The University of Texas at Dallas Richardson, Texas 75080, USA 2 Research and Technology Center, Robert Bosch LLC Palo Alto, California 94304, USA {chenli,yangl@hlt.utdallas.edu} {lin.zhao@us.bosch.com} Abstract
2008; Fisher and Roark, 2008; Long et al., 2010; Bysani, 2010). One important line is to use graphbased co-ranking. They rank the sentences in the earlier and later document sets simultaneously by considering the sentence relationship. For example, Li et al. (2008) was inspired by the intuition that "a sentence receives a positive influence from the sentences that correlate to it in the same collection, whereas receives a negative influence from the sentences that correlates to it in the different (or previously read) collection', and proposed a graph based sentence ranking algorithm for update summarization. Wan (2012) integrated two co-ranking processes by adding some strict constraints, which led to more accurate computation of sentences' scores for update summarization. A similar method was also applied earlier by (Wan et al., 2011) for multilingual news summarization. In addition, generative models, such as topic models, have also been adopted for this task. For example, Delort and Alfonseca (2012) proposed a novel nonparametric Bayesian approach, a variant of Latent Dirichlet Allocation (LDA), aiming to distinguish between common information and novel information. Li et al. (2012) borrowed the idea of evolutionary clustering and proposed a three-level HDP (Hierarchical Dirichlet Process) model to represent the diversity and commonality between aspects discovered from two different document data sets. One of the most competitive summarization methods is based on Integer Linear Programming (ILP). It has been widely adopted in the generic summarization task (Martins and Smith, 2009; BergKirkpatrick et al., 2011; Woodsend and Lapata, 2012; Li et al., 2013a; Li et al., 2013b; Li et al., 2014). In this paper, we use the ILP summarization

Integer Linear Programming (ILP) based summarization methods have been widely adopted recently because of their state-of-the-art performance. This paper proposes two new modifications in this framework for update summarization. Our key idea is to use discriminative models with a set of features to measure both the salience and the novelty of words and sentences. First, these features are used in a supervised model to predict the weights of the concepts used in the ILP model. Second, we generate preliminary sentence candidates in the ILP model and then rerank them using sentence level features. We evaluate our method on different TAC update summarization data sets, and the results show that our system performs competitively compared to the best TAC systems based on the ROUGE evaluation metric.

1

Introduction

Update summarization has attracted significant research focus recently. Different from generic extractive summarization, update summarization assumes that users already have some information about a given topic from an old data set, and thus for a new data set the system aims to generate a summary that contains as much novel information as possible. This task was first introduced at DUC 2007 and then continued until TAC 2011. It is very useful to chronological events in real applications. Most basic update summarization methods are variants of multi-document summarization methods, with some consideration of the difference between the earlier and later document sets (Boudin et al.,

1317
Human Language Technologies: The 2015 Annual Conference of the North American Chapter of the ACL, pages 1317­1322, Denver, Colorado, May 31 ­ June 5, 2015. c 2015 Association for Computational Linguistics

