· Input: A random, system-generated 60-bit password. · Output: An English word sequence with two properties: ­ It is memorable. ­ We can deterministically recover the original input 60-bit string from it. This implies that we map 260 distinct bit strings into 260 distinct English sequences. If a user memorizes the English word sequence supplied to them, then they have effectively memorized the 60-bit string.

Bit Sequence 0000 0001 0010 0011 0100 0101 0110 0111

Mapped Character e t a o i n s,z h,q

Bit Sequence 1000 1001 1010 1011 1100 1101 1110 1111

Mapped Character r,x d,j l,k c,v u,b m,p w,y f,g

Table 2: Mapping function between 4-bit sequences and English letters in the First Letter Mnemonic method.

2

Password Generation Methods

We now describe our baseline password generation method, followed by four novel methods. In Section 3 we experimentally test their memorability. 2.1 XKCD Baseline

or two, per Table 2. We build a word-confusion network (or "sausage lattice") by replacing each 4-bit code with all English words that start with a corresponding letter, e.g.:
0100 ---income is inner ... 1101 ---my miner priest ... 1111 ---frog feast gratuitous ... ... 0011 ---... octopus ... of ... oregon ...

Our baseline is a version of XKCD. Instead of a 2048-word dictionary, we use a 32,7868-word dictionary. We assign each word a distinct 15-bit code. At runtime, we take a system-assigned 60-bit code and split it into four 15-bit sequences. We then substitute each 15-bit segment with its corresponding word. By doing this, we convert a random 60-bit code into a 4-word password. The first row of Table 1 shows three sample XKCD passwords, along with other information, such as the average number of characters (including spaces). 2.2 First Letter Mnemonic

XKCD passwords are short but nonsensical, so we now look into methods that instead create longer but fluent English sentences. We might think to guarantee fluency by selecting sentences from an alreadyexisting text corpus, but no corpus is large enough to contain 260 ( 1018 ) distinct sentences. Therefore, we must be able to synthesize new English strings. In our first sentence generation method (First Letter Mnemonic), we store our input 60-bit code in the first letters of each word. We divide the 60-bit code into 4-bit sections, e.g., `0100-1101-1101-...'. Every 4-bit sequence type corresponds to an English letter 1571

This yields about 1074 paths, some good (is my frog. . . ) and some bad (income miner feast. . . ). To select the most fluent path, we train a 5-gram language model with the SRILM toolkit (Stolcke, 2002) on the English Gigaword corpus.3 SRILM also includes functionality for extracting the best path from a confusion network. Table 1 shows sample sentences generated by the method. Perhaps surprisingly, even though the sentences are much longer than XKCD (15 words versus 4 words), the n-gram language model (LM) score is a bit better. The sentences are locally fluent, but not perfectly grammatical. We can easily reconstruct the original 60-bit code by extracting the first letter of each word and applying the Table 2 mapping in reverse. 2.3 All Letter Method

Most of the characters in the previous methods seem "wasted", as only the word-initial letters bear information relevant to reconstructing the original 603

https://catalog.ldc.upenn.edu/LDC2011T07

