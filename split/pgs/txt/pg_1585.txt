p2 p1 p3 p4

p4 p1 p3 p2 p5

p1 p2 p3 p4 p5

1 1 1 0 0

0 1 1 1 0

0 0 1 1 1

bin 1 bin 2 bin 3

bin 1 p1

bin 2 p4 p3

bin 3 p5

p2

(a)

(b)

(c)

Figure 3: (a) A quantized random projection in LSH. The arrows show the direction of the projection. Points p1 , p2 , p3 are correctly projected to the same bin, while p4 falls into another bin, despite being very close to p1 . (b) A simplified example illustrating RBV in two dimensions. The circle with radius r is centered at p1 and contains all neighbors of p1 . RBV approximates the circle by a square of width d = 2 × 0.95r, which contains most of the neighbors of p1 but also p4 , a false positive, while missing p5 , a closer point. (c) On each dimension, RBV uses bit vectors to maintain the set of points whose hypercubes (represented as the segments on the points in 1-dimensional view) intersect with a bin.

an s-dimensional space. Phrases whose projections collide in the s-dimensional space are considered candidates to be neighbors. A fast retrieval of those colliding phrases can be done via a hash table. However, since the projection is random, it is very likely that true neighbors in the d-dimensional space fall into different bins after projection (false negatives; e.g., p1 and p4 in Figure 3 (a)). To ease this problem, LSH employs a set of such projections and runs a linear search over the union of all possible neighbor candidates resulting from these projections to find the approximated k -nearest neighbors. 4.2 Redundant Bit Vectors

The performance of LSH decreases as the number of dimensions grows. Redundant bit vectors (RBV; Goldstein et al., 2005) address this problem and can quickly search in high dimensional space, which suits our task better. RBV is a combination of: a) an approximated neighborhood test designed for high dimensional space, and b) an efficient data structure for fast neighborhood query. First, for a given point p in high dimensional space, the volume of a hypersphere of radius r centered at p can be approximately covered by a hypercube of width d = 2 r, 1.3 Figure 3 (b) shows
Here we use in an imprecise way. 1 does not mean is smaller than 1 by orders of magnitudes; usually > 0.1.
3

an illustration in two dimensional space where a square of width d = 2 × 0.95r covers most of a circle with radius r. In higher dimensional space, e.g., d = 256 as in Goldstein et al. (2005), we can cover 99% of the volume of a hypersphere of r = 1 with a hypercube whose width is only  2 × 0.2r.4 This surprising result allows us to use a very small hypercube to approximate the hypersphere. Furthermore, if two points q and p are within a certain radius r, i.e., q - p  r, then frequently |q(i) - p(i) |  r, where x(i) denotes the i-th element of vector x. Thus, the neighbor query can be approximated as a check whether the distance between p and q on each dimension is less than r, 1. Second, each dimension is quantized into bins. Each bin redundantly maintains a set of points whose hypercubes intersect with the bin on that dimension. This set is an approximation of the neighbors of a query point p that falls into the same bin on this dimension. RBV uses bit vectors to store this set of points for each bin. (See Figure 3 (c).) For a given query vector p, we fetch the bins where p falls into for each dimension. We then perWhat we mean is that in high dimensional space, the volume of a hypercube of width 2 r is more than hundreds of magnitudes smaller than a hypercube of width 2r. 4 Note that this does not mean the volume of the hypercube is smaller than the hypersphere. It just means that most of the volume of the hypersphere is covered in the hypercube.

1531

