References
H. Bourlard and N. Morgan. 1993. Connectionist Speech Recognition: A Hybrid Approach. Kluwer Academic Publishers, Norwell, MA. G. E. Dahl, D. Yu, and L. Deng. 2011. Large vocabulary continuous speech recognition with context-dependent DBN-HMMs. In Proc. ICASSP. G. E. Dahl, T. N. Sainath, and G. E. Hinton. 2013. Improving Deep Neural Networks for LVCSR using Rectified Linear Units and Dropout. In ICASSP. R. De Mori, F. Bechet, D. Hakkani-Tur, M. McTear, G. Riccardi, and G. Tur. 2008. Spoken language understanding. Signal Processing Magazine, IEEE, 25(3):50­58. X. Glorot, A. Bordes, and Y Bengio. 2011. Deep Sparse Rectifier Networks. In AISTATS, pages 315­323. S. Goldwater, D. Jurafsky, and C. Manning. 2010. Which Words are Hard to Recognize? Prosodic, Lexical, and Disfluency Factors That Increase Speech Recognition Error Rates. Speech Communications, 52:181­200. A. Graves and N. Jaitly. 2014. Towards End-to-End Speech Recognition with Recurrent Neural Networks. In ICML. A. Graves, S. Fern´ andez, F. Gomez, and J. Schmidhuber. 2006. Connectionist temporal classification: Labelling unsegmented sequence data with recurrent neural networks. In ICML, pages 369­376. ACM. K. Heafield, I. Pouzyrevsky, J. H. Clark, and P. Koehn. 2013. Scalable modified Kneser-Ney language model estimation. In ACL-HLT, pages 690­696, Sofia, Bulgaria. G. E. Hinton, L. Deng, D. Yu, G. E. Dahl, A. Mohamed, N. Jaitly, A. Senior, V. Vanhoucke, P. Nguyen, T. Sainath, and B. Kingsbury. 2012. Deep neural networks for acoustic modeling in speech recognition. IEEE Signal Processing Magazine, 29(November):82­97. X. Huang, A. Acero, H.-W. Hon, et al. 2001. Spoken language processing, volume 18. Prentice Hall Englewood Cliffs. A. Maas, A. Hannun, and A. Ng. 2013. Rectifier Nonlinearities Improve Neural Network Acoustic Models. In ICML Workshop on Deep Learning for Audio, Speech, and Language Processing. T. Mikolov, M. Karafi´ at, L. Burget, J. Cernock` y, and S. Khudanpur. 2010. Recurrent neural network based language model. In INTERSPEECH, pages 1045­ 1048. D. Povey, A. Ghoshal, G. Boulianne, L. Burget, O. Glembek, K. Vesel´ y, N. Goel, M. Hannemann, P. Motlicek, Y. Qian, P. Schwarz, J. Silovsky, and G. Stemmer. 2011. The kaldi speech recognition toolkit. In ASRU.

T. N. Sainath, I. Chung, B. Ramabhadran, M. Picheny, J. Gunnels, B. Kingsbury, G. Saon, V. Austel, and U. Chaudhari. 2014. Parallel deep neural network training for lvcsr tasks using blue gene/q. In INTERSPEECH. G. Saon and J. Chien. 2012. Large-vocabulary continuous speech recognition systems: A look at some recent advances. IEEE Signal Processing Magazine, 29(6):18­33. I. Sutskever, J. Martens, and G. E. Hinton. 2011. Generating text with recurrent neural networks. In ICML, pages 1017­1024. I. Sutskever, J. Martens, G. Dahl, and G. Hinton. 2013. On the Importance of Momentum and Initialization in Deep Learning. In ICML. K. Vesely, A. Ghoshal, L. Burget, and D. Povey. 2013. Sequence-discriminative training of deep neural networks. In Interspeech. M. D. Zeiler, M. Ranzato, R. Monga, M. Mao, K. Yang, Q.V. Le, P. Nguyen, A. Senior, V. Vanhoucke, J. Dean, and G. E. Hinton. 2013. On Rectified Linear Units for Speech Processing. In ICASSP.

354

