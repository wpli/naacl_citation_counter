artifacts, not within a system ontology. This paper focuses on the complex problem-solving domain of introductory computer programming. In this domain the user might say, for example, "Is myVariable supposed to be an int?" where myVariable refers to the name of a variable within the computer program that the user has created. The semantic interpretation task in this case is akin to situated dialogue where user utterances must be grounded within a physical environment (Liu et al., 2014, Gorniak et al., 2007). However, even these situated dialogue models typically rely on a world defined by a limited number of entities (e.g., a chair or a cup). To address these challenges, this paper presents a step toward semantic grounding for complex problem-solving dialogues, in which the number of potential entities (e.g., a Java variable or a piece of code) is infinite. The present work focuses on the semantic understanding of noun phrases, which tend to bear significant semantic information for each utterance. Although noun phrases are typically small in their number of tokens, their complexity and semantics vary in important ways. For example, in the domain of computer programming, two similar noun phrases such as "the 2 dimensional array" and "the 3 dimensional array" refer to two different entities within the problem-solving artifact. Inferring the semantic structure of the noun phrases is necessary to differentiate these two references within a dialogue, to ground them in the task, and to respond to them appropriately. This noun phrase grounding task is similar to coreference resolution, which discovers the relationship between pairs of noun phrases in a piece of natural language text (Culotta, Wick, & Mccallum, 2007; Lappin & Leass, 1994). However, different from coreference resolution, noun phrase grounding links natural language expressions to entities in a real world environment. The current approach leverages the structure of noun phrases, mapping their segments to attributes of entities to which they should be semantically linked. In order to overcome the limitation of needing to fully enumerate the entities in the environment, we represent the entities as automatically extracted vectors of attributes. We then perform joint segmentation and labeling of the noun phrases in user utterances to map them to the entity vectors (used to describe entities within the environment). This mapping of noun phrases to real-

world attributes is the grounding task focused on in this work. The results show that a Conditional Random Field performs well for this task, achieving 89.3% accuracy. Moreover, even in the absence of lexical features (using only dependency parse features and parts of speech), the model achieves 71.3% accuracy, indicating that it may be tolerant to unseen words. The flexibility of this approach is due in part to the fact that it does not rely on a syntactic parser's ability to accurately segment within noun phrases, but rather includes parse features as just one type of feature among several made available to the model. Finally, in contrast to methods based on bag-of-words such as latent semantic analysis, the proposed approach models the structure of noun phrases to facilitate specific grounding within an artifact. The remainder of this paper is structured as follows. Section 2 presents related work on semantic interpretation and on natural language interpretation for tutorial dialogue. Section 3 describes the corpus and highlights some of the characteristics of dialogue for complex problem solving. The semantic interpretation approach is introduced in Section 4, with the experiments and results presented in Section 5. Section 6 concludes with important directions for future work.

2 Related Work
The approach presented in this paper draws upon a rich foundation of research in semantic interpretation and specifically upon dialogue interpretation for tutorial dialogues. Each of these areas of related work is discussed in turn. 2.1 Semantic Interpretation

The current work is closely related to several wellestablished research directions within the computational linguistics literature: semantic role labeling, semantic parsing, and language grounding. Semantic tagging assigns a semantic role label to text segments in a sentence (Pradhan, et. al, 2004). The set of semantic roles are relatively coarse-grained, not mapping to specific entities within the world. In contrast, the approach used in this paper does perform semantic role labeling, but the semantic grounding of these text segments are extracted at the same time. Semantic parsing addresses a more complex problem than semantic role labeling: in-

842

