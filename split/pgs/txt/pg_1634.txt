We removed stopwords as well as words with a part of speech other than noun, verb, and adjective. Furthermore, we discarded words with an age of acquisition above 10 years (Kuperman et al., 2012) to restrict the vocabulary to frequent and generally familiar words. Models and Parameters We compared the performance of BCF against BayesCat, a Bayesian model of category acquisition (Frermann and Lapata, 2014) and Strudel, a pattern-based model which extracts concept features from text (Baroni et al., 2010). BayesCat induces categories, which are represented through a distribution over target concepts, and a distribution over features (i.e., individual context words). In contrast to BCF, it does not learn types of features. In addition, while BCF induces a hard assignment of concepts to categories, BayesCat learns soft distributions over target concepts for each category. Soft assignments can be converted into hard assignments by assigning each concept to its most probable category. We ran BayesCat on the same input stimuli as BCF, with the following parameters: the number of categories was set to K = 40, and the hyperparameters to  = 0.7,  = 0.1,  = 0.1. For the BCF model, we used the same number of categories, namely K = 40. The number of feature types was set to G = 75, and the hyperparameters to  = 0.5,  = 0.5, and  = 0.1. Parameters were tuned on the development set. For both models, we report results averaged over 10 Gibbs runs, each time we ran the sampler for 1,000 iterations. We used annealing during learning which proved effective for avoiding local optima. Strudel automatically extracts features for concepts from text collections following a pattern-based approach. It takes as input a set of target concepts and a set of patterns, and extracts a list of features for each concept, where each concept-feature pair is weighted with a log-likelihood ratio expressing the pair's strength of association. Baroni et al. (2010) show that the learnt representations can be used as a basis for various tasks such as typicality rating, categorization, or clustering of features into types. In our experiments we obtained Strudel representations from the same Wackypedia corpus used for extracting the input stimuli for BCF (and BayesCat). Note 1580

that Strudel, unlike the two Bayesian models, is not a cognitively motivated acquisition model, but an optimized system developed with the aim of obtaining the best possible features from data. 4.1 Experiment 1: Evaluation of Categories In our first experiment we evaluate the quality of the categories induced by the three models presented above. The models produce hard categorizations, however, the cognitive gold standard we use for evaluation (Fountain and Lapata, 2010) represents soft categories. We obtained a hard categorization by assigning members of multiple categories to their most typical category (typicality scores are provided with the data).1 Method BCF and BayesCat learn a set of categories which we can directly compare to the gold standard. For Strudel, we produce a categorization as follows: we represent each concept as a vector over features (obtained from Wackypedia), where each component corresponds to the concept-feature log-likelihood ratios provided by Strudel; following Baroni et al. (2010), we then cluster the vectors using K-means and the Cluto toolkit.2 As for the other models, we set the number of categories to K = 40. Metrics To assess the quality of the clusters produced by the models, we measure purity ( pur; the extent to which each learnt cluster corresponds to a single gold class) as well as its inverse, collocation (col ; the extent to which all items of a particular gold class are represented in a single learnt cluster). Both measures are based on set-overlap, and we also report their harmonic mean ( f 1; Lang and Lapata 2011). In addition, we report the V-measure (v1; Rosenberg and Hirschberg 2007) and its factors measuring the homogeneity of clusters (hom) and their completeness (com). The two factors intuitively correspond to purity and collocation, but are based on information-theoretic measures. Results Our results are summarized in Table 1. They show that BCF and Strudel perform almost identically, and both outperform BayesCat. BCF learns the categories from data, whereas for Strudel
2 http://glaros.dtc.umn.edu/gkhome/cluto/cluto/ overview 1 http://homepages.inf.ed.ac.uk/s0897549/data/.

