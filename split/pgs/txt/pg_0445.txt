if N1 is a Vfin and ((R1,2 == I and N1 is in active voice and N2 is not by) or (R1,2 == II and N1 is in passive voice)) if  one-to-one correspondence between NDi and NSi then introduce SBJ between NS1 and NS2 else if NS2 is top node of the SSyntS hypernode and ((NS1 is top node of the SSynt hypernode and is AUX) or (NS1 is the bottom node of the SSynt hypernode and is Vfin ) or (NS1 is not top node or bottom node of the SSynt-hypernode and is AUX)) then introduce SBJ between NS1 and NS2 endif endif

determiners are introduced, and so are Spanish auxiliaries, reflexive pronouns, and determiners. That is, the rules produce well-formed SSyntSs of all possible combinations of auxiliaries, conjunctions and/or prepositions for verbs, determiners and/or prepositions for nouns, adjectives and adverbs. When there are several possible mappings, the baseline takes decisions by default. For example, when a governed preposition must be introduced, we always introduce the most common one (of in English, de `of' in Spanish). 3.2 Data-Driven Generator The data-driven generator is defined as a tree transducer framework that consists of a cascade of 6 datadriven small tasks; cf. Figure 4. The first four tasks capture the actions 1.­4. from Section 2.2; the 5th linearizes the obtained SSyntS. Figure 4 provides a sample input and output of each submodule. The system outputs a 14 column CoNLL'09 linearized format without morphological inflections or punctuation marks. In the next sections, we discuss how these actions are realized and how they are embedded into the overall generation process. The intra- and inter-hypernode dependency determination works as an informed dependency parser that uses the DSyntS as input. The search space is thus completely pruned. Note also that for each step, the space of classes for the SVMs is based on linguistic facts extracted from the training corpus (for instance, for the preposition generation SVM, the classes are the possible prepositions; for the auxiliary generation SVM, the possible auxiliaries, etc.). 3.2.1 Hypernode Identification Given a node nd from the DSyntS, the system must find the shape of the surface hypernode that corresponds to nd in the SSyntS. The hypernode identification SVMs use the following features:
PoS of nd , PoS of nd 's head, verbal voice (active, passive) and aspect (perfective, progressive) of the current node, lemma of nd , and nd 's dependencies.

Figure 3: Sample graph transducer rule

(simple nouns, verbs, adverbs, adjectives, etc.), 22 rules map DSyntS-nodes that have a one-to-many correspondence in the SSyntS (N  DET+NN, N  DET+NN+governed PREP, V  AUX+VV, V  that COMPL+AUX+VV+governed PREP, etc.), and 25 rules generate the dependency relations.9 The transduction rules apply in two phases, see Figure 3. During the first phase, all nodes and intra-hypernode dependencies are created in the output structure. During the second phase, all inter-hypernode dependencies are established. Since there are one-to-many DSyntS-SSyntS correspondences, the rules of the second phase have to ensure that the correct output nodes are targeted, i.e., that jobs in Figure 1(b) is made a dependent of have, and not of been or created, which all correspond to create in the input. Consider, for illustration of the complexity of the rule-based generator, the transduction rule in Figure 3. The rule creates the SSynt dependency relation SBJ (subject) in a target SSyntS (with a governor node ND1 and a dependent node ND2 linked by a deep dependency relation R1,2 in the input DSyntS and two nodes NS1 and NS2 which correspond to ND1 and ND2 respectively in the target SSyntS). The evaluation shows that all straightforward mappings are performed correctly; English auxiliaries, that complementizers, infinitive markers and
`N' stands for "noun", `NN' for "common noun", `DET' for "determiner", `PREP' for "preposition", `V' for "verb", `AUX' for "auxiliary verb", `VV' for "main verb", and `COMPL' for "complementizer".
9

In order to simplify the task, we define the shape of a surface hypernode as a list of surface PoS tags. This unordered list contains the PoS of each of the lemmas contained within the hypernode and a tag that encodes the original deep node; for instance:

391

