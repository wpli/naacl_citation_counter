· We present a simple and elegant algorithm that runs in polynomial time and finds the global optimum of our objective function. This represents an important advantage of our proposal because many former techniques resort to heuristic-driven search algorithms that are not guaranteed to find the global optimum. · With the intention of overcoming several problems suffered by traditional metrics for automatically evaluating the quality of proposed headlines, we propose two new evaluation metrics that correlate with ratings given by human annotators.

main problem with these approaches is that they make use of techniques that were not initially devised for generating compressions of less than 10% of the original content, which directly affects the quality of the resulting summary (Banko et al., 2000). It is noteworthy to highlight that most of the modern summarization-based techniques opt for generating headlines just by recycling and reordering words present in the article, which also raises the risk of losing or changing the contextual meaning of the reused words (Berger and Mittal, 2000). An area that deals with a target similar to headline generation is multi-sentence compression, where its objective is to produce a single short phrase that abridges a set of sentences that conform a document. The main difference between both practices is that headline generation is more strict about the length of the generated output, which should consist of about eight tokens (Banko et al., 2000), whereas the latter accepts longer results. One of the most recent and competitive approaches for multi-sentence compression is described by Filippova (2010).

2

Related work

There has been a significant amount of research about headline generation. As noted by Gattani (2007), it is possible to identify three main trends of techniques broadly employed through different studies: Rule-based approaches. These methods make use of handcrafted linguistically-based rules for detecting or compressing important parts in a document. They are simple and lightweight, but fail at exploring complex relationships in the text. The most representative model for this group is the Hedge Trimmer (Dorr et al., 2003). Statistics-based approaches. These methods make use of statistical models for learning correlations between words in headlines and in the articles. The models are fit under supervised learning environments and therefore need large amounts of labelled data. One of the most influential works in this category is the Na¨ ive Bayes approach presented by Banko et al. (2000), and augmented in works such as Jin and Hauptmann (2001; Zajic et al. (2002). The use of statistical models for learning pruning-rules for parse trees has also been studied, the most notable work on this area is presented in Knight and Marcu (2001) and extended by Unno et al. (2006). Summarization-based approaches. Headlines can be regarded as very short summaries, therefore traditional summarization methods could be adapted for generating one-line compressions; the common trend consists in performing multiple or combined steps of sentence selection and compression (Hajime et al., 2013; Martins and Smith, 2009). The 134

3

Background on sequence prediction

Sequence models have been broadly used for many Natural Language Processing tasks, such as identification of sentence boundaries (Reynar and Ratnaparkhi, 1997), named entity recognition (McCallum and Li, 2003), part of speech tagging (Kupiec, 1992), dependency tree parsing (McDonald et al., 2005), document summarization (Shen et al., 2007), and single-sentence compression (McDonald, 2006; Nomoto, 2007). These models are formalizations of relationships between observed sequences of variables and predicted categories for each one. Mathematically, let X = {x1 , x2 , ..., xN } be a finite set of possible atomic observations, and let Y = {y1 , y2 , ..., yM } be a finite set of possible categories that each atomic observation could belong to. Statistical sequence models try to approximate a probability distribution P with parameters  capable of predicting for any sequence of n observations x  X n , and any sequence of assigned categories per observation y  Y n , the probability P (y |x; ). The final objective of these models is to predict the

