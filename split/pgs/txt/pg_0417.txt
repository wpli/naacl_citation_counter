Figure 6: Examples from the meme generation experiment. First row: the chemistry cat meme. Second row: the forever alone meme. Third row: the Batman slaps Robin meme. Left column: human generated topvoted meme descriptions on memegenerator.net at the time of writing. Middle column: generated output from RNNLM. Right column: generated output from NPNs.

used in many caption generation studies (Vinyals et al., 2014; Chen and Zitnick, 2014; Donahue et al., 2014; Fang et al., 2014; Karpathy and Fei-Fei, 2014). The generation result is shown in Table 4. Note that when combining B-1 to B-4 scores, BLEU includes a brevity penalty as described in the original BLEU paper. We see that our NPN model outperforms the best supervised baseline by 4.35 BLEU points, while also obtaining an advantage of 4.48
Systems RNN-C RNN-F LR LSVM GSVM NPN BLEU 19.52 23.76 23.89 21.06 20.63 28.24* B-1 62.2 72.2 72.3 65.0 66.2 66.9 B-2 21.2 31.4* 28.3 24.8 22.8 29.0 B-3 12.1 16.2 15.0 13.1 12.8 19.7* B-4 9.0 8.7 10.6 9.3 9.3 16.6*

BLEU points over the full RNNLM, which is trained on a corpus that is 90 times larger, in an unsupervised fashion. When breaking down the results, we see that our NPN's advantage is on generating longer phrases, typically trigrams and four-grams, comparing to the other models. This is very interesting, because generating high-quality long phrases is difficult, since the memes are often short. We show some generation examples in Figure 6. We see that on the left column, the reference memes are the ones with top votes by the crowd. The first chemistry cat meme includes puns, the second forever alone meme includes reference to the life simulation video game, while the last Batman meme has interesting conversations. In the second column, we see that the memes generated by the full RNNLM model are short, which corresponds to the quantitative results in Table 4. In the third column, our NPN meme generator was able to generate longer descriptions. Interestingly, it also creates a pun for the chemistry cat meme. Our generation on the forever alone meme is also accurate. In the Batman example, we show that the NPN model makes a sentence-image-mismatch type of error: although the generated sentence includes the entities Batman and Robin, as well as their slapping activity, it was originally created for the "overly attached girlfriend" meme10 .

7

Conclusions

Table 4: The BLEU scores for generating memes from images. B-1 to B-4: BLEU unigram to four-grams. The best BLEU results are highlighted in bold. * indicates p < .001 comparing to the second best system.

In this paper, we study the language of memes by jointly learning the image, the description, and the popular votes. In particular, we propose a robust nonparanormal approach to transform all vision and text features into the cumulative density function space. By learning the stochastic dependencies, we show that our model significantly outperforms various competitive baselines in the prediction experiments. In addition, we also propose a simple pipeline for generating memes from raw images, drawing the wisdom from reverse image search and traditional information retrieval perspectives. Finally, we show that our model obtains significant BLEU point improvements over an unsupervised RNNLM baseline trained on a larger corpus, as well as other strong supervised baselines.
10

http://www.overlyattachedgirlfriend.com

363

