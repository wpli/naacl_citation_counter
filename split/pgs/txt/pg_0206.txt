refinements to online instructions from user generated content. In Proc. ACL, pages 545­553. O. Etzioni, A. Fader, J. Christensen, S. Soderland, and Mausam. 2011. Open Information Extraction: the Second Generation. In Intl. Joint Conf. on AI. S. Guadarrama, N. Krishnamoorthy, G. Malkarnenkar, S. Venugopalan, R. Mooney, T. Darrell, and K. Saenko. 2013. YouTube2Text: Recognizing and describing arbitrary activities using semantic hierarchies and Zero-Shot recognition. In Intl. Conf. on Computer Vision, pages 2712­2719. Yangqing Jia, Evan Shelhamer, Jeff Donahue, Sergey Karayev, Jonathan Long, Ross Girshick, Sergio Guadarrama, and Trevor Darrell. 2014. Caffe: Convolutional architecture for fast feature embedding, 20 June. Dhiraj Joshi, James Z Wang, and Jia Li. 2006. The story picturing Engine-A system for automatic text illustration. ACM Trans. Multimedia Comp., Comm. and Appl., 2(1):1­22. Hank Liao, Erik McDermott, and Andrew Senior. 2013. Large scale deep neural network acoustic modeling with semi-supervised training data for YouTube video transcription. In ASRU (IEEE Automatic Speech Recognition and Understanding Workshop). Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean. 2013. Efficient estimation of word representations in vector space. http://arxiv.org/abs/1301.3781. I Naim, Y C Song, Q Liu, H Kautz, J Luo, and D Gildea. 2014. Unsupervised alignment of natural language instructions with video segments. In Procs. of AAAI. Slav Petrov, Leon Barrett, Romain Thibaux, and Dan Klein. 2006. Learning accurate, compact, and interpretable tree annotation. In Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics, pages 433­440, Sydney, Australia, July. Association for Computational Linguistics. M Rohrbach, S Amin, M Andriluka, and B Schiele. 2012a. A database for fine grained activity detection of cooking activities. In CVPR, pages 1194­1201. Marcus Rohrbach, Michaela Regneri, Mykhaylo Andriluka, Sikandar Amin, Manfred Pinkal, and Bernt Schiele. 2012b. Script data for Attribute-Based recognition of composite activities. In Proc. European Conf. on Computer Vision, pages 144­157. Olga Russakovsky, Jia Deng, Hao Su, Jonathan Krause, Sanjeev Satheesh, Sean Ma, Zhiheng Huang, Andrej Karpathy, Aditya Khosla, Michael Bernstein, Alexander C. Berg, and Li Fei-Fei. 2014. ImageNet Large Scale Visual Recognition Challenge. http://arxiv.org/abs/1409.0575. Ashutosh Saxena, Ashesh Jain, Ozan Sener, Aditya Jami, Dipendra K Misra, and Hema S Koppula. 2014.

RoboBrain: Large-Scale knowledge engine for robots. http://arxiv.org/pdf/1412.0691.pdf. Karen Simonyan and Andrew Zisserman. 2014. Very deep convolutional networks for LargeScale image recognition, 4 September. http://arxiv.org/abs/1409.1556. F. M. Suchanek, G. Kasneci, and G. Weikum. 2007. YAGO: A Large Ontology from Wikipedia and WordNet. J. Web Semantics, 6:203217. J Thomason, S Venugopalan, S Guadarrama, K Saenko, and R Mooney. 2014. Integrating language and vision to generate natural language descriptions of videos in the wild. In Intl. Conf. on Comp. Linguistics. Yezhou Yang, Yi Li, Cornelia Ferm¨ uller, and Yiannis Aloimonos. 2015. Robot learning manipulation action plans by watching unconstrained videos from the world wide web. In The Twenty-Ninth AAAI Conference on Artificial Intelligence (AAAI-15). Haonan Yu and JM Siskind. 2013. Grounded language learning from video described with sentences. In Proc. ACL. Shoou-I Yu, Lu Jiang, and Alexander Hauptmann. 2014. Instructional videos for unsupervised harvesting and learning of action examples. In Intl. Conf. Multimedia, pages 825­828. ACM.

152

