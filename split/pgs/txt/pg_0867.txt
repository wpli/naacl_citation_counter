threshold, the constraints in (1) become more conservative, thus it leads to fewer but more reliable constraints added into the ILP. We tune the threshold values such that their corresponding scores attain high enough accuracy, either in the multiplicative form or the additive form.5 Note that, given a pair of mentions and context, we automatically instantiate a collection of relevant schemas, and then generate and evaluate a set of corresponding constraints. To the best of our knowledge, this is the first work to use such automatic constraint generation and tuning method for coreference resolution with ILP inference. In Section 4, we describe how we acquire the score vectors S (u, v ) for the Predicate Schemas in an unsupervised fashion. We now briefly explain the pre-processing step required in order to extract the score vector S (u, v ) from a pair of mentions. Define a triple structure tm predm (m, am ) for any m  M. The subscript m for pred and a, emphasizes that they are extracted as a function of the mention m. The extraction of triples is done by utilizing the dependency parse tree from the Easy-first dependency parser (Goldberg and Elhadad, 2010). We start with a mention m, and extract its related predicate and the other argument based on the dependency parse tree and partof-speech information. To handle multiword predicates and arguments, we use a set of hand-designed rules. We then get the score vector S (u, v ) by concatenating all scores of the Predicate Schemas given two triples tu , tv . Thus, we can expand the score representation for each type of Predicate Schemas given in Table 2: 1) For Type 1 schema, S (u, v )  S (predv (m = u, a = av )) 6 2) For Type 2 schema, S (u, v )  S (predu (m = u, a = au )|predv (m = v, a = av ), cn). In additional to schema-driven constraints, we also apply constraints between pairs of pronouns within a fixed distance7 . For two pronouns that are semantically different (e.g. he vs. it), they must refer to different antecedents. For two non-possesive pronouns that are related to the same predicate (e.g. he
5 The choice is made based on the performance on the development set. 6 In predv (m = u, a = av ) the argument and the predicate are extracted relative to v but the mention m is set to be u. 7 We set the distance to be 3 sentences.

saw him), they must refer to different antecedents.8

4

Knowledge Acquisition

One key point that remains to be explained is how to acquire the knowledge scores S (u, v ). In this section, we propose multiple ways to acquire these scores. In the current implementation, we make use of four resources. Each of them generates its own score vector. Therefore, the overall score vector is the concatenation of the score vector from each resource: S (u, v ) = [Sgiga (u, v ) Swiki (u, v ) Sweb (u, v ) Spol (u, v )]. 4.1 Gigaword Co-occurence We extract triples tm predm (m, am ) (explained in Section 3) from Gigaword data (4,111,240 documents). We start by extracting noun phrases using the Illinois-Chunker (Punyakanok and Roth, 2001). For each noun phrase, we extract its head noun and then extract the associated predicate and argument to form a triple. We gather the statistics for both schema types after applying lemmatization on the predicates and arguments. Using the extracted triples, we get a score vector from each schema type: Sgiga = (1) (2) [Sgiga Sgiga ]. To extract scores for Type 1 Predicate Schemas, we create occurence counts for each schema instance. After all scores are gathered, our goal is to (1) query Sgiga (u, v )  S (predv (m = u, a = av )) from our knowledge base. The returned score is the log (.) of the number of occurences. For Type 2 Predicate Schemas, we gather the statistics of triple co-occurence. We count the cooccurrence of neighboring triples that share at least one linked argument. We consider two triples to be neighbors if they are within a distance of three sentences. We use two heuristic rules to decide whether a pair of arguments between two neighboring triples are coreferents or not: 1) If the head noun of two arguments can match, we consider them coreferents. 2) If one argument in the first triple is a person name and there is a compatible pronoun (based on its gender and plurality information) in the second triple, they are also labeled as coreferents. We also extract the discourse connectives between triples (because,
8

Three cases are considered: he-him, she-her, they-them

813

