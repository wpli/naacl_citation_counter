Text Phone Text+Phn T+P+Latt tri4b Reference 0.82 0.82 0.85 0.85 51% tri4b 0.76 0.62 0.77 0.78 63% 22% 0.56/0.55 Table 3: Cross validation accuracy evaluated over only 0.47/0.46 those queries whose correct candidate was output by the 0.58/0.61*triager for both tri4b and reference. 0.59/0.60* Reference tri4b 0.52/0.56 0.59/0.61* on joseph Don Joseph 0.59/0.63** ira magazine Ira Magaziner bob defiance Bob Mathias Dave Deforest gave deforest Table 1: Performance of different feature sets for refergeorgia the books George W. Bush's ence transcripts and ASR output (mono, tri4b). Results George W. Bush george w. porsche are cross-fold validation/test accuracy. Significance of louis freer Louis Freeh system test accuracy compared to the Text baseline comNorman Mineta norman monetta puted with two-sample proportion test. (*p < 0.05, ** edward and Edward Egan p < 0.01). keith clarke Nikki Clark Text Phone Text+Phn Table 4: Examples of improved linking accuracy. Reference 0.92/0.87 0.95/0.91 0.98/0.97 mono 0.48/0.13 0.50/0.17 0.51/0.19 tri4b 0.68/0.47 0.71/0.52 0.73/0.56 WER Mention WER Mention Exact Text Phone Text+Phn Text+Phn+Latt Metaphone Text+Metaphn Text+Metaphn+Latt Reference 0.77/0.77 0.77/0.79 0.81/0.81 0.52/0.61 0.78/0.78 mono 71% 90% 5% 0.44/0.48 0.42/0.45 0.45/0.49 0.45/0.49 0.43/48 0.45/0.50 0.45/0.51

5

Results

Table 2: Overall/non-NIL triager recall.

news variety in HUB4. These higher error settings test the limits of entity linking in noisy ASR. To find the ASR-corrupted mention string used for the query q we align the ASR transcript by tokenlevel edit distance ­ additions and deletions cost 1, while substitutions cost the Jaccard distance between two tokens. This is done at both training and test time, and allows us to evaluate performance of entity linking features without worrying about errors introduced by a named entity recognizer on the transcripts. Entity Linking System Training The entity linking system relies on a linear Ranking SVM objective (Joachims, 2006), and the optimal slack parameter C was chosen using 5-fold cross validation over the training set (C varied from 1 and 5 ×10-5...3 ). During cross-validation, mention string types were kept disjoint between the train and development folds. Ranking was performed over the (up to) 1000 candidates produced by triage selected from the TACKBP 2009/10 KB (Mcnamee et al., 2009; Ji et al., 2010). Using the selected C we trained over the entire training set and evaluated on the test set. 228

Table 1 reports both the average accuracy for 5-fold cross validation (CV) on train and for the best tuned system from CV on test data. The reference test accuracy is relatively high, but lags behind person entity linking for written language. When accurate transcripts are available, entity linking for spoken language, while harder, achieves just a little behind written language. However, on ASR transcripts, accuracy drops considerably: 0.77 reference to 0.48 (mono, 71% WER) or 0.55 (tri4b, 51% WER). Our features improve accuracy for both ASR systems. Metaphone features do better than Phone features. Lattice do not show significant improvements, likely because they help with context but not mentions (see below.) When combined with text, both metaphone and phone features do similarly. The majority of our improvement comes from improvements to recall. Table 3 shows the accuracy of queries for which the triager found the correct candidate in both the reference transcript and tri4b, providing a consistent set for comparison. For these queries, tri4b is much closer to the results obtained on reference and much higher than the best results in Table 1. This is encouraging, especially given the 50% WER of tri4b; entity linking accuracy is not seriously impacted by noisy transcripts, provided that

