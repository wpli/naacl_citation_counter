is a better match for determining the adjective ordering than a more-limited domain corpus, despite the limitation of Google N-grams being restricted to 5-word sequences. We think this is because of two reasons: First, Google N-grams is a very large corpus compared to the one we use. Second, our corpus consists of abstracts and not full text of scientific articles from PubMed. Hence there is less variety in the language used; capturing fewer comparative constructs than Google N-grams. However, it is interesting that we can still extract patterns from domain-specific corpora to act as constraints for the MILP process.

5

Rankings for adjectives extracted from PubMed

We also desired to see how well our approach does on terms that are not specifically in WordNet, but present in a domain-specific corpus such as PubMed. We therefore also evaluate the clustering and ranking steps on a set of adjectives extracted from the PubMed data using structural patterns. 5.1 Clustering

specific adjectives, which are quite unfamiliar even to native English speakers. We manually partitioned the clusters into two sets: (i) containing domainspecific words, and (ii) containing words used in day-to-day English (henceforth referred to as "regular" terms). Examples of clusters from both sets are summarized in Table 3. The clusters we obtain look reasonable, grouping together adjectives that pertain to the same scale. The first cluster of domainspecific adjectives qualifies the nouns corresponding to different types of protein with varying degree of specificity, the second cluster contains different qualifications of a tumor, and adjectives in the third cluster qualify different parts of a living cell. For the regular adjective clusters, the clusters look intuitive too, except for the first cluster. The adjectives male and female are not scalar, but match the structural patterns, and are grouped together with adjectives describing age qualifications, due to a strong context overlap in which these words are used. Clusters of domain-specific adjectives cytokine, gm-csf, ifn-gamma, il-10, il-12, il-2 benign, malignant, metastatic, neoplastic, squamous mitochondrial, nuclear, ribosomal Clusters of regular adjectives female, male, middle-aged, older, young, younger accurate, precise, reliable, reproducible, robust additive, insignificant, negligible
Table 3: Examples of automatically derived adjective clusters from PubMed abstracts.

Since there was no gold standard reflecting ideal clustering of data, we explored heuristic measures to choose parameters for our clustering step. We used CBOW vectors over skip-gram vectors since these were more effective in the previous experiment. Since the true value for number of clusters k was unknown, we chose k such that the average cardinality of a cluster was three. The value of k was found to be the same (k = 375) for all clustering experiments conducted using vector dimension sizes varying from 200 to 800 in increments of 100. To choose the right dimension size d of the CBOW vectors for this fixed value of k , we obtained clusters for incremental values of d from 200 to 800 in increments of 100. We determined the number of identical clusters obtained using a particular value of d with its next increment. The lowest value of d which resulted in a maximum number of identical clusters with its next increment was chosen: d = 400. Using vectors of 400 dimensions, we obtained 375 adjective clusters with cardinality varying from 1 to 9. Since these clusters were derived from our biomedical dataset, they comprised of domain489

We randomly sampled 25 clusters from each set, "regular adjectives" and "domain-specific adjectives", for our evaluation. We evaluated the clustering quality of the regular adjectives using the exact same approach as described in Section 4.1. We obtained a clustering accuracy of 86.26% for 25 clusters across 101 regular adjectives. This is substantially better than the performance of clustering in the previous experiment. We believe that this is due to the fact that the adjectives in the dataset used in the previous experiment originate from WordNet and contain many words (e.g., handsome, crazy, spicy),

