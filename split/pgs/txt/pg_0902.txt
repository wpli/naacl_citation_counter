4.2. There were 364 grounded noun phrases extracted manually from the six tutorial dialogue sessions used in the current work. Each of these noun phrases extracted has one or multiple corresponding entities in the programming artifact. Since each word in a noun phrase is linked to an element in the description vector, the indices in this vector were used as the label for each word. Annotation of all 346 noun phrases was performed by one annotator, and 20% of the noun phrases (70 noun phrases) were doubly annotated by an independent second annotator. The percent agreement was 85.3% and the Kappa was 0.765. To extract features, the lemmatization and syntactic parsing were performed with the Stanford CoreNLP toolkit (Manning et al., 2014). Then, a CRF was trained to predict the label for each word in a new noun phrase. The training was performed with the crfChain toolbox (Schmidt, 2008). We use ten-fold cross-validation to evaluate the performance of the CRF in this problem. Results with different feature combinations are shown in Table 2. Manually labeled data were taken as ground truth for computing accuracy, which is defined as the percentage of segments correctly labeled. Recall that consecutive words with the same label in a noun phrase are treated as a segment. Therefore, if a segment sCRF identified by the CRF has the same boundary and the same label as a segment sHuman in the noun phrase containing sCRF, this segment sCRF will be counted as a correct segment. Otherwise, sCRF will be counted as incorrect. The accuracy is then calculated as the number of correct segments identified by the CRF divided by the number of segments annotated manually. As can be seen in Table 2, all of the models perform substantially better than a minimal majority class baseline of 43%, which would result from taking each word as a segment and assigning it with the most frequent attribute label. The results demonstrate important characteristics of the segmentation and labeling model. First, unlike most previous semantic interpretation work, our semantic interpretation of noun phrases does not rely on accurate syntactic parse within noun phrases. Rather, we use a dependency parse from an open-domain parser as only one of several types of features provided to the model. These dependency features improved the model in most feature combinations (Table 2). The feature combination

of words, lemmas, and dependency parses achieved the best accuracy, which is 4.8% higher than the model that only used word features. This difference is statistically significant (Wilcoxon rank-sum test; n=10; p=0.02). features word word + lemma Word + Dep lemma + Dep word + lemma + Dep word + lemma + POS word + lemma + POS + Dep POS + Dep
Table 2. Labeling accuracy.

accuracy 84.5% 85.5% 87.22% 89.1% 89.3% 86.9% 88.7% 71.3%

Notably, the combination of part-of-speech features and dependency parse features still performed at 71.3% accuracy, indicating that to some extent, the method may be tolerant to unseen words.

6 Conclusion and Future Work
This paper has presented a technique for semantic grounding of noun phrases in a complex problemsolving domain, tutorial dialogue for computer programming. By performing joint segmentation and labeling of noun phrases from user utterances, and mapping those segments to attributes of entities within the problem solving artifact, we have made a first step toward grounding complex problem-solving dialogue within a dynamically changing artifact from a potentially infinite set of surface forms. While trained on a small subset of the corpus, the high accuracy of this model indicates that it may be successfully applied to the larger corpus without extensive additional manual annotations. Several directions of future work are very promising. In order to fully support users in complex problem-solving dialogues, the field must move toward richer grounding of natural language utterances within complex artifacts across many domains. Additionally, generating specific and tailored dialogue feedback grounded in the artifact is a complementary area of research that holds the potential to increase the effectiveness of dialogue systems for supporting problem solving. It is hoped that this line of investigation will lead to dialogue systems that smoothly support a much broader range of human endeavors.

848

