Figure 1: Freebase description of Jean Metellus can be used to infer that the entity has the type /book/author. This missing fact is found by our algorithm and is still missing in the latest version of Freebase when the paper is written.

on their ability to predict missing facts. To overcome these drawbacks we construct the train and test data using two snapshots of the KB and evaluate the methods on predicting facts that are added to the more recent snapshot, enabling a more realistic and challenging evaluation. Standard evaluation metrics for KBC methods are generally type-based (Mintz et al., 2009; Riedel et al., 2013), measuring the quality of the predictions by aggregating scores computed within a type. This is not ideal because: (1) it treats every entity type equally not considering the distribution of types, (2) it does not measure the ability of the methods to rank predictions across types. Therefore, we additionally use a global evaluation metric, where the quality of predictions is measured within and across types, and also accounts for the high variance in type distribution. In our experiments, we show that models trained with negative examples from the entity side perform better on type-based metrics, while when trained with negative examples from the type side perform better on the global metric. In order to design methods that can rank predictions both within and across entity (or relation) types, we propose a global objective to train the models. Our proposed method combines the advantages of previous approaches by using negative examples from both the entity and the type side. When considering the same number of negative examples, we find that the linear classifiers and the low-dimensional embedding models trained with the global objective produce better quality ranking within and across entity types when compared to training with negatives examples only from entity or type side. Additionally compared to prior methods, the model trained on the proposed global objective can more reliably suggest confident entity-type pair candidates that could be added into the given knowledge base. Our contributions are summarized as follows: 516

· We develop an evaluation framework comprising of methods for dataset construction and evaluation metrics to evaluate KBC approaches for missing entity type instances. The dataset and evaluation scripts are publicly available at http://research.
microsoft.com/en-US/downloads/ df481862-65cc-4b05-886c-acc181ad07bb/ default.aspx.

· We propose a global training objective for KBC methods. The experimental results show that both linear classifiers and low-dimensional embedding models achieve best overall performance when trained with the global objective function. · We conduct extensive studies on models for inferring missing type instances studying the impact of using various features and models.

2 Inferring Entity Types
We consider a KB  containing entity type information of the form (e, t), where e  E (E is the set of all entities) is an entity in the KB with type t  T (T is the set of all types). For example, e could be Tiger Woods and t could be sports athlete. As a single entity can have multiple types, entities in Freebase often miss some of their types. The aim of this work is to infer missing entity type instances in the KB. Given an unobserved fact (an entity-type pair) in the training data (e, t)   where entity e  E and type t  T , the task is to infer whether the KB currently misses the fact, i.e., infer whether (e, t)  . We consider entities in the intersection of Freebase and Wikipedia in our experiments. 2.1 Information Resources

Now, we describe the information sources used to construct the feature representation of an entity to

