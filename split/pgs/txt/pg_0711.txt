System Bisk and Hockenmaier (2012) Blunsom and Cohn (2010) Tu and Honavar (2012) Marecek and Straka (2013)3 Naseem and Barzilay (2011) Spitkovsky et al. (2012) Spitkovsky et al. (2013) Our system (MinEnc) Our system (MaxEnc)

DDA (@10) 53.3 (71.5) 55.7 (67.7) 57.0 (71.4) 57.1 (68.8) 59.4 (70.2) 61.2 (71.4) 64.4 (72.0) 66.2 (72.7) 65.8 (73.2)

Figure 3: DDA of phase 1 (MaxEnc), with and without the word embeddings (denoted by w/ sem and wo/ sem, respectively), on training sentences up to length 15 (i.e. S (1) ).

Table 1: Performance on section 23 of the WSJ corpus (all sentences and up to length 10) for recent systems and our system. MinEnc and MaxEnc denote itersMST = 10 and itersMST = 1 respectively.

Figure 4: DDA of phase 1 (MaxEnc) before and after training with three different starting points provided by three parsers used in phase 0: MS (Marecek and Straka, 2013), GGGPT (Gillenwater et al., 2011), and Harmonic (Klein and Manning, 2004). The role of lexical semantics Figure 2: DDAMaxEnc - DDAMinEnc of all phases on the their training sets (e.g., phase 3 with S (3) containing all training sentences up to length 17). pute DDAMaxEnc - DDAMinEnc of each phase on its training set (e.g., phase 3 with S (3) containing all training sentences up to length 17). MinEnc outperforms MaxEnc within phases 1, 2, 3, and 4. However, from phase 5, the latter surpasses the former. It suggests that exploring areas far away from the current point with long sentences is risky. The reason is that long sentences contain more ambiguities than short ones; thus rich diversity, high difference from the current point, but small size (i.e., small k ) could easily lead the learning to a wrong path. The performance of the system with the two encouragement levels on section 23 (Table 1) also suggests the same. MaxEnc strategy helps the system achieve the highest accuracy on short sentences (up to length 10). However, it is less helpful than MinEnc when performing on long sentences. 657 We examine the role of the lexical semantics, which is given by the word embeddings. Figure 3 shows DDAs on training sentences up to length 15 (i.e. S (1) ) of phase 1 (MaxEnc) with and without the word-embeddings. With the wordembeddings, phase 1 achieves 71.11%. When the word-embeddings are not given, i.e. the IORNN uses randomly generated word vectors, the accuracy drops 4.2%. It shows that lexical semantics plays a decisive role in the performance of the system. However, it is worth noting that, even without that knowledge (i.e., with the -order generative model alone), the DDA of phase 1 is 2% higher than before being trained (66.89% vs 64.9%). It suggests that phase 1 is capable of discovering some useful dependency patterns that are invisible to the parser in phase 0. This, we conjecture, is thanks to high-order features captured by the IORNN. The importance of the starting point Starting point is claimed to be important in local search. We examine this by using three different parsers in phase 0: (i) MS (Marecek and Straka,

