semantic descriptors is called the primary descriptor: this is the semantic neighbor that is conceptually most central. Primary descriptors are most often hypernyms or synonyms, but they can also be e.g. antonyms or meronyms, or be in an argument­ predicate relationship with the entry. To exemplify, we consider the word rock, which has two senses: a long coat and rock music, respectively. Its first sense has the primary descriptor kappa `coat', while for the second sense it is musik `music'. When embedding the SALDO network using the algorithm in Section 2, the neighbors nijk of a SALDO sense sij are its primary descriptor and inverse primaries (the senses for which sij is the primary descriptor). We did not use any descriptors beside the primary. The neighborhood weights were set so that the primary descriptor and the set of inverse primaries were balanced, and so that all weights sum to 1. If there were N inverse primaries, we set the weight of the primary descriptor 1 to 1 2 and of each inverse primary to 2N . We did not see any measurable effect of using a larger set of neighbors (e.g. adding connections to second-order neighbors). 3.3 Inspection of Sense Embeddings

have been hard to derive in a standard word vector space, due to the dominance of the music sense.
rock-1 `coat' midjekort `doublet' trekvarts¨ arm `3/4 sleeve' spetsbh `lace bra' bl° ajeans `blue jeans' treggings `treggings' rock-2 `rock music' indie `indie' indierock `indie rock' doo-wop `doo-wop' psykedelia `psychedelia' R&B `R&B'

Table 2: The unlisted lemmas closest to the two senses of rock.

4

Evaluation

Table 1 shows a list of the nearest neighbors of the two senses of rock; as we can see, both lists make sense semantically. (A similar query among the lemma embeddings returns a list almost identical to that of the second sense.)
rock-1 `coat' syrtut-1 `overcoat' k° apa-2 `cloak' kappa-1 `coat' kavaj-1 `blazer' jacka-1 `jacket' rock-2 `rock music' punk-1 `punk music' pop-1 `pop music' soul-1 `soul music' h° ardrock-1 `hard rock' hot-2 `hot jazz'

Table 1: The senses closest to the two senses of rock. A more difficult and interesting use case, where corpus-based methods clearly have an advantage over knowledge-based methods, is to search among the lemmas that have occurred in the corpus but which are not listed in SALDO. Table 2 shows the result of this search, and again the result is very useful. We stress that the list for the first sense would 1431

Evaluating intrinsically using e.g. a correlation between a graph-based similarity measure and geometric similarity would be problematic, since this is in some sense what our algorithm optimizes. We therefore evaluate extrinsically, by using the sense vectors in a classifier that maps senses to semantic classes defined by FrameNet (Fillmore and Baker, 2009). FrameNet is a semantic database consisting of two parts: first, an ontology of semantic frames ­ the classes ­ and secondly a lexicon that maps word senses to frames. In standard FrameNet terminology, the senses assigned to a frame are called its lexical units (LUs). Coverage is often a problem in frame-semantic lexicons, and this has a negative impact on the quality of NLP systems using FrameNet (Palmer and Sporleder, 2010). The task of finding LUs for frames is thus a useful testbed for evaluating lemma and sense vectors. To evaluate, we used 567 frames from the Swedish FrameNet (Friberg Heppin and Toporowska Gronostaj, 2012); in total we had 28,842 verb, noun, adjective, and adverb LUs, which we split into training (67%) and test sets (33%). For each frame, we trained a SVM with L IBLINEAR (Fan et al., 2008), using the LUs in that frame as positive training instances, and all other LUs as negative instances. Each LU was represented as a vector: its lemma or sense embedding normalized to unit length. Table 3 shows the precision, recall, and F measure for the classifiers for the five frames with most LUs, and finally the micro-average over all frames. In the overall evaluation as well as in four

