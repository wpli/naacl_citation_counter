tion or ranking. Second, we demonstrate strong results on query classification and web search. Our multi-task representation learning consistently outperforms stateof-the-art baselines. Meanwhile, we show that our model is not only compact but it also enables agile deployment into new domains. This is because the learned representations allow domain adaptation with substantially fewer in-domain labels.

of relevance. For example, if the query Q is "Denver sushi", model returns a list of documents that satisfies such information need. Formally, we estimate P (D1 |Q), P (D2 |Q), . . . for each document Dn and rank according to these probabilities. We assume that supervised data exist; I.e., there is at least one relevant document Dn for each query Q. 2.2 The Proposed Multi-Task DNN Model Briefly, our proposed model maps any arbitrary queries Q or documents D into fixed lowdimensional vector representations using DNNs. These vectors can then be used to perform query classification or web search. In contrast to existing representation learning methods which employ either unsupervised or single-task supervised objectives, our model learns these representations using multi-task objectives. The architecture of our multi-task DNN model is shown in Figure 1. The lower layers are shared across different tasks, whereas the top layers represent task-specific outputs. Importantly, the input X (either a query or document), initially represented as a bag of words, is mapped to a vector (l2 ) of dimension 300. This is the shared semantic representation that is trained by our multi-task objectives. In the following, we elaborate the model in detail: Word Hash Layer (l1 ): Traditionally, each word is represented by a one-hot word vector, where the dimensionality of the vector is the vocabulary size. However, due to the large size of vocabulary in realworld tasks, it is very expensive to learn such kind of models. To alleviate this problem, we adopt the word hashing method (Huang et al., 2013). We map a one-hot word vector, with an extremely high dimensionality, into a limited letter-trigram space (e.g., with the dimensionality as low as 50k). For example, word cat is hashed as the bag of letter trigram {#-c-a, c-a-t, a-t-#}, where # is a boundary symbol. Word hashing complements the one-hot vector representation in two aspects: 1) out of vocabulary words can be represented by letter-trigram vectors; 2) spelling variations of the same word can be mapped to the points that are close to each other in the letter-trigram space. Semantic-Representation Layer (l2 ): This is a shared representation learned across different tasks. this layer maps the letter-trigram inputs into a 300-

2
2.1

Multi-Task Representation Learning
Preliminaries

Our multi-task model combines classification and ranking tasks. For concreteness, throughout this paper we will use query classification as the classification task and web search as the ranking task. These are important tasks in commercial search engines: Query Classification: Given a search query Q, the model classifies in the binary fashion as to whether it belongs to one of the domains of interest. For example, if the query Q is "Denver sushi", the classifier should decide that it belongs to the "Restaurant" domain. Accurate query classification enables a richer personalized user experience, since the search engine can tailor the interface and results. It is however challenging because queries tend to be short (Shen et al., 2006). Surface-form word features that are common in traditional document classification problems tend to be too sparse for query classification, so representation learning is a promising solution. In this study, we classify queries into four domains of interest: ("Restaurant", "Hotel", "Flight", "Nightlife"). Note that one query can belong to multiple domains. Therefore, a set of binary classifiers are built, one for each domain, to perform the classification. We frame the problem as four binary classification tasks. Thus, for domain Ct , our goal is binary classification based on P (Ct | Q) (Ct = {0, 1} ). For each domain t, we assume supervised data (Q, yt = {0, 1} with yt as binary labels.1 Web Search: Given a search query Q and a document list L, the model ranks documents in the order
1

One could frame the problem as a a single multi-class classification task, but our formulation is more practical as it allows adding new domains without retraining existing classifiers. This will be relevant in domain adaptation (§3.3).

913

