window size w, the CBOW model predicts the current word given the neighboring words as context. In contrast, the skip-gram model predicts the neighboring words given the current word. We used w = 5 and found CBOW to yield better results for our task. Thus the terms extracted from a corpus by the structural patterns are automatically clustered, and these clusters are used as an input to the ranking algorithm. 3.3 Ranking based on semantic intensity

ranking step is. Each step is evaluated separately using annotations obtained from Amazon Mechanical Turk. 4.1 Clustering In order to evaluate the automatic clustering procedure that uses K-means++ and word vectors, we start with the gold standard provided by de Melo and Bansal (2013): as mentioned above, their data set has 88 gold standard clusters, corresponding to 346 adjectives, annotated by humans for scale ordering. One problem with evaluating a hard clustering algorithm is that the same word may appear in multiple WordNet synsets, corresponding to multiple clusters (soft clustering). We therefore made a "hard cluster version" of the de Melo & Bansal dataset by removing any adjectives that occur in multiple clusters, and then eliminating any singleton clusters. This resulted in a gold standard set of 256 adjectives belonging to 84 clusters. We clustered the 256 adjectives from the gold standard data subset into 84 clusters: the representation for each adjective was a neural embedding derived using the word2vec tool trained on our PubMed data. We experimented with both the skipgram and continuous bag of words (CBOW) models to derive vectors of dimension sizes varying from 200 to 800 in increments of 100. To choose the right dimensionality and the best model, we evaluated the quality of the automatically derived 84 clusters against the gold standard. As a metric of evaluation for cluster quality, we follow Hatzivassiloglou and McKeown (1993) and use F1 calculated by comparing equivalence relations generated by the clusters (as implemented in LingPipe (2008)). We found that the CBOW model gave clusters closer to the gold standard than the skip-gram model. We found that a dimension size of 600 for the vectors yielded clusters with a maximum F1 score of 57%. Thus, we were able to fix the parameters for our clustering task. Figure 1 summarizes the results of this experiment. In their study, Hatzivassiloglou and McKeown (1993) evaluate the results of their clustering on a small set of 21 adjectives. They presented the 21 adjectives to 9 annotators and asked them to partition these adjectives such that each partition contain adjectives that belong to the same scale. They re-

Once the terms have been clustered, the second step is to provide a ranking between the cluster members. To do so, we use the MILP implementation provided by de Melo and Bansal (2013). This method computes an overall weak-strong score for a pair of adjectives based on the frequency of that pair in the matches for weak-strong and strong-weak patterns. The MILP then uses these scores among all relevant pairs of adjectives belonging to the same scale, capturing complex interactions to infer an ordering among them. 3.4 Data: PubMed corpus

In this work, we want to provide an approach that can infer scalar orderings for any domain-specific terms. Such terms might be absent from existing thesauri. Our approach is thus corpus-based as outlined above. We chose to test the robustness of our technique on PubMed, a large domain-specific corpus of biomedical texts. It is a free resource developed and maintained by the National Center for Biotechnology Information at the National Library of Medicine. It provides access to scientific abstracts, full text articles and associated resources. We used 10, 875, 982 freely available abstracts (not full text articles) from PubMed as our corpus. This corresponds to 88, 303, 272 sentences in total, where the average length of a sentence is 28 words (including punctuations). We used this corpus to find instances of the structural strong-weak and weakstrong patterns, both for adjectives and adverbs.

4

Comparison with the gold standard of de Melo & Bansal

To evaluate our approach, we need to establish how good the clustering step is, as well as how good the 486

