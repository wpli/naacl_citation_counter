we use logistic classifiers independently predicting role distribution for every argument. For the reconstruction component, both for English and German, we set the embedding dimensionality d, the projection dimensionality k and the number of negative samples n to 30, 15 and 20, respectively. The model was not sensitive to the parameter |R|, defining the number of roles as long it was large enough (see Section 4.3 for more discussion). For training, we used uniform random initialization and AdaGrad (Duchi et al., 2011). Any model selections (e.g., choosing the number of epochs) was done on the basis of the respective held-out set. 4.3 4.3.1 Results English

Our Model Bayes Agglom+ RoleOrdering Agglom GraphPart LLogistic SyntF

PU 79.7 89.3 87.9 83.5 88.7 88.6 79.5 81.6

CO 86.2 76.6 75.6 78.5 73.0 70.7 76.5 77.5

F1 82.8 82.5 81.3 80.9 80.1 78.6 78.0 79.5

Table 1: Results on English (PropBank / CoNLL 2008).

Table 1 summarizes the results of our method, as well as those of alternative approaches and baselines. Following (Lang and Lapata, 2010), we use a baseline (SyntF) which simply clusters predicate arguments according to the dependency relation to their head. A separate cluster is allocated for each of 20 most frequent relations in the dataset and an additional cluster is used for all other relations. As observed in the previous work (Lang and Lapata, 2011a), this is a hard baseline to beat. We also compare with previous approaches: the latent logistic classification model (Lang and Lapata, 2010) (labeled LLogistic), the agglomerative clustering method (Lang and Lapata, 2011a) (Agglom), the graph partitioning approach (Lang and Lapata, 2011b) (GraphPart), the global role ordering model (Garg and Henderson, 2012) (RoleOrdering). We also report results of an improved version of Agglom, recently reported by Lang and Lapata (2014) (Agglom+). The strongest previous model is Bayes: Bayes is the most accurate (`coupled') version of the Bayesian model of Titov and Klementiev (2012a), estimated from the CoNLL dataset without relying on any external data. Titov and Klementiev (2012a) also showed that using Brown clusters induced from a large external corpus resulted in an 0.5% improvement in F1 but that version is not entirely comparable to other systems induced solely from the CoNLL text. Our model outperforms or performs on par with 7

best previous models in terms of F1. Interestingly, the purity and collocation balance is very different for our model and for the rest of the systems. In fact, our model induces at most 4-6 roles (even if |R| is much larger). On the contrary, Bayes predicts more than 30 roles for the majority of frequent predicates (e.g., 43 roles for the predicate include or 35 for say). Though this tendency reduces the purity scores for our model, this also means that our roles are more human interpretable. For example, agents and patients are clearly identifiable in the model predictions. Our model has similar purity to the syntactic baseline but outperforms it vastly according to the collocation metric, suggesting that we go substantially beyond recovering syntactic relations. In additional experiments, we observed that our model, in some regimes, starts to induce roles specific to individual verb senses or specific to groups of semantically similar predicates. This suggests that adding a latent variable capturing predicate senses and conditioning the reconstruction component on this variable may not only result in a more informative semantic representation (i.e. include verb senses) but also improve the role induction performance. We leave this exploration for future work. 4.3.2 German

For German, we replicate the experimental set-up previously used by Titov and Klementiev (2012b). As for English, we report results of the syntactic baseline (SyntF). The results for all approaches are presented in Table 2. We compare against Bayes (De) ­ the Bayes model with argument signatures specialized for German (as reported in Titov and Klementiev (2012b)). We also consider the original

