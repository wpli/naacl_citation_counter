framework for the update summarization task, and make improvement from two aspects, with the goal to more discriminatively represent both the salience and novelty of words and sentences. First, we use supervised models and a rich set of features to learn the weights for the bigram concepts used in the ILP model. Second, we design a sentence reranking component to score the summary candidate sentences generated by the ILP model. This second reranking approach allows us to explicitly model a sentence's importance and novelty, which complements the bigram centric view in the first step of ILP sentence selection. Our experimental results on multiple TAC data sets demonstrate the effectiveness of our proposed method.

the concepts it contains, and selecting a concept only happens when it is present in at least one of the selected sentences. 2.2 Bigrams Weighting for Salience and Novelty

2

Proposed Update Summarization System

2.1 ILP Framework for Summarization The core idea of the ILP based summarization method is to select the summary sentences by maximizing the sum of the weights of the language concepts that appear in the summary. Bigrams are often used as the language concepts in this method. Gillick et al. (2009) stated that the bigrams gave consistently better performance than unigrams or trigrams for a variety of ROUGE measures. The association between the language concepts and sentences serves as the constraints. This ILP method is formally represented as below (see (Gillick et al., 2009) for more details): max
i wi ci

(1) sj Occij  ci
j

In the above ILP-based summarization method, how to determine the concepts and measure their weights is the key factor impacting the system performance. Intuitively, if we can successfully identify the important key bigrams used in the ILP system, or assign large weights to those important bigrams, the generated summary sentences will contain as many important bigrams as possible, and thus resulting in better summarization performance. The oracle experiment in (Gillick et al., 2008) showed that if they use the bigrams extracted from the human written summaries as the input of the ILP system, much better ROUGE scores can be obtained than using the automatically selected bigrams, suggesting the importance of using the right concepts. (Gillick et al., 2009) used document frequency as the weight of a bigram. They also provided some justification for document frequency as a weighting function in that paper. For update summarization, intuitively we need to not only identify the salience of the bigram, but also incorporate bigrams' novelty in their weights. Therefore, only using the document frequency as the weight in the objective function is insufficient. We thus propose to use a supervised framework for the bigram weight estimation in the ILP model. The new objective function is: max
i (

s.t. ci  {0, 1} i sj  {0, 1} j sj Occij  ci
j lj sj

· f(bi )) ci

(2)

L

where ci and sj are binary variables that indicate the presence of a concept and a sentence respectively. lj is the sentence length and L is the maximum length (word number) of the generated summary. wi is a concept's weight and Occij means the occurrence of concept i in sentence j . The first two inequalities associate the sentences and concepts. They ensure that selecting a sentence leads to the selection of all

We replace the heuristic wi in Formula (1) with a feature based one: f (bi ) represents the features for a bigram bi , and  is a weight vector for these features. Constraints remain the same as before in the ILP method. There are two kinds of features for each bigram: one set is related to the bigrams themselves; the other set is related to the sentences containing the bigram. Table 1 shows the features we design. For both the bigram and the sentence level features, we separate the features based on whether they represent the importance or the novelty. For

1318

