Figure 2: Our nonparanormal method extends Gaussian by transforming each dimension with a smooth function, and jointly models the stochastic dependencies among textual and visual features, as well as the popular votes by the crowd.

Figure 3: An example of the standard SIFT keypoints detected on the "doge" meme.

using raw counts or histograms, we first use probability integral transform to generate empirical cumulative density functions (ECDF): now instead of the probability density function (PDF) space, we are working in the ECDF space where the value of each feature is based on the rank, and is strictly restricted between 0 and 1. Then, we use kernel density estimation to smooth out the zeroing features1 . Finally, now textual and visual features are compatible, and we then build a parametric Gaussian copula model to estimate the pair-wise correlations among the covariate and the dependent variable. In this section, we first explain the visual and textual features used in this study. Then, we introduce the theory of copula, and describe the robust nonparanormal. Finally, we show a simple pipeline for generating meme descriptions. 3.1 Features Textual Features To model the meme descriptions, we take a broad range of textual features into considerations:  Lexical Features: we extract unigrams and bigrams from meme descriptions as surface-level lexical features.  Part-of-Speech Features: to model shallow syntactic cues, we extract lexicalized part-ofspeech features using the Stanford part-ofspeech tagger (Toutanova et al., 2003).  Dependency Triples: to better understand the deeper syntactic dependencies of keywords in
This is necessary for the normal inversion of the ECDFs, which we will describe in Section 3.2.
1

memes, we have also extracted typed dependency triples (e.g., subj(I,are)) using the MaltParser (Nivre et al., 2007).  Named Entity Features: after browsing the dataset, we notice that certain names are often mentioned in memes (e.g. "Drake", "Kenye West", and "Justin Bieber"), so we utilize the Stanford named entity recognizer (Finkel et al., 2005) to extract lexicalized named entities.  Frame-Semantics Features: SEMAFOR (Das et al., 2010) is a state-of-the-art framesemantics parser that produces FrameNet-style semantic annotation. We use SEMAFOR to extract frame-level semantic features. Visual Features A key insight on viral memes is that the images producing a shared social signal are typically inter-related in style. For example, LOLcats are an early series of memes involving funny cat photos. Similarly, "Bieber memes" involve modified pictures of Bieber. Therefore, we hypothesize that, by extracting visual features, it is of crucial importance to capture the entities, objects, and styles as visual words in these inter-related meme images. The popular visual bag-of-words representation (Sivic and Zisserman, 2003) is used to describe images: 1. PHOW Features Extraction: unlike text features, SIFT first detects the Harris keypoints from an image, and then describes each keypoint with a vector. An example of the SIFT frames are shown in Figure 3. PHOW (Bosch et al., 2007) is a dense and multi-scale variant of the Scale Invariant Feature Transform (SIFT) descriptors. Using PHOW, we obtain about 20K keypoints for each image.

357

