Algorithm 1 Beam Search Decoding: Given the likelihoods from our DBRNN and our character language model, for each time step t and for each string s in our current previous hypothesis set Zt-1 , we consider extending s with a new character. Blanks and repeat characters with no separating blank are handled separately. For all other character extensions, we apply our character language model when computing the probability of s. We initialize Z0 with the empty string . Notation:  : character set excluding " ", s + c: concatenation of character c to string s, |s|: length of s, pb (c|x1:t ) and pnb (c|x1:t ): probability of s ending and not ending in blank conditioned on input up to time t, ptot (c|x1:t ): pb (c|x1:t ) + pnb (c|x1:t ) Inputs CTC likelihoods pctc (c|xt ), character language model pclm (c|s) Parameters language model weight , insertion bonus  , beam width k Initialize Z0  {}, pb (|x1:0 )  1, pnb (|x1:0 )  0 for t = 1, . . . , T do Zt  {} for s in Zt-1 do pb (s|x1:t )  pctc ( |xt )ptot (s|x1:t-1 ) Handle blanks pnb (s|x1:t )  pctc (c|xt )pnb (s|x1:t-1 ) Handle repeat character collapsing Add s to Zt for c in  do s+  s + c if c = st-1 then pnb (s+ |x1:t )  pctc (c|xt )pclm (c|s) ptot (c|x1:t-1 ) else pnb (s+ |x1:t )  pctc (c|xt )pclm (c|s) pb (c|x1:t-1 ) Repeat characters have " " between end if Add s+ to Zt end for end for Zt  k most probable s by ptot (s|x1:t )|s| in Zt Apply beam end for Return arg maxsZt ptot (s|x1:T )|s| moves the difficulties of handling OOV words during decoding, which is typically a troublesome issue in speech recognition systems. and character error rate (CER) on the HUB5 Eval2000 dataset (LDC2002S09). This test set consists of two subsets, Switchboard and CallHome. The CallHome subset represents a mismatched test condition as it was collected from phone conversations among family and friends rather than strangers directed to discuss a particular topic. The mismatch makes the CallHome subset quite difficult overall. The Switchboard evaluation subset is substantially easier, and represents a better match of test data to our training corpus. We report WER and CER on the test set as a whole, and additionally report WER for each subset individually. 4.1 Baseline Systems We build two baseline LVCSR systems to compare our approach to standard HMM-based approaches.

4

Experiments

We perform LVCSR experiments on the 300 hour Switchboard conversational telephone speech corpus (LDC97S62). Switchboard utterances are taken from approximately 2,400 conversations among 543 speakers. Each pair of speakers had never met, and converse no more than once about a given topic chosen randomly from a set of 50 possible topics. Utterances exhibit many rich, complex phenomena that make spoken language understanding difficult. Table 2 shows example transcripts from the corpus. For evaluation, we report word error rate (WER) 349

