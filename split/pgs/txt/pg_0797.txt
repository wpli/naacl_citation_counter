(a) RT @USER : Christmas:PER was so much better when there was a santa :( #allteensthings RT @USER : Christmas was so much better when there was a santa :( #allteensthings (b) Lmao . I have a feeling Imma:ORG get yelled at tomorrow . Big time . XD Ehh oh well Lmao . I have a feeling Imma get yelled at tomorrow . Big time . XD Ehh oh well (c) I pray an give God glory even when im in pain , hurting , or crying . I pray an give God:PER glory even when im in pain , hurting , or crying . (d) Anyone know what days/times that you can smoke hookah at the mix ( cma center ) in corbin:PER . Anyone know what days/times that you can smoke hookah at the mix ( cma center ) in corbin:LOC .
Figure 3: (a,b): examples where the baseline (top) is improved by our final system (bottom) (c,d): examples where our final system (top) falls short of the gold-standard (bottom)

to rely heavily on local context and capitalization, while the primary system has a much stronger global prior on a given type's entity assignment. Reps+Weights improved the baseline in 54 out of 100 tweets. There were 31 cases where the primary system corrected a baseline error caused by a misleading capitalization cue. Some of these, such as Figure 3(a) are patched by world knowledge provided by word representations, but many simply reflect a reduced reliance on capitalization. We were surprised to find only 11 cases where Twitter's informal language led to an error, often due to a vaguely name-shaped colloquialism, such as in 3(b). 6 of these 11 cases were fixed by the primary system. Reps+Weights fell short of the gold-standard in 62 of 100 tweets. We observed 39 recall errors that were difficult to divide into smaller bins. These entities were often missed despite clear capitalization cues, as in Figure 3(c). This particular example is actually a symptom of inconsistent annotation: CoNLL and Rit11 consistently annotate God as a person, while our Fin10 training data leaves God untagged. The next largest class of errors consists of 11 problems caused by uniform casing (all caps or all lowercase). We also have 5 remaining errors due to informal language, which are interesting, as they highlight gaps in our representations. These include cases where the system generates false entities for variants of rare words (Tidying  Tidyin), or unusual lengthenings (Yayaayayay, as opposed to the well-attested Yayayayay). We also saw cases where entities were missed due to creative punctuation (Go V-I-K-I-N-G-S!). Finally, we found 4 cases where the system actually over-relies on its word represen743

tations, such as in 3(d), where the global PER interpretation of corbin overrides a fairly strong LOC signal provided by the local context word in.

7

Discussion

We have shown that the combination of Brown clusters, word vectors, and a simple data weighting scheme is sufficient to establish a new state-of-theart on two Twitter NER test sets, using only 1,000 annotated tweets. We have designed our experiments to emphasize the dramatic impact of word representations in this domain, and to clarify the effects of in- and out-of-domain training sets. Word representations learned on a large, unlabeled Twitter corpus have addressed a surprising number of issues with inconsistent capitalization and informal language. However, our continuing problems with uncased tweets and unusual colloquialisms demonstrate that there are still many humanreadable words that remain a mystery to our system. In response to these observations, we would like to investigate more flexible representations, perhaps similar to those of Botha and Blunsom (2014), who use a linear combination of morpheme vectors to create representations that can generalize across words with similar forms.

Acknowledgments
Thanks to the anonymous reviewers for their helpful comments, to Alan Ritter for providing us with our corpus of unlabeled tweets, and to Barbara Plank for providing us with our three labeled corpora.

