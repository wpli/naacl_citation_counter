Conversation A: if youre following today maybe follow me B: lol ur off to an early start A: like you're talking about the stupidest things ever. its annoying B: who is this about A: Aww man happy birthday bro!! Lol you know you gotta die right? B: What? Lol

Response Avg. Rank 1: im at the bus stop how was your night 2.1 2: i dont fancy hame pass for 3.6 3: lmao i got my second home 3.2 4: updating haha I get u off too 1.9 1: the ppl behind you 1.9 2: I want tie you 3.6 3: like I said Im talking seriously are you 2.3 4: one of them is that you 2.9 1: you gotta damn near die from drinking today 1.2 2: lol yea 3.8 3: thank you man you know me 2.4 4: lol I know I know 2.8

* 1 is the actual response on Twitter, while 2,3 and 4 are responses generated by the baseline, pair-based, token-based models respectively.

Table 3: Examples of Responses

15% of the questions, especially when the actual responses were grammatically poor, or irrelevant to the topic of the conversation. There was no significant difference between the performances of our models. It also shows the p-value and mutual agreement between two models. Using S coefficient (Bennett et al., 1954) as a measurement of agreement yields the following result. Most of them fall into "moderate agreement" range of 0.4 to 0.6, except Token-based model against Pair-based model is slightly lower and falls into "fair agreement" range (Landis and Koch, 1977). Table 2 shows the distribution of each model over each ranking and their average rankings. Our models outperform the baseline model in higher rankings. Table 3 features examples of responses generated by each model and the actual responses on Twitter, along with their average ranking in the final evaluation. In the first conversation, one of our models was ranked higher than both the baseline model and the actual response. In other conversations, our models were ranked higher than the baseline model, but lower than the actual response. Generally, our models have a wider range of topic-relevant vocabularies, and sound comparatively coherent than the baseline model, without too much grammatical violations.

model when examined in a wider scope of conversations. Although its performance against the actual responses was not as satisfactory, it could outperform them when the actual responses diverted from the topic, or had poor coherence and grammaticality. Possible applications include chatterbots or conversational agents. Most such applications are based on one-turn conversation, where user says something, system gives some response, and that is technically the end of the conversation of current topic, which will not be referred to in later conversations. Our work can, for example, provide the system with possible topics to talk about, especially when the input from the user is short or trivial. Diversity of the responses is obtained because, even when the system is given the same input, it will return completely different responses depending on what was previously talked about, as opposed to the applications where certain responses can be expected given an input. An improvement is likely to come from attempting different methods to extract the core tokens from the past utterances. We relied on the Fisher's Exact Test and tf-idf throughout the research, but other approaches may perform better. Alternatively, we may try different weighting systems depending on whether a token is from the same speaker as the current utterance or a different speaker, since it would generally make more sense for a particular speaker not to repeat him/herself.

5

Conclusion and Future Work

As we observed in the experimental results, our context-dependent model outperformed the baseline 1349

