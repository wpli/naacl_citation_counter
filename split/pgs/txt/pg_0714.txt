References
Mohit Bansal, Kevin Gimpel, and Karen Livescu. 2014. Tailoring continuous word representations for dependency parsing. In Proceedings of the Annual Meeting of the Association for Computational Linguistics. Yonatan Bisk and Julia Hockenmaier. 2012. Simple robust grammar induction with combinatory categorial grammars. In AAAI. Avrim Blum and Tom M. Mitchell. 1998. Combining labeled and unlabeled sata with co-training. In COLT, pages 92­100. Phil Blunsom and Trevor Cohn. 2010. Unsupervised induction of tree substitution grammars for dependency parsing. In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 1204­1213. Association for Computational Linguistics. Eugene Charniak and Mark Johnson. 2005. Coarse-tofine n-best parsing and maxent discriminative reranking. In ACL. Danqi Chen and Christopher D Manning. 2014. A fast and accurate dependency parser using neural networks. In Empirical Methods in Natural Language Processing (EMNLP). Michael Collins. 2000. Discriminative reranking for natural language parsing. In ICML, pages 175­182. Michael Collins. 2003a. Head-driven statistical models for natural language parsing. Computational linguistics, 29(4):589­637. Michael Collins. 2003b. Head-driven statistical models for natural language parsing. Computational Linguistics, 29(4):589­637. Ronan Collobert, Jason Weston, L´ eon Bottou, Michael Karlen, Koray Kavukcuoglu, and Pavel Kuksa. 2011. Natural language processing (almost) from scratch. The Journal of Machine Learning Research, 12:2493­ 2537. George Cybenko. 1989. Approximation by superpositions of a sigmoidal function. Mathematics of control, signals and systems, 2(4):303­314. Jason M Eisner. 1996. Three new probabilistic models for dependency parsing: An exploration. In Proceedings of the 16th conference on Computational linguistics-Volume 1, pages 340­345. Association for Computational Linguistics. Jeffrey L Elman. 1993. Learning and development in neural networks: The importance of starting small. Cognition, 48(1):71­99. Jennifer Gillenwater, Kuzman Ganchev, Jo~ ao Grac ¸ a, Fernando Pereira, and Ben Taskar. 2011. Posterior sparsity in unsupervised dependency parsing. The Journal of Machine Learning Research, 12:455­490.

Katsuhiko Hayashi, Shuhei Kondo, and Yuji Matsumoto. 2013. Efficient stacked dependency parsing by forest reranking. Transactions of the Association for Computational Linguistics, 1(1):139­150. Dan Klein and Christopher D. Manning. 2004. Corpusbased induction of syntactic structure: Models of dependency and constituency. In ACL, pages 478­485. Terry Koo and Michael Collins. 2010. Efficient thirdorder dependency parsers. In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 1­11. Association for Computational Linguistics. Phong Le and Willem Zuidema. 2014. The insideoutside recursive neural network model for dependency parsing. In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics. David Marecek and Milan Straka. 2013. Stopprobability estimates computed on a large corpus improve unsupervised dependency parsing. In ACL (1), pages 281­290. Andr´ e FT Martins, Miguel B Almeida, and Noah A Smith. 2013. Turning on the turbo: Fast third-order non-projective turbo parsers. In Proc. of ACL. David McClosky, Eugene Charniak, and Mark Johnson. 2006. Effective self-training for parsing. In Proceedings of the main conference on human language technology conference of the North American Chapter of the Association of Computational Linguistics, pages 152­159. Association for Computational Linguistics. Ryan T. McDonald and Fernando C. N. Pereira. 2006. Online learning of approximate dependency parsing algorithms. In EACL. Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Corrado, and Jeff Dean. 2013. Distributed representations of words and phrases and their compositionality. In Advances in Neural Information Processing Systems, pages 3111­3119. Tahira Naseem and Regina Barzilay. 2011. Using semantic cues to learn syntax. In AAAI. Tahira Naseem. 2014. Linguistically Motivated Models for Lightly-Supervised Dependency Parsing. Ph.D. thesis, Massachusetts Institute of Technology. Jeffrey Pennington, Richard Socher, and Christopher D Manning. 2014. Glove: Global vectors for word representation. Proceedings of the Empiricial Methods in Natural Language Processing (EMNLP 2014), 12. Federico Sangati, Willem Zuidema, and Rens Bod. 2009. A generative re-ranking model for dependency parsing. In Proceedings of the 11th International Conference on Parsing Technologies, pages 238­241. Association for Computational Linguistics.

660

