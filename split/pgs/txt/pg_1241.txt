3

3

2

2

1

1

0

0

-1

-1

-2

-2

-3

-3

-3

-2

-1

0

1

2

3

-3

-2

-1

0

1

2

3

-3

-2

-1

0

1

2

r = 0.41

r = 0.6

3

r = 0.76

-3

-2

-1

0

1

2

3

N=1
3 3

N=2 r = 0.91
3

N=5 r = 0.97

2

2

1

1

0

0

-1

-1

-2

-2

-3

-3

-3

-2

-1

0

1

2

3

-3

-2

-1

0

1

2

3

-3 -3

-2

-1

0

1

2

r = 0.86

-2

-1

0

1

2

3

N = 10

N = 15

N = 40

Figure 2: Plots and correlation (r) of translation quality assessments in the initial (x-axis) and replicate experiments (y axis) for Spanish-to-English over W MT-13, where each point represents a standardized segment-level score computed as the mean of the N individual assessments for that plot.

task was posed as a monolingual task, where assessors were asked to rate the degree to which the MT system output adequately expressed the meaning of the corresponding reference translation. Translations were sampled at random from the W MT-13 data sets for the four language pairs, as detailed in Table 1. Due to low-quality assessors on MTurk and the need for assessments solely for quality assurance purposes, the exercise required a substantial number of individual assessments. For Spanish-toEnglish, for example, a total of (280 translations + 120 translations for quality-control purposes) × 40 assessments per translation × 2 separate data collections × 2 to allow for filtering of low-quality assessors = 64k assessments were collected; after quality control filtering and removing the qualitycontrol translations, around 22k assessments were used for the actual experiment. Figure 1 shows the Pearson correlation between mean segment-level scores calculated for varying numbers of assessments (N ), and the full set of assessments for the second set of assessments. For each language pair, we calculate the correlation first over the raw segment scores and second over standardized scores, based on the method of Graham et 1187

al. (2014a).2 For all language pairs, although the correlation is relatively low for single assessments, as the sample size increases, it increases, and by approximately N = 15 assessments, for all four language pairs, the correlation reaches r = 0.9. For Spanish-to-English, for which most assessments were collected, when we increase the number of assessments to N = 40 per translation, the correlation reaches r = 0.97. Figure 2 is a set of scatter plots for mean segment-level scores for Spanish-toEnglish rising, for varying sample sizes N . As expected, the larger the sample size of assessments, the greater the agreement with the true mean score, but what is more surprising is that with as few as 15 assessments, the scores collected in the two separate experiments correlate extremely well, and provide what we believe to be a sufficient stability to evaluate segment-level metrics.

Standardized segment scores are computed by standardizing individual raw scores according to the mean and standard deviation of individual assessors, and then combined into mean segment scores.

2

