of relation labels, respectively. For example, given an AMR graph GAM R in Figure 2a, its span graph G can be represented as Figure 2b. In span graph G, node s3,4 's sentence span is (want) and its concept label is want-01, which represents a single node want-01 in AMR. To simplify the alignment, when creating a span graph out of an AMR, we also collapse some AMR subgraphs in such a way that they can be deterministically restored to their original state for evaluation. For example, the four nodes in the AMR subgraph that correspond to span (Micheal, Karras) is collapsed into a single node s6,8 in the span graph and assigned the concept label person+name, as shown in Figure 3. So the concept label set that our model predicts consists of both those from the concepts in the original AMR graph and those as a result of collapsing the AMR subgraphs.
person name s6,8 :person+name op1 "Micheal" name op2 "Karras"

 St  S is a set of terminal states. Each state (configuration) of our transition-based parser is a triple (, , G).  is a buffer that stores indices of the nodes which have not been processed and we write  = 0 | to indicate that 0 is the topmost element of  .  is also a buffer [0 , 1 , . . . , j ] and each element i of  indicates the edge (0 , i ) which has not been processed in the partial graph. We also write  = 0 | to indicate the topmost element of  is 0 . We use span graph G to store the partial parses for the input sentence w. Note that unlike traditional transition-based syntactic parsers which store partial parses in the stack structure and build a tree or graph incrementally, here we use  and  buffers only to guide the parsing process (which node or edge to be processed next) and the actual tree-to-graph transformations are applied to G. When the parsing procedure starts,  is initialized with a post-order traversal of the input dependency tree D with topmost element 0 ,  is initialized with node 0 's children or set to null if 0 is a leaf node. G is initialized with all the nodes and edges of D. Initially, all the nodes of G have a span length of one and all the labels for nodes and edges are set to null. As the parsing procedure goes on, the parser will process all the nodes and their outgoing edges in dependency tree D in a bottom-up left-right manner, and at each state certain action will be applied to the current node or edge. The parsing process will terminate when both  and  are empty. The most important part of the transition-based parser is the set of actions (transitions). As stated in (Sartorio et al., 2013), the design space of possible actions is actually infinite since the set of parsing states is infinite. However, if the problem is amenable to transition-based parsing, we can design a finite set of actions by categorizing all the possible situations we run into in the parsing process. In 5.2 we show this is the case here and our action set can account for almost all the transformations from dependency trees to AMR graphs. We define 8 types of actions for the actions set T , which is summarized in Table 1. The action set could be divided into two categories based on conditions of buffer  . When  is not empty, parsing decisions are made based on the edge (0 , 0 ); oth-

Figure 3: Collapsed nodes Representing AMR graph this way allows us to formulate the AMR parsing problem as a joint learning problem where we can design a set of actions to simultaneously predict the concepts (nodes) and relations (arcs) in the AMR graph as well as the labels on them.

3
3.1

Transition-based AMR Parsing
Transition System

Similar to transition-based dependency parsing (Nivre, 2008), we define a transition system for AMR parsing as a quadruple S = (S, T, s0 , St ), where  S is a set of parsing states (configurations).  T is a set of parsing actions (transitions), each of which is a function t : S  S .  s0 is an initialization function, mapping each input sentence w and its dependency tree D to an initial state.

368

