input (t1 , w1 ) ... (tn , wn ) axiom 0 : sh rex unx , (t1 , w1 ) ... (tn , wn ) : 0

sh

l : S, (t, w)|Q : (c, v ) l is even l+1 : S |t(w), Q : (c+csh , 0) l : S |s1 , Q : (c , v ) l : S |s1 |s0 , Q : (c, v ) l+1 : S |x(s1 , s0 ), Q : (c +v +, v +v + ) l and l are even, p   (q ) l : S |s0 , Q : (c, v ) l is odd l+1 : S |x(s0 ), Q : (c+cunx , v + cunx )
state p: state q :

l : S, (t, w)|Q : c l is even l+1 : S |t(w), Q : c+csh l : S |s1 |s0 , Q : c l is even l+1 : S |x(s1 , s0 ), Q : c+crex l : S |s0 , Q : c l is odd l+1 : S |x(s0 ), Q : c+cunx l : S |s0 , Q : c l is odd l+1 : S |s0 , Q : c+cst :c

rex

unx

st

Figure 2: DP shift-reduce, omitting rex and st. c and v are prefix and inside scores, and  = csh (p) + crex (q ). State equivalence is defined below in Section 3.

goal 2(2n - 1) : s0 ,

syntactic category of tree s0 , resp., and s0 .lc.w is the head word of its leftmost child).

Figure 1: Shift-reduce system, omitting rex . c is the model score, and csh , crex , etc. are the action scores.

3

Dynamic Programming

·

unx :

replace s0 with a new tree x(s0 ) with x being the root nonterminal;

· st: no action. Figure 1 shows the deductive system. Note that we alternate between standard shift-reduce actions in even steps and unary actions (unx or st) in odd steps, and the first action must be sh, followed by a unx or st, and followed by another sh. Continuing this procedure, we can always achieve the goal in 2(2n - 1) steps. In practice, we have larger than two-way rules and multi-level unary rules, so we binarize them and collapse multi-level unary rules into one level, for example,
NP S VP V NP PP = NP+S VP VP V NP PP

The key idea towards DP is the merging of equivalent states, after which the stacks are organized in a "graph-structured stack" (GSS)(Tomita, 1988). Following Huang and Sagae (2010), "equivalent states"  in a same beam are defined by the atomic features ~ f (S, Q) and the span of s0 : S, Q  S , Q ~ f (S, Q) = ~ f (S , Q ) and s0 .span = s0 .span . Similarly, for each state p,  (p) is a set of predictor states, each of which can be combined with p in a rex or rex action. For each action, we have different operations on  (p). If a state p makes a sh action and generates a state p , then  (p ) = {p}. If two shifted states p and p are equivalent, p  p , we merge  (p ) and  (p ). If a state p makes a reduce (rex or rex ) action, p tries to combine with every p   (p), and each combination generates a state r with  (r) =  (p ). If two reduced states are equivalent, we only keep one predictor states, as their predictor states are identical. If a state p fires an unx or a st action resulting in a state u, we copy the predictor states  (u) =  (p). Similar to reduce actions, if two resulting states after applying an unx or a st action are equivalent, we only keep the best one with highest score (the recombined ones are only useful for searching k -best trees).

Following Huang and Sagae (2010), we represent feature templates as functions f (·, ·) on stack S and queue Q. Table 1 shows the 43 feature templates we use in this paper, all adopted from Zhu et al. (2013). They are combinations of the 32 atomic features ~ f (S, Q) (e.g. s0 .t and s0 .c denote the head tag and 1031

