I DENTITY: An edgeless knowledge graph. The only relations are between identical concepts, equivalent to Jaccard overlap of concept keyword roots. W ORDNET: Paraphrase relations from Wordnet. Wordnet (Fellbaum, 1998) is a lexical database of synonyms and hypernyms common in NLP tasks. For example, Snow et al (2006) use Wordnet as training data for ontology induction. To build W ORDNET, we draw an edge between every pair of Wordnet concepts (ws , wq ) for which the WuPalmer Similarity (WUP) (Wu and Palmer, 1994) of the first sense in each concept's synset exceeds 0.9, the best-performing WUP threshold we found. Concepts in the Wordnet hierarchy have a higher WUP when they have a closer common ancestor. If a known fact is Heat energy causes snow to melt, but a question asks if ice melts, then Wordnet should provide the missing knowledge that ice acts like snow. PPDB: Paraphrase relations from PPDB (Ganitkevitch et al., 2013) are derived by aligning bilingual parallel texts. PPDB is divided into subsets where the larger subsets have more paraphrases with less precision. We tried all subsets and found the smallest to give the best results, which we report here. The largest performed the worst of all relation sets we tested. We use the lexical paraphrases, which relates unigrams. Concepts are related when at least one concept keyword for each are paraphrases in PPDB. We obtained better performance by stemming PPDB words: for example, if snows and iced are paraphrases in PPDB then we also considered snowing and icy to be in PPDB. K NOWBOT: Each question is answered using relations pooled from all dialogs about all questions. The goal in each dialog is to acquire knowledge helpful to answer the question. If K NOWBOT leads to an increase in QA accuracy over I DENTITY, then we can successfully use open dialog with a human in the loop to learn knowledge that solves a question. L EAVE - ONE - OUT: Each question is answered only with relations learned during dialogs for every other question. While K NOWBOT uses relations learned from dialogs about the questions on those same questions, L EAVE - ONE - OUT tests whether knowledge generalizes to questions without dialogs. Generalization is only possible when there are at least two questions involving the same concepts. Due to our small number of questions, in the 857

best case we expect only slight improvement. I DENTITY W ORDNET PPDB K NOWBOT L EAVE - ONE - OUT %correct 41% 34% 39% 57% 45%

Table 2: QA accuracy on the 107 questions with dif-

ferent sources of domain knowledge. I DENTITY: identity relations only, e.g. "heats" to "heating." W ORD NET : Wordnet-derived pseudo-synonyms, e.g. "eagle" to "owl." K NOWBOT: the full, unablated global KG. L EAVE - ONE - OUT: answers each question while ignoring relations acquired during dialogs on that question.

5.2

Results

The results of QA using the different domain knowledge is shown in Table 2. I DENTITY achieves 41% accuracy on this difficult reasoning task, showing that some questions are answerable by searching S CITEXT for supporting sentences with the same concepts as in the question-answer statement. W ORDNET works surprisingly poorly. Examination found W ORDNET's relations to be of good quality, yet underperform I DENTITY. PPDB performed better but still underperformed I DENTITY. We conclude that general paraphrase bases introduce too much noise to apply directly without manual curation to our science domain, underscoring the need for domain-specific knowledge acquisition. K NOWBOT achieves accuracy of 57%, a dramatic improvement over both baselines. Importantly, this value does not test generalization to unseen questions, since K NOWBOT has held dialogs on these questions. However, it does show that our system can effectively learn about its domain: a poor dialog extraction system will fail to extract any helpful knowledge from users during a training dialog. This is a significant result because it shows that we successfully acquire knowledge to solve many question through conversational interaction without the overhead of a closed dialog model or fixed ontology. We also tested how well knowledge generalizes with L EAVE - ONE - OUT. Our question set is less suited to evaluate generalization because it covers a wide range of topics with little overlap between

