Word meaning in context Next, following Erk and Pad´ o (2010), to represent the meaning of word u in context c, we would like to alter the out-of-context representation by theoretically averaging only over contexts that induce a word sense similar to that of the given context. To approximate this objective we use a weighted average of all contexts of u, where contexts are weighted according to their similarity to the given context: pu,c = 1 Z sim(c, i) · si
iCcu

(4)

where Ccu = Cu  c (u's corpus contexts plus the given context) and Z is a normalization factor. 1 pu,c [v ] = Z iCcu sim(c, i) · si [v ] is the average fitness of v within the contexts of u, biased to those similar to c. We consider this a contextsensitive similarity score, indicative of the likelihood of v to be a paraphrase of u in context c.2 Thus, we name our in-context representation for a word instance as its paraphrase vector. m denotes a word representation as deFinally, pu,c fined in Equation (4), where only the top-m percent of the contexts in Ccu most similar to c are averaged. Using low values for m means injecting a stronger bias in our model towards the given context.

5

Evaluating Context Representations

As described in Section 4, our model for word meaning in context utilizes a context similarity measure under the premise that similar contexts induce similar target word senses. In this section we describe a focused evaluation of our proposed similarity measure and prior methods with respect to this objective. This evaluation suggests that our measures may be useful as a component in other models as well. 5.1 Task description Given a word window context c of a target word u, we wish to evaluate context similarity measures on their ability to retrieve other contexts of u from Cu that induce a similar sense. To perform such an evaluation we want a dataset of target words with thousands of sense tagged contexts in Cu for each target word u. Since available manually sense-tagged
This can be considered an in-context extension of the outof-context similarity score proposed by Melamud et al. (2014).
2

datasets, such as SemCor (Mihalcea, 1998), are not large enough for this purpose, we adopted a pseudoword approach, with which we can automatically generate as many tagged contexts as we wish. Pseudo-word methods consider a set of real words as pseudo-senses of an artificial pseudo-word (Pilehvar and Navigli, 2014). Specifically, we adopted a simple approach following Otrusina and Smrz (2010) to generate our pseduo-words. First, we sampled 100 words randomly from our learning corpus, ukWaC (Ferraresi et al., 2008). Then we constructed a pseudo-word based on each of these words as follows. We used WordNet (Fellbaum, 2010) to identify all of the word's synsets. Next, for each synset we chose the surface word which is the least polysemous yet occurs in our learning corpus at least 1,000 times, as a representative for this synset. Then, we created a pseudoword whose pseudo-senses are the set of the representative words. For example, the pseudo-word that was generated based on the word promote is elevate encourage advertise. Finally, we sampled from our learning corpus 1,000 contexts for each pseudo-sense word, and for each pseudo-word we mixed together all contexts of its pseudo-sense words. The original pseudo-sense word for each context was recorded as its sense tag. Next, for each pseudo-word, we sampled a single query context from all of its mixed contexts and then ranked the remaining contexts according to each of the compared context similarity measures. We computed precision at top-1, top-1% and average precision for the ranked lists, where a true-positive is a context with an identical sense tag as the query context. We repeated this procedure, sampling 100 different query contexts and computed the mean precision values. Finally, we report for each compared method, the average of the mean precision values for all 100 pseudo-words. Our pseudo-word dataset consists on average around 4.5 senses and 4,500 tagged contexts per pseudo-word. 3 5.2 Compared methods

All compared methods are unsupervised and use the plain text of ukWaC (Ferraresi et al., 2008), a two
Our pseudo-word dataset is available at: www.cs.biu. ac.il/nlp/resources/downloads/word2parvec/
3

475

