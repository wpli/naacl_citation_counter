its correct antecedent, we can rewrite P (l=1|e, k, c) as follows: P (e, k, c, l=1) P (l=1|e, k, c) =   c C P (e, k, c , l=1)

where Zx =


i

 i i P (fx |l=1)P (l=1)+ P (fx |l=0)P (l=0)
i

(1)

As we can see from Equation (1), to compute P (l=1|e, k, c), we need to compute P (e, k, c, l=1), which can be rewritten using Chain Rule: P (e, k, c, l=1) = P (e|k, c, l=1)  P (l=1|k, c)  P (c|k )  P (k ) (2) Next, given l = 1 (i.e., c is the antecedent of e), we assume that we can generate e from c without looking at the context. Using this assumption and approximating e and c by their trigger words, we can rewrite P (e|k, c, l=1) as follows: P (e|k, c, l=1)  P (et |ct , l=1) (3)

Moreover, we assume that (1) given e and c's context, the probability of c being the antecedent of e is not affected by the context of the other candidate antecedents; and (2) kc is sufficient for determining whether c is the antecedent of e. So, P (l=1|k, c)  P (l=1|kc , c)  P (l=1|kc ) (4)

Next, applying Bayes Rule to P (l=1|kc ), we get: P (kc |l=1)P (l=1) P (kc |l=1)P (l=1) + P (kc |l=0)P (l=0) (5)

1, . . . f n Representing kc as a set of n features fc c i and assuming that each fc is conditionally independent given l, we can approximate Expression (5) as: i P (l=1) i P (fc |l=1)  i i i P (fc |l=1)P (l=1) + i P (fc |l=0)P (l=0)





(6) Given Equations (2), (3), (4) and (6), we can rewrite P (l=1|e, k, c) as follows: P (l=1|e, k, c) =   P (e, k, c, l=1)  c C P (e, k, c , l=1)


(8) As we can see from Equation (7), our model has four groups of parameters, namely P (et |ct , l=1), i =1|l), P (l) and P (c|k ). With these four groups P (fc of parameters, we can apply Equation (7) to efficiently compute P (l=1|e, k, c). Two points deserve mention before we describe our M-step. First, among the four groups of parami |l) are estimated in the eters, P (et |ct , l=1) and P (fc M-step described below; P (l) is estimated in parameter initialization and used throughout the EM iterations (details on parameter initialization appear after the M-step); and P (c|k ) is computed heuristically. Intuitively, P (c|k ) is the prior probability of a candidate antecedent c given context k . The simplest way to model P (c|k ) is to assume that every candidate antecedent is equally likely given the context. In practice, however, some candidate antecedents are implausible given the context. To identify such candidate antecedents, we employ a simple heuristic, which considers a candidate antecedent implausible if its event subtype is different from that of e. Consequently, we model P (c|k ) as follows: if c is implausible, we set P (c|k ) to 0 and distribute the probability mass uniformly over all and only the plausible candidate antecedents. Since this heuristic is not applicable to dummy candidates, we assume for simplicity that they are all plausible. Second, by including d as a dummy candidate antecedent for each e, we model anaphoricity determination and event coreference in a joint fashion. If the model resolves e to d, it means that the model posits e as non-anaphoric; on the other hand, if the model resolves e to a non-dummy candidate antecedent c, it means that the model posits e as anaphoric and c as e's correct antecedent. This joint modeling method has proven effective in earlier work on supervised entity coreference resolution (e.g., Rahman and Ng (2009; 2011)). 4.2.2 M-Step Given P (l=1|e, k, c), the goal of the M-step is to (re)estimate two of the four groups of parameters mentioned above, namely P (et |ct , l=1) and i |l), using maximum likelihood estimation. P (fc

P (et |ct , l=1) 

c C

P (et |c t , l=1)

i i P (fc |l=1)  P (c|k ) Zc  i P (f |l=1)  P (c |k )  i Z c c

(7)

1100

