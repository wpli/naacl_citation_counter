Table 2: Accuracy of dataless classification using ESA and Dense-ESA with 500 dimensions.
Method ESA (Cosine) Dense-ESA (Average) Dense-ESA (Max) Dense-ESA (Hungarian) rec.autos vs. sci.electronics (easy) Full document Short (1/16 doc.) 87.75% 56.55% 87.80% 64.67% 87.10% 64.34% 88.85% 65.95% rec.autos vs. rec.motorcycles (difficult) Full document Short (1/16 doc.) 80.95% 46.64% 81.11% 59.38% 84.30% 59.11% 82.15% 59.65%

Figure 2: Boxplot of similarity scores for "rec.autos vs. sci.electronics" (easy, left) and "rec.autos vs. rec.motorcycles" (difficult, right). For each method of ESA and Dense-ESA with max matching in Eq. (3), we compute S (d, l1 ) and S (d, l2 ) between a document d and the labels l1 and l2 . Then we compute S (d) = S (d, l1 ) - S (d, l2 ). For each ground truth label, we draw the distribution of S (·) with outliers in the figures. For example, "ESA:autos" shows the S (·)'s distribution of the data with label "rec.autos." The t-test results show that the distributions of different labels are significantly different (99%). We can see that Dense-ESA pulls apart the distributions of different labels and that the separation is more significant for the more difficult problem (right).

baseline method. To demonstrate how the length of documents affects the classification result, we used both full documents and the 16 split parts (the parts are associated with the same label as the original document). To demonstrate the impact of densification, we selected two problems as an illustration: "rec.autos vs. sci.electronics" and "rec.autos vs. rec.motorcycles." While the former problem is relatively easy since they belong to different superclasses, the latter problem is more difficult since they are under the same super-class. The value of threshold  for max matching and Hungarian based densification is set to 0.85 empirically. Figure 1 shows the results of the dataless classification using ESA and ESA with densification (Dense-ESA) with different numbers of Wikipedia concepts as the representation dimensionality. We can see that Dense-ESA significantly improves the dataless classification results. As shown in Table 2, while the max matching and Hungarian matching based methods are typically the best metrics the most significant results, the improvements are more significant for shorter documents, and for more difficult problems. Figure 2 highlights this observation. 1278

Table 3: Spearman's correlation of document similarity using ESA and Dense-ESA with 500 concepts.
Method ESA (Cosine) Dense-ESA (Average) Dense-ESA (Max) Dense-ESA (Hungarian) Spearman's correlation 0.5665 0.5814 0.5888 0.6003

3.2

Document Similarity

We used the data set provided by Lee et al.2 (Lee et al., 2005) to evaluate pairwise short document similarity. There are 50 documents and the average number of words is 80.2. We averaged all the human annotations for the same document pair as the similarity score. After computing the scores for pairs of documents, we used Spearman's correlation to evaluate the results. Larger correlation score means that the similarity is more consistent with human annotation. The best word level based similarity result is close to 0.5 (Lee et al., 2005). We tried the cosine similarity between ESA representations and
2

http://faculty.sites.uci.edu/mdlee/similarity-data/

