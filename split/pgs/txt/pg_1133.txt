# Docs. Train Dev. Test

Ave. # Sents. Source Graph Summ. Doc. Nodes Edges Expand 298 1.5 17.5 127 188 2,670 35 1.4 19.2 143 220 3,203 33 1.4 20.5 162 255 4,002

person
name year

date-entity
month day

name
op1

"2002"

"4"

"8"

Table 1: Statistics of our dataset. "Expand" shows the number of edges after performing graph expansion. The numbers are averaged across all documents in the split. We use the official split, dropping one training document for which no summary sentences were annotated.

"Joe"

date-entity::year::"2002"::month::"4"::day::"8"

person::name::name::op1::"Joe"

Figure 2: Graph fragments are collapsed into a single concept and assigned a new concept label.

proxy report is created by annotators based on a single newswire article, selected from the English Gigaword corpus. The report header contains metadata about date, country, topic, and a short summary. The report body is generated by editing or rewriting the content of the newswire article to approximate the style of an analyst report. Hence this is a single document summarization task. All sentences are paired with gold-standard AMR annotations. Table 1 provides an overview of our dataset.

4

Graph Summarization

Given AMR graphs for all of the sentences in the input (step 1), graph summarization transforms them into a single summary AMR graph (step 2). This is accomplished in two stages: source graph construction (§4.1); and subgraph prediction (§4.2). 4.1 Source Graph Construction The "source graph" is a single graph constructed using the individual sentences' AMR graphs by merging identical concepts. In the AMR formalism, an entity or event is canonicalized and represented by a single graph fragment, regardless of how many times it is referred to in the sentence. This principle can be extended to multiple sentences, ideally resulting in a source graph with no redundancy. Because repeated mentions of a concept in the input can signal its importance, we will later encode the frequency of mentions as a feature used in subgraph prediction. Concept merging involves collapsing certain graph fragments into a single concept, then merging all concepts that have the same label. We collapse the graph fragments that are headed by either a dateentity ("date-entity") or a named entity ("name"), if 1079

the fragment is a flat structure. A collapsed named entity is further combined with its parent (e.g., "person") into one concept node if it is the only child of the parent. Two such graph fragments are illustrated in Fig. 2. We choose named and date entity concepts since they appear frequently, but most often refer to different entities (e.g., "April 8, 2002" vs. "Nov. 17"). No further collapsing is done. A collapsed graph fragment is assigned a new label by concatenating the consisting concept and edge labels. Each fragment that is collapsed into a new concept node can then only be merged with other identical fragments. This process won't recognize coreferent concepts like "Barack Obama" = "Obama" and "say-01" = "report-01," but future work may incorporate both entity coreference resolution and event coreference resolution, as concept nodes can represent either. Due to the concept merging step, a pair of concepts may now have multiple labeled edges between them. We merge all such edges between a given pair of concepts into a single unlabeled edge. We remember the two most common labels in such a group, which are used in the edge "Label" feature (Table 3). To ensure that the source graph is connected, we add a new "ROOT" node and connect it to every concept that was originally the root of a sentence graph (see Fig. 3). When we apply this procedure to the documents in our dataset (§3), source graphs contain 144 nodes and 221 edges on average. We investigated how well these automatically constructed source graphs cover the gold-standard summary graphs produced by AMR annotators. Ideally, a source graph should cover all of the goldstandard edges, so that summarization can be accomplished by selecting a subgraph of the source

