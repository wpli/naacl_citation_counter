frequencies for each lemma. We take into account the frequency of the words, because previous studies have shown that less frequent words were found to be more challenging for people with and without the most frequent reading disorder, that is, dyslexia (Rello et al., 2013b). Second, we use the 5-grams in the Google Books Ngram Corpus, where we use the third token of each 5-gram as our target words. The other tokens are the context of the target word. A context is considered valid if all words, including the target word, consist only of lowercase alphabetic characters, to filter for proper names, and is not a stop word, using a standard list of stop words in Spanish. The lemmatized token is included in the list of target words only if it appears in our List of Senses. The remaining four tokens are the context, kept in a context list. We count the frequency of the target word appearing with that context in the corpus, as well as the frequency of the same context appearing with different target words. See two possible contexts for noche and fortuna in the examples below:
era una noche oscura de (`it was a dark night of') de probar fortuna en el (`to try fortune in the')

Original Baseline LexSis CASSA

´ contemplaba en silencio aquella cruz. El He was contemplating in silence that cross. ´ ve´ El ia en silencio aquella cruz. He was seeing in silence that cross. ´ consideraba en silencio aquella cruz. El He was considering in silence that cross. ´ miraba en silencio aquella cruz. El He was looking in silence that cross.

Figure 1: Example of substitutions performed by the three algorithms.

line has been broadly used in previous lexical simplification studies (Burstein et al., 2007; Carroll et al., 1999; Devlin and Unthank, 2006; Lal and Ruger, 2002), with the exception of (Bott et al., 2012) that used word frequency and length. It is very hard to beat this baseline for simpler synonyms generation. For instance, in SemEval task for English lexical simplification (Specia et al., 2012), only one system out of nine outperformed the frequency baseline. For the complexity part we use the same as our new method. That is, both algorithms consider the same words as complex. LexSiS: replaces a word with the output of the state-of-the-art method for Spanish lexical simplification (Bott et al., 2012). 4.2 Frequency Bands

Third, we define the complexity of a word using the relative frequency of the synonyms within the same sense in the List of Senses. That is, our definition is tailored to web text. For this we use a parameter k such that if a word is k or more times less frequent than one or more of its synonyms, is considered a complex word. We used k = 10 as the default threshold to get that 27% of the words have simpler synonyms. We later show how this percentage changes with smaller k . Finally, for each complex word and the contexts it appears in, we select as simpler synonym the most frequent synonym of the sense that appears most frequently for the n-gram corresponding to that (word, context) pair. That is, to disambiguate the sense, our method uses the context where the target word appears. If the context is not found, we use the most frequent sense (baseline below).

We divided the selected complex words methods into two groups: [L OW ], that includes very low frequency complex words, and [H IGH ], that contains high frequency complex words. The word frequency ranges from 40 to 2,000 occurrences in Google Books Ngram Corpus for the [L OW ] group, and from 2,001 to 1,300,000 for the [H IGH ] group. 4.3 Evaluation Datasets

4
4.1

Quality Evaluation
Comparison Points

Baseline: replaces a word with its most frequent synonym (presumed to be the simplest). This base1382

Main dataset: From a set of texts of scientific and literature genres (37,876 words), we randomly selected 20 [L OW ] and 20 [H IGH ] complex words within the sentence they appear, together with their corresponding candidate for substitution generated by the Baseline, LexSiS, and ours (a valid sentence must had at least 2 different substitutions). We had in total 120 simplification examples (composed by an original and a simplified sentence). Figure 1

