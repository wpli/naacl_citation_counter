Method EM-HMM PostCAT-HMM ABA-HMM MIR-HMM EM-IBM4 MIR-IBM4

Chi-Eng Align F1 64.6 69.8 70.8 70.9 68.4 72.9

Cze-Eng Align F1 65.0 69.6 70.4 69.6 67.3 70.7

Method EM-HMM PostCAT-HMM MIR-HMM ABA-HMM EM-IBM4 MIR-IBM4 ABA + MIR-HMM

Chi-Eng NIST08 23.6 24.6 24.0 24.4 24.2 24.6 25.1

Cze-Eng WMT09 WMT10 16.7 17.1 16.9 17.4 17.1 17.6 17.1 17.7 16.8 17.2 17.2 17.5 17.4 17.9

Table 1: Word alignment F1 scores.

Table 2: Bleu scores. Combining ABA and MIR HMM alignments improves Bleu score significantly over all other methods.

Model 4. We then extracted symmetrized alignments in the following manner: For all HMM models, we used the posterior decoding technique described in Liang et al. (2006) as implemented by each package. For IBM Model 4, we used the standard grow-diag-final-and (gdfa) symmetrization heuristic (Koehn et al., 2003). We tuned MIR's  parameter to maximize alignment F-score on a validation set of 460 hand-aligned Czech-English and 1102 Chinese-English sentences. Alignment F-scores are reported in Table 1. In particular, the best results were obtained by MIR, when applied to the fertility based IBM4 model we obtained gains of +2.1% (Chinese-English) and +0.3% (Czech-English) compared to the best competitor. 5.4 MT Experiments

For example, by combining their HMM alignments (simply concatenating aligned bitexts) the total improvement reaches +1.5 Bleu on the Chinese-toEnglish task, a statistically significant improvement ( p < 0.05) according to a bootstrap resampling significance test (Koehn, 2004)). Table 5.4 summarizes our MT results.

6

Experiments without Parallel Data

We ran MT experiments using the Moses (Koehn et al., 2007) phrase-based translation system.6 The feature weights were trained discriminatively using MIRA (Chiang et al., 2008), and we used a 5-gram language model trained on the Xinhua portion of English Gigaword (LDC2007T07). All other parameters remained with their default settings. The development data used for discriminative training were: for Chinese-English, data from the NIST 2004 and NIST 2006 test sets; for Czech-English, 2051 sentences from the WMT 2010 shared task. We used case-insensitive IBM Bleu (closest reference length) as our metric. On both language pairs, ABA, PostCAT and MIR outperform their respective EM baseline with comparable gains overall. However, we noticed that ABA and MIR are not producing the same alignments.
6

Ravi and Knight (2009) consider the challenging task of learning a Japanese-English backtransliteration model without parallel data. The goal is to correctly decode a list of 100 US senator names written in katakana script, without having access to parallel data. In this section, we reproduce their decipherment experiment and show that applying MIR to their baseline model significantly outperforms both the baseline and the bi-EM method. 6.1 Phonetic-Based Japanese Decipherment

http://www.statmt.org/moses/

Ravi and Knight (2009) construct a English-toJapanese transliteration model as a cascade of wFSTs (depicted in Figure 1, top). According to their generative story, any word in katakana is generated by re-writing an English word in its English phonetic representation, which is then transformed to a Japanese phonetic representation and finally re-written in katakana script. For example, the word "computer" is mapped to a sequence of 8 English phonemes (k, ah, m, p, y, uw, t, er), which is mapped to a sequence of 9 Japanese phonemes (K, O, N, P, Y, U, T, A, A) and finally to Katakana. They apply their trained transliteration model to decode a list of 100 US senator names and report a

614

