the algorithm returns the maximum similarity score of one (lines 1-3). 2. If the words are not defined as synonyms, we proceed by obtaining, for each word wi , its set of possible senses (Cwi , lines 5-11). We accordingly obtain the set of their respective NASARI vector representations (Vi , lines 13-17), two (word-based and synset-based) for each concept in Cwi . Section 3.2.2 describes the concept extraction process. 3. Finally, the algorithm returns the similarity score Sim (line 19), calculated as the similarity of the closest senses of w1 and w2 . In our default setting, we linearly combine our two vector representations by averaging them (line 18). 3.2.1 Wiktionary synonyms S

3.2.2 Concept extraction If the two input words w1 and w2 are not found in the same synonym set in S , we proceed by obtaining their sets of senses Cw1 and Cw2 , respectively. Depending on the type of wi , we use two different resources for obtaining Cwi : the WordNet sense inventory and Wikipedia. WordNet words. When the word wi is defined in the WordNet sense inventory and is not a named entity (line 6 in Algorithm 1), we set Cwi as all the WordNet synsets that contain wi , i.e., Cwi = {synset s  WordNet : wi  s}. We use Stanford Named Entity Recognizer (Finkel et al., 2005) in our experiments. WordNet OOV and named entities. For named entities and words that do not exist in WordNet's vocabulary (OOV) we construct the set Cwi by exploiting Wikipedia's piped links (line 10 in Algorithm 1). To this end, we take as elements of Cwi the Wikipedia pages of the hyperlinks which have wi as their surface form, i.e., piped-links (wi ). If |Cwi | > 5, we prune Cwi to its top-5 pages in terms of their number of ingoing links. Our choice of Wikipedia as a source for named entities is due to its higher coverage in comparison to WordNet.

Wiktionary is a rich collaboratively-constructed lexical resource that provides a considerable amount of multilingual lexical information for a large number of words. We use this resource in order to obtain sets of synonymous words S . To this end, we first extract all the pre-specified synonymy relations in the English Wiktionary. This results in 17K sets with an average size of 2.8 synonyms. In order to enrich the set we introduce a method that exploits the multilinguality of Wiktionary to extract synonymous words. Our approach utilizes translations of words in other languages as bridges between synonymous words in English. Specifically, for each sense s of word w in Wiktionary, we first get all the available translations. Assume that the sense s of w translates into the word tl in language l. If there is another word sense s of another word w in Wiktionary that is also translated to tl in language l, we hypothesize that w and w are synonyms. In order to avoid ambiguity, as tl we only consider words that are monosemous according to language l. This procedure results in around 9K additional synonymous sets with an average size of 2.1. For instance, the Finnish noun ammatti, which is monosemous according to Wiktionary, links seven English words into a single set of synonyms: career, business, profession, occupation, trade, calling, and vocation. The final synonym set collection S contains 25K sets, each having, on average, 2.6 words. 571

4

Experiments

We evaluated NASARI on two different tasks that require the computation of semantic similarity between words or concepts: word similarity (Section 4.1) and sense clustering (Section 4.2). 4.1 Word similarity 4.1.1 Datasets We took as benchmark for our word similarity experiments three standard datasets that are widely used in the literature: RG-65 (Rubenstein and Goodenough, 1965), MC-30 (Miller and Charles, 1991), and WordSim-353 (Finkelstein et al., 2002; Agirre et al., 2009). WordSim-353 originally conflated similarity and relatedness, leading to high similarity scores for pairs such as computer-keyboard despite the dissimilarity in their meanings. To correct the conflation, Agirre et al. (2009) partitioned the dataset into two subsets: relatedness and similarity. Given that our similarity measure is targeted at semantic similarity, we took the similarity subset of

