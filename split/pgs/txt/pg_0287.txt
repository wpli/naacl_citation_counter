narrative of the previous one, and creates artificial question-answer pairs from all pairs of consecutive sentences. Thus, this model takes advantage of intersentence cohesion by aligning the content words3 in each sentence with the content words in the following sentence. For example, in the passage in Figure 1, this model would associate cider in the first sentence with apples and orchard in the second sentence. The second model uses RST to capture discourse cohesion both within and across sentence boundaries. We extracted RST discourse structures using an in-house parser (Surdeanu et al., 2015), which follows the architecture introduced by Hernault et al. (2010) and Feng and Hirst (2012). The parser first segments text into elementary discourse units (EDUs), which may be at sub-sentence granularity, then recursively connects neighboring units with binary discourse relations, such as Elaboration or Contrast.4 Our parser differs from previous work with respect to feature generation in that we implement all features that rely on syntax using solely dependency syntax. For example, a crucial feature used by the parser is the dominance relations of Soricut and Marcu (2003), which capture syntactic dominance between discourse units located in the same sentence. While originally these dominance relations were implemented using constituent syntax, we provide an equivalent implementation that relies on dependency syntax. The main advantage to this approach is speed: the resulting parser performs at least an order of magnitude faster than the parser of Feng and Hirst (2012). Importantly, we generate artificial alignment pairs from this imposed structure by aligning the governing text (nucleus) with its dependent text (satellite).5 Turning again to the example in Figure 1, this RSTbased model captures additional alignments that are both intrasentence, e.g., apples­orchard, and intersentence, e.g., cider­autumn.
In pilot experiments, we found that aligning only nouns, verbs, adjectives, and adverbs yielded higher performance. 4 The RST parser performs better on relations which occur more frequently. We use only relations that occurred at least 1% of the time. This amounted to six relations: elaboration, attribution, background, contrast, same-unit, and joint. Using all relations slightly improves performance by 0.3% P@1. 5 Pilot experiments showed that this direction of alignment performed better than aligning from satellite to nucleus.
3

4

Models and Features

We evaluate the contribution of these alignment models using a standard reranking architecture (Jansen et al., 2014). The initial ranking of candidate answers is done using a shallow candidate retrieval (CR) component.6 Then, these answers are reranked using a more expressive model that incorporates alignment features alongside the CR score. As a learning framework we use SVMrank , a Support Vector Machine tailored for ranking.7 We compare this alignment-based reranking model against one that uses a state-of-the-art recurrent neural network language model (RNNLM) (Mikolov et al., 2010; Mikolov et al., 2013), which has been successfully applied to QA previously (Yih et al., 2013). Alignment Model: The alignment matrices were generated with IBM Model 1 (Brown et al., 1993) using GIZA++ (Och and Ney, 2003), and the corresponding models were implemented as per Surdeanu et al. (2011) with a global alignment probability. We extend this alignment model with features from Fried et al. (In press) that treat each (source) word's probability distribution (over destination words) in the alignment matrix as a distributed semantic representation, and make use the Jensen-Shannon distance (JSD)8 between these conditional distributions. A summary of all these features is shown in Table 1. RNNLM: We learned word embeddings using the word2vec RNNLM of Mikolov et al. (2013), and include the cosine similarity-based features described in Table 1.

5

Experiments

We tested our approach in two different domains, open-domain and cellular biology. For consistency we use the same corpora as Jansen et al. (2014), which are described briefly here. Yahoo! Answers (YA): Ten thousand open-domain how questions were randomly chosen from the YaWe use the same cosine similarity between question and answer lemmas as Jansen et al. (2014), weighted using tf.idf. 7 http://www.cs.cornell.edu/people/tj/ svm_light/svm_rank.html 8 Jensen-Shannon distance is based on Kullback-Liebler divergence but is a distance metric (finite and symmetric).
6

233

