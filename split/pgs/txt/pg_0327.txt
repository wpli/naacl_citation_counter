intended to refer to, has been well-studied in various fields such as psychology (Isaacs and Clark, 1987; Tanenhaus and Spivey-Knowlton, 1995), linguistics (Pineda and Garza, 2000), as well as human/human (Iida et al., 2010) and human/machine interaction (Prasov and Chai, 2010; Siebert and Schlangen, 2008; Schlangen et al., 2009). In recent years, multi-modal corpora have emerged which provide RR with important contextual information: collecting dialogue between two humans (Tokunaga et al., 2012; Spanger et al., 2012), between a human and a (simulated) dialogue system (Kousidis et al., 2013; Liu et al., 2013), with gaze, information about the shared environment, and in some cases deixis. It has been shown that incorporating gaze improves RR in a situated setting because speakers need to look at and distinguish from distractors the objects they are describing: this has been shown in a static scene on a computer screen (Prasov and Chai, 2008), in human-human interactive puzzle tasks (Iida et al., 2010; Iida et al., 2011), in web browsing (Hakkani-t¨ ur et al., 2014), and in a moving car where speakers look at objects in their vicinity (Misu et al., 2014). Incorporating pointing (deictic) gestures is also potentially useful in situated RR; as for example Matuszek et al. (2014) have shown in work on resolving objects processed by computer vision techniques. Chen and Eugenio (2012) looked into reference in multi-modal settings, with focus on co-referential pronouns and pointing gestures. However, these approaches were applied in settings in which communication between the two interlocutors was constrained, or the developed systems did not process incrementally. Kehler (2000) presented approach that focused more on interaction in a map task, though the model was not incremental, nor did grounding occur between language and world, as we do here. Incremental RR has also been studied in a number of papers, including a framework for fast incremental interpretation (Schuler et al., 2009), a Bayesian filtering model approach that was sensitive to disfluencies (Schlangen et al., 2009), a model that used Markov Logic Networks to resolve objects on a screen (Kennington and Schlangen, 2013), a model of RR and incremental feedback (Traum et al., 2012), and an approach that used a semantic representation to refer to objects (Peldszus et al., 2012; 273

Kennington et al., 2014). However, the approaches reported there did not incorporate multi-modal information, were too slow to work in real-time, were evaluated on constrained data, or only focused on a specific type of RR, ignoring pronouns or deixis. In this paper, we opted to use the model presented in Kennington et al. (2013), the simple incremental update model (SIUM). It has been tested extensively against data from a puzzle-playing human/computer interaction domain (the PENTO data, (Kousidis et al., 2013)); it can incorporate multi-modal information, works in real-time, and can resolve definite, exophoric, and deictic references in a single framework, all of which makes it a potential candidate for working in an interactive, multi-modal dialogue system. The model is similar to the one proposed in Funakoshi et al. (2012), which could resolve descriptions, anaphora, and deixis in a unified manner, but that model does not work incrementally.1 The main contributions of this paper are the more thorough exposition of the model (in Section 3) and its application and evaluation on much less constrained, more interactive (and hence realistic) data than what it has previously been tested on (Section 4). Moreover, the data set used here is also from a typologically very different language (Japanese) than what the model has been previously tested on (German), and so the robustness of the model against these differences is also investigated. We will now describe the model, and that will be followed by a description of the corpus we used.

3

The Simple Incremental Update Model

Following Kennington et al. (2013) and Kennington et al. (2014), we model the task at hand as one of recovering I , the intention of the speaker making the RE, where I ranges over the possible alternatives (the objects in the domain). This recovery proceeds incrementally (word by word), for RE of arbitrary length. That is, if U denotes the current word, we are interested in P (I |U ), the current hypothesis about
It can be argued that any non-incremental model could be made into an incremental one by applying that model at each word (Khouzaimi et al., 2014), but we would argue that more modeling effort is required in order for the model to work in an interactive dialogue system, see (Schlangen and Skantze, 2009; Aist et al., 2007; Skantze and Schlangen, 2009; Skantze and Hjalmarsson, 1991).
1

