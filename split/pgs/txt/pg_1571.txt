pairs, which, to the best of our knowledge, is 2.4 times the size of the largest training set reported in previous work (1.66M sentences in (Simianer et al., 2012)). This proves the scalability of our approach. 4. On two large scale tasks our experiments show good improvements over strong baselines which include recurrent language modeling components. On the ChineseEnglish DARPA BOLT task, we achieve nearly twice the improvement reported in (Setiawan and Zhou, 2013) on the same test sets which results in a superior final system. Finally, the best single system reported on matrix.statmt.org is outperformed by 0.8 B LEU points on the WMT GermanEnglish newstest2013 set. Our experiments also prove that leave-one-out impacts translation quality. This paper is organized as follows. We review related work in Section 2 and present the translation system in Section 3. In Section 4 we describe the different discriminative update strategies applied in this work and Section 5 derives the complete maximum expected B LEU training algorithm. Finally, experimental results are given in Section 6 and we conclude with Section 7.

2

Related Work

Discriminative training is one of the most active research areas in SMT and it can be integrated into the pipeline at various stages. Och (2003) proposed to apply minimum error rate training (MERT) to optimize the different feature weights in the log-linear model combination on a small development data set. This is still considered to be the state of the art, but is only capable of optimizing a handful of features. More recently, MIRA (Watanabe et al., 2007; Chiang et al., 2008) and PRO (Hopkins and May, 2011) have been presented as optimization procedures that can replace MERT and scale to thousands of parameters. In a different line of work, Liang et al. (2006) describe a fully discriminative training pipeline, where more than one million features are tuned on the training data using a perceptron-style update algorithm. The Direct Translation Model 2 introduced 1517

by Ittycheriah and Roukos (2007) is similar in that it also trains millions of features on the training data. However, the weights are estimated based on a maximum entropy model and the underlying translation paradigm differs from the standard phrasebased model. Gao and He (2013) use gradient ascent to train Markov random field models for phrase translation. These models are interpreted as undirected phrase compatibility scores rather than translation probabilities. Thus, as in our work, they are not subject to a sum-to-one constraint. Simianer et al. (2012) propose a distributed setup for large-scale discriminative training with joint feature selection. The training corpus is divided into several shards, on which features are updated via perceptron-style gradient descent. The authors present results showing that training on large data sets improves results over just using a small development corpus. Another approach based on the AdaGrad method that scales to large numbers of sparse features is proposed in (Green et al., 2013; Green et al., 2014). Different from our work, the authors use either the tuning sets or a small subsample of the training data (15k sentences) for discriminative training. A notably different idea is pursued by Yu et al. (2013), who present a large-scale training procedure that explicitly minimizes search errors. This is achieved by force-decoding the training data and updating at the point where the correct derivation drops off the beam. In (Blunsom et al., 2008), conditional random fields (CRFs) are trained within a hierarchical phrase-based translation framework. The hierarchical phrase-based paradigm is used to model the search space in model estimation and search, leaving the hypothesis weighting to CRF features. They constrain search by a beam width for gradient estimation and update the model with the help of LBFGS. In a similar way Lavergne et al. (2011) use the n-gram based approach (Casacuberta and Vidal, 2004; Mari~ no et al., 2006) to model the reordering, phrase alignment, and the language model. A CRF is applied to estimate the phrase weights. Model updates are carried out by the RPROP algorithm (Riedmiller and Braun, 1993). However, both approaches only improve over constrained baselines. Our work is inspired by (He and Deng, 2012; Setiawan and Zhou, 2013), where the authors propose to

