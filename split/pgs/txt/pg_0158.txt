et al., 2014; Kim, 2014). Notably, in many of these CNN studies on text, the first layer of the network converts words in sentences to word vectors by table lookup. The word vectors are either trained as part of CNN training, or fixed to those learned by some other method (e.g., word2vec (Mikolov et al., 2013)) from an additional large corpus. The latter is a form of semi-supervised learning, which we study elsewhere. We are interested in the effectiveness of CNN itself without aid of additional resources; therefore, word vectors should be trained as part of network training if word vector lookup is to be done. A question arises, however, whether word vector lookup in a purely supervised setting is really useful for text categorization. The essence of convolution layers is to convert text regions of a fixed size (e.g., "am so happy" with size 3) to feature vectors, as described later. In that sense, a word vector learning layer is a special (and unusual) case of convolution layer with region size one. Why is size one appropriate if bi-grams are more discriminating than unigrams? Hence, we take a different approach. We directly apply CNN to high-dimensional one-hot vectors; i.e., we directly learn embedding1 of text regions without going through word embedding learning. This approach is made possible by solving the computational issue2 through efficient handling of high-dimensional sparse data on GPU, and it turned out to have the merits of improving accuracy with fast training/prediction and simplifying the system (fewer hyper-parameters to tune). Our CNN code for text is publicly available on the internet3 . We study the effectiveness of CNN on text categorization and explain why CNN is suitable for the task. Two types of CNN are tested: seq-CNN is a straightforward adaptation of CNN from image to text, and bow-CNN is a simple but new variation of CNN that employs bag-of-word conversion in the convolution layer. The experiments show that seqCNN outperforms bow-CNN on sentiment classiWe use the term `embedding' loosely to mean a structurepreserving function, in particular, a function that generates lowdimensional features that preserve the predictive structure. 2 CNN implemented for image would not handle sparse data efficiently, and without efficient handling of sparse data, convolution over high-dimensional one-hot vectors would be computationally infeasible. 3 riejohnson.com/cnn_download.html
1

Output

[0010000000] Output layer (Linear classifier) Pooling layer Convolution layer Pooling layer Convolution layer

Input

Figure 1: Convolutional neural network.

Figure 2: Convolution layer for image. Each computation

unit (oval) computes a non-linear function  (W · r (x) + b) of a small region r (x) of input image x, where weight matrix W and bias vector b are shared by all the units in the same layer.

fication, vice versa on topic classification, and the winner generally outperforms the conventional bagof-n-gram vector-based methods, as well as previous CNN models for text which are more complex. In particular, to our knowledge, this is the first work that has successfully used word order to improve topic classification performance. A simple extension that combines multiple convolution layers (thus combining multiple types of text region embedding) leads to further improvement. Through empirical analysis, we will show that CNN can make effective use of high-order n-grams when conventional methods fail.

2

CNN for document classification

We first review CNN applied to image data and then discuss the application of CNN to document classification tasks to introduce seq-CNN and bow-CNN. 2.1 Preliminary: CNN for image CNN is a feed-forward neural network with convolution layers interleaved with pooling layers, as illustrated in Figure 1, where the top layer performs classification using the features generated by the layers below. A convolution layer consists of several computation units, each of which takes as input a region vector that represents a small region of the input image and applies a non-linear function to it. Typically, the region vector is a concatenation of pixels in the region, which would be, for example,

104

