Solving Hard Coreference Problems
Haoruo Peng and Daniel Khashabi and Dan Roth University of Illinois, Urbana-Champaign Urbana, IL, 61801 {hpeng7,khashab2,danr}@illinois.edu

Abstract
Coreference resolution is a key problem in natural language understanding that still escapes reliable solutions. One fundamental difficulty has been that of resolving instances involving pronouns since they often require deep language understanding and use of background knowledge. In this paper we propose an algorithmic solution that involves a new representation for the knowledge required to address hard coreference problems, along with a constrained optimization framework that uses this knowledge in coreference decision making. Our representation, Predicate Schemas, is instantiated with knowledge acquired in an unsupervised way, and is compiled automatically into constraints that impact the coreference decision. We present a general coreference resolution system that significantly improves state-of-the-art performance on hard, Winograd-style, pronoun resolution cases, while still performing at the stateof-the-art level on standard coreference resolution datasets.

1

Introduction

text. Existing methods perform particularly poorly on pronouns, specifically when gender or plurality information cannot help. In this paper, we aim to improve coreference resolution by addressing these hard problems. Consider the following examples: Ex.1 [A bird]e1 perched on the [limb]e2 and [it]pro bent. Ex.2 [Robert]e1 was robbed by [Kevin]e2 , and [he]pro is arrested by police. In both examples, one cannot resolve the pronouns based on only gender or plurality information. Recently, Rahman and Ng (2012) gathered a dataset containing 1886 sentences of such challenging pronoun resolution problems (referred to later as the Winograd dataset, following Winograd (1972) and Levesque et al. (2011)). As an indication to the difficulty of these instances, we note that a state-ofthe-art coreference resolution system (Chang et al., 2013) achieves precision of 53.26% on it. A special purpose classifier (Rahman and Ng, 2012) trained on this data set achieves 73.05%. The key contribution of this paper is a general purpose, state-of-theart coreference approach which, at the same time, achieves precision of 76.76% on these hard cases. Addressing these hard coreference problems requires significant amounts of background knowledge, along with an inference paradigm that can make use of it in supporting the coreference decision. Specifically, in Ex.1 one needs to know that "a limb bends" is more likely than "a bird bends". In Ex.2 one needs to know that the subject of the verb "rob" is more likely to be the object of "arrest" than the object of the verb "rob" is. The knowledge required is, naturally, centered around

Coreference resolution is one of the most important tasks in Natural Language Processing (NLP). Although there is a plethora of works on this task (Soon et al., 2001a; Ng and Cardie, 2002a; Ng, 2004; Bengtson and Roth, 2008; Pradhan et al., 2012; Kummerfeld and Klein, 2013; Chang et al., 2013), it is still deemed an unsolved problem due to intricate and ambiguous nature of natural language


These authors contributed equally to this work.

809
Human Language Technologies: The 2015 Annual Conference of the North American Chapter of the ACL, pages 809­819, Denver, Colorado, May 31 ­ June 5, 2015. c 2015 Association for Computational Linguistics

