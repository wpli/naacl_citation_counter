syntactically motivated grammars yielded promising results. Thus, using weak supervision in the form of perceptual context information appears to be beneficial for detecting semantic classes compared to working with raw text. An interesting point for future work might be to explore whether using semantic groupings induced by our algorithm in a classbased model yields reasonable results, in particular when applied as a back-off model in combination with a semantically motivated recognition grammar. Further, we have also investigated weighting rules for semantically meaningful lexical units, i.e. in this example the probability for the occurrence of players like "pink nine" and "pink seven" can be increased according to their occurrence frequencies, thus making recognizing them more likely. Our results indicate that by weighting semantically meaningful sequences, performance is improved, possibly because more words carrying semantics are recognized correctly, even though words carrying no semantics like "forward" or "backward" might be confused, which, however, may not prevent correct parsing. In general, while in SLU research mainly cascading systems are explored, in line with previous work (Wang et al., 2003; Bayer and Riccardi, 2012), our results indicate that joint models yield improved parsing performance, even though word recognition performance may decrease. Yet, our results indicate that a combination of a semantic grammar with a standard trigram model during speech recognition can also reduce the word error rate in some cases compared to applying the trigram model only. Furthermore, the results emphasize that capturing semantic information in a language model applied during ASR is beneficial for subsequent semantic parsing, since the ASR can be tuned towards recognizing words carrying semantics more precisely, which is important with respect to parsing performance.

results indicate that by applying the same semantically motivated grammar learned with weak supervision for both recognition and parsing, speech can be parsed into formal meaning representations with a rather low loss in performance compared to parsing of data without recognition errors, that is, textual data or manual transcriptions of speech. An improvement in parsing performance was obtained over a cascading approach in which a standard ngram model is used, and we have shown how learning weights for grammatical rules applied in speech recognition can yield improved subsequent parsing results compared to applying unweighted grammars.

Acknowledgments
This work has been funded by the DFG within the CRC 673 and the Cognitive Interaction Technology Excellence Center.

References
Ali Orkan Bayer and Giuseppe Riccardi. 2012. Joint language models for automatic speech recognition and understanding. In Proceedings of the IEEE/ACL Workshop on Spoken Language Technology (SLT). Benjamin B¨ orschinger, Bevan K. Jones, and Mark Johnson. 2011. Reducing grounded learning tasks to grammatical inference. In Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing (EMNLP). David L. Chen and Raymond J. Mooney. 2008. Learning to sportscast: A test of grounded language acquisition. In Proceedings of the 25th International Conference on Machine Learning (ICML). David L. Chen, Joohyun Kim, and Raymond J. Mooney. 2010. Training a multilingual sportscaster: Using perceptual context to learn language. Journal of Artificial Intelligence Research, 37(1):397­435. Renato De Mori, 2011. History of Knowledge and Processes for Spoken Language Understanding, pages 11­40. John Wiley & Sons. Anoop Deoras, Gokhan Tur, Ruhi Sarikaya, and Dilek Hakkani-Tur. 2013. Joint discriminative decoding of words and semantic tags for spoken language understanding. IEEE Transactions on Audio, Speech and Language Processing. Marco Dinarelli, Alessandro Moschitti, and Giuseppe Riccardi. 2012. Discriminative reranking for spoken language understanding. IEEE Transactions on Audio Speech and Language Processing, 20(2):526­539.

6

Conclusion

This work investigated the induction of semantic grammars applicable for both speech recognition and understanding in a weakly supervised setting, i.e. using ambiguous context information. In doing so, we compared parsing the output of speech recognizers applied with different language models. Our

880

