infoboxes are filtered out, thus yielding four models: Full English Wikipedia ­ CBOW(FW-CBOW), Full English Wikipedia ­ Skip-gram(FW-SG), Simple English Wikipedia ­ CBOW(SW-CBOW) and Simple English Wikipedia ­ Skip-gram(SWSG). The pre-trained Google News skip-gram model with 300-dimensional vectors (GN-SG) is also downloaded from the Google word2vec website for comparison. This model is trained on the Google News dataset with 100 billion words, which is 30 times as large as the full English Wikipedia and 240 times as large as Simple English Wikipedia.

5

Results

Table 1 shows the accuracy rate at every recall rate point, with the sum of all the accuracy rates as the cumulative score. It is shown that GN-SG, although not far behind, is not giving the best performance despite being trained on the largest dataset. In fact, it is clear that it never excels at any given recall rate point. It outperforms various models at certain recall rate points by a small margin, but there is no obvious advantage gained from training using a much larger corpus even when compared with the models trained on Simple English Wikipedia, despite the greater risk of sparse data problems on this smaller data set. For models trained on Simple English Wikipedia and full English Wikipedia, it is also interesting to see that the models almost perform equally well. The FW-CBOW trained on full English Wikipedia performs the best among the models overall, but for the first few recall rate points, it performs equally well or slightly worse than either SWCBOW or SW-SG trained on Simple English Wikipedia. At the later points, it is also clear that although FW-CBOW is generally better than all the other models most of the time, the margin could be considered narrow and furthermore it is equally as good as SW-CBOW at the first two recall points.
Model   FW-CBOW   SW-CBOW   FW-SG   SW-SG   GN-SG   10%   Recall   Rate   0.91   0.91   0.91   0.91   0.85   20%   Recall   Rate   0.95   0.95   0.95   0.95   0.84   30%   Recall   Rate   0.89   0.78   0.79   0.91   0.82   40%   Recall   Rate   0.83   0.75   0.75   0.70   0.79   50%   Recall   Rate   0.72   0.72   0.63   0.62   0.70  

Comparing FW-SG with SW-SG and SWCBOW, there is almost no sign of performance gain from training using full Wikipedia instead of the much smaller Simple Wikipedia. FW-SG performs equally well or often slightly worse than both Simple Wikipedia models. The main observation in this paper is that Google News is not out-performing other systems substantially and that full Wikipedia systems are not out-performing Simple Wikipedia substantially (that is, comparing the CBOW models to one another and the Skip-gram models to one another). The main result from the table is not that smaller training datasets yield better systems, but that systems trained using significantly smaller training datasets of explanatory text have very close performances in this task compared with systems trained on very large datasets, despite the big training data size difference.

6

Analysis

As mentioned previously, similarity may be better predicted by a context-window model because it measures functional or syntactic similarity. However, it is not clear in these models that the syntactic information is a major component in the word embeddings. Instead, it may be that the main factor for the performance level of the models is the general explanatory content of the Wikipedia articles, as opposed to the current events content of Google News. For similar words such as synonyms or hyponyms, the crucial information making them similar is shared general semantic features of the words. For example, for the word pair physics : chemistry, the shared semantic features might be that they are both academic subjects, both studied in institutions and both composed of different subfields, as shown in Table 2. The `@' sign in table 2 connects a context word with its position relative to the word in the center of the window. These shared properties
60%   Recall   Rate   0.74   0.70   0.61   0.57   0.64   70%   Recall   Rate   0.61   0.56   0.53   0.54   0.57   80%   Recall   Rate   0.51   0.50   0.49   0.45   0.48   90%   Recall   Rate   0.46   0.46   0.43   0.42   0.43   100%   Recall   Rate   0.40   0.40   0.40   0.40   0.40   Cumulative   Score   7.03   6.74   6.50   6.47   6.51  

Table 1: Performance of Different Models at Different Recall Rate Points

992

