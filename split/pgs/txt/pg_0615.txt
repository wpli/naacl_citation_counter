are probability of correctness of algorithms A, B ^A ,  ^B are observed empirical accuracies. and  Unfortunately there are no widely reported traintest splits of the above datasets, leading to potential concerns of soft supervision (hyper-parameter tuning) on these evaluations, both in our own work and throughout the existing literature. We report on the resulting impact of various parameterizations, and our final results are based on a single set of parameters used across all evaluation sets.

Test Set MEN RW SCWS AN-SYN AN-SEM

6.25K 70.2 41.8 67.1 59.2 37.7

12.5K 71.2 41.7 67.3 60.0 38.6

25K 71.5 41.5 67.1 59.5 39.4

50K 71.6 40.9 67.0 58.4 39.2

100K 71.2 39.6 66.9 56.1 38.4

200K 70.7 37.8 66.6 53.6 38.7

Table 4: Performance versus the truncation threshold, t, 1 of raw cooccurrence counts. We used nj = Count 4 and other settings were the same as Table 3.

5

Experiments and Results

We wanted to answer the following questions through our experiments: (1) How do hyperparameters affect performance? (2) What is the contribution of the multiple sources of data to performance? (3) How does the performance of MVLSA compare with other methods? For brevity we show tuning runs only on the larger datasets. We also highlight the top performing configurations in bold 0.09 of using the small threshold values in column 0 .05 Table 2. Effect of Hyper-parameters fj : We modeled the preprocessing function fj as the composition of two functions, fj = nj  tj . nj represents nonlinear preprocessing that is usually employed with LSA. We experimented by setting nj to be: identity; logarithm of count plus one; and the fourth root of the count. tj represents the truncation of columns and can be interpreted as a type of regularization of the raw counts themselves through which we prune away the noisy contexts. Decrease in tj also reduces the influence of views that have a large number of context columns and emphasizes the sparser views. Table 3 and Table 4 show the results. Test Set MEN RW SCWS AN-SYN AN-SEM Log 67.5 31.1 64.2 45.7 25.4 Count 59.7 25.3 58.2 21.1 15.9 Count 4 70.7 37.8 66.6 53.6 38.7
1

m: The number of left singular vectors extracted after SVD of the preprocessed cooccurrence matrices can again be interpreted as a type of regularization, since the result of this truncation is that we find cooccurrence patterns only between the top left singular vectors. We set mj = max(dj , m) with m = [100, 300, 500]. See table 5. Test Set MEN RW SCWS AN-SYN AN-SEM 100 65.6 34.6 64.2 50.5 24.3 200 68.5 36.0 65.4 56.2 31.4 300 70.1 37.2 66.4 56.4 34.3 500 71.1 37.1 66.5 56.4 40.6

Table 5: Performance versus m, the number of left singular vectors extracted from raw cooccurrence counts. We 1 set nj = Count 4 , t = 100K, v = 25, k = 300.

k : Table 6 demonstrates the variation in performance versus the dimensionality of the learnt vector representations of the words. Since the dimensions of the MVLSA representations are orthogonal to each other therefore creating lower dimensional representations is a trivial matrix slicing operation and does not require retraining. Test Set MEN RW SCWS AN-SYN AN-SEM 10 49.0 28.8 57.8 9.0 2.5 50 67.0 33.3 64.4 41.2 21.8 100 69.7 35.0 65.2 52.2 34.8 200 70.2 35.2 66.1 55.4 35.8 300 70.1 37.2 66.4 56.4 34.3 500 69.8 38.3 65.1 54.4 33.8

Table 3: Performance versus nj , the non linear processing of cooccurrence counts. t = 200K, m = 500, v = 16, k = 300. All the top configurations determined by 0.09 0 .05 are in bold font.

Table 6: Performance versus k , the final dimensionality of the embeddings. We set m = 300 and other settings were same as Table 5.

v : Expression 12 describes a method to set Wj . We experimented with a different, more global,

561

