... the very essence or heart of being a coach . c ... the very essence or heart of being a . sc christian, non-smoker, traitor, grandparent pu coach, bus, train, boat pu,c coach, teacher, writer, manager Table 2: The substitute vector sc for context c, the out-ofcontext paraphrase vector pu for the word type u = coach, and the in-context paraphrase vector pu,c for u in context c, as learned by our model. Only the first few vector entries (weights omitted) are shown. sc , pu and pu,c are defined formally in sections 4.1 and 4.2.

Q: the transcendental meditation people advertised this: meditation can fix many sicknesses. substitutes relieve, circumvent, alleviate Rsub : use the results of your analysis to suggest design changes that would fix these problems. substitutes overcome, solve, alleviate Rcbow : fix in your mind a picture of heavenly worship that is real and eternal. substitutes echoing, send, stick Table 3: Example for a context of the word fix, Q, and the two contexts of fix, Rsub and Rcbow , most similar to it, based on substitute vector and CBOW similarity, respectively. The substitute vectors are illustrated below each context (selected substitutes in the top-10 entries shown).

a substitute vector similarity measure. Intuitively, with this weighting scheme, we wish to consider mostly the word type contexts that induce a sense similar to that of the given word instance, under the premise that similar contexts induce similar word senses. The resulting word representation is biased towards the given context on one hand due to the context weighting scheme, and is bounded to the target word type spectrum of meanings on the other hand as only contexts of that word type are taken into consideration. Table 2 exemplifies a context substitute vector and both out-of-context and in-context word representations learned by our model for a word instance. It is evident in this case that our in-context representation comprises suitable paraphrases in contrast to the out-of-context representation. We evaluate these word representations quantitatively in Section 6. We next describe our model in more detail. 4.1 Context representation

similarity function (Bullinaria and Levy, 2007): sc [v ] = P P M I (c, v ) = max(0, P M I (c, v )) (1) sim(c, c ) = cos(sc , sc ) (2) where sc [v ] is the fitness weight for word v in the substitute vector of context c, PMI is point-wise mutual information (Church and Hanks, 1990), and sim(c, c ) is our context similarity measure. We note that a context c in our setting stands for an entire word window rather than a single context word. We therefore follow Yatbaz et al. (2012) using an n-gram language model to estimate P M I (c, v ), as detailed in Section 5. Table 3 illustrates an example of a given context and the contexts most similar to it, as retrieved by our substitute vector and continuous bag-of-words context similarity measures. It is evident in this case that our measure correlates with the induced senses better than the bag-of-words measure. We suggest this context similarity measure as a standalone contribution, which may be useful in other settings as well. We evaluate it quantitatively in Section 5. 4.2 Modeling word meaning Word meaning out-of-context We first define our out-of-context representation for target word type u, as an average of the substitute vectors of its contexts: pu = 1 |Cu | si
iCu

We wish the context representation in our model to be optimized for measuring context similarity, which is typically used to bias in-context word representations towards a given context. For the purpose of measuring similarity between contexts, we consider in this section the contexts as `targets'. Accordingly, we observe that the substitute vector of a word window context c can be considered as a vector of first-order co-occurrence features of c, as it consists of slot filler words that are likely to co-occur with this context. Hence, we follow prior work and propose to use Positive PMI (PPMI) as our substitute vector feature weights, instead of the conditional probabilities used by Yatbaz et al. (2012), and vector Cosine as our context 474

(3)

where Cu is a collection of the contexts observed for target word type u in a learning corpus, and si are their substitute vectors.

