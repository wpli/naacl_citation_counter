5.1.2

Using Logical rules on Regular Expression output and Sentence constituents

One example of the rules we use to detect "Command" is: if the subject of the verb is second person and the verb is associated with a modal verb which indicates a question that suggests command, then the LI "Command" is detected. Examples of such verbs are "Would you" and "Could you" etc. It is to be noted that such a verb will denote both politeness and command depending on the rest of the sentence. This fascinating inter-dependency is one reason why we have to collect all such Language Indicators before we infer the higher level Language Uses.

5.2

Mapping of LIs to LUs and LUs to Social Constructs

Input: To encode one conversation we use a collection of facts of the form participant(X) and addresses(X, Y, LI, Level). These facts essentially encode the identity of the participants and the Language Indicators observed in the overall conversation among a pair of participants. Output: The module outputs a collection of claim, evidence and confidence mappings. For example one such mapping is: claim_mapping(X, "is the leader", "because", X, "demonstrates <language use>","(Confidence: <confidence level>)"). Here <language use> is one of the language uses, <confidence level> is either low, medium, or high. Algorithm: We employ statistical and logic-based procedure in parallel to get the above output. On the statistical side, we adopt a regression technique to learn a function that can map the scores associated with LI s to individual LUs based on annotated training data and this function is then applied to test data to get confidence score on LU s. The same procedure is adopted for mapping LU s to SCs. In parallel to this procedure, we also employ a rulebased technique that uses quantized confidence scores and outputs confidence levels along with explanations. As we are able to get the explanation from logical reasoning, we use the output confidence scores as votes from statistical learning to output the final confidence level. The rules for logical reasoning are explained as definitions and intuitions in the following paragraphs. Mapping LIs into LUs: A signed LU is said to be exhibited by participant X towards participant Y with a certain degree of confidence based on the number of indicators(LI ) and counter-indicators(LI ) of the signed LU used by X when addressing Y. The confidence in LU is directly proportional to the difference between the number of indicators and counter-indicators.

We categorize LU s according to the number of indicators and apply slight variation to the above rules for each such category. Also, there are a few LI s that, when used, automatically override the computed confidence level for an LU and increase it to high. For example, "criticism" increases confidence level of positive "motivational behavior" to high. Mapping LUs to SCs: The relative status of two participants is determined based on i) the number of relevant signed LUs exhibited by each participant towards the other, ii) the ordering of relevant signed LUs and iii) the confidence level in each exhibited signed LU. The leader is determined based on the number of exhibited relevant LUs (both favorable and unfavorable). Mapping LIs to SCs: As shown in Figure 1, we directly associate some of the LIs to Social Constructs. For such an association, we again adopt the regression technique mentioned previously. In this case, the confidence scores from LI s are directly mapped to the confidence scores of SCs. We combine this confidence with the above confidence levels using simplistic rules to output final social constructs. It should be noted that the constants used in the rules are obtained from statistics on annotated conversations. The annotation process involves labels about SCs, LUs and LIs for each conversation data.

5.3

Brief Details and Results of the Regression Technique

In this sub-section, we provide few details of the Sparse Logistic Regression technique we have used alongside the logical formulation and present few results from our experiments with relevant statistical methods. We have used a similar formulations for mapping LIs to LUs and LUs to SCs. Here, we provide the example of formulating the entire problem of detection of Social Constructs directly in the Classification paradigm. Status and Leadership can be formulated as a threeclass and two-class problem respectively. For Status, we had 102 samples with the 38(higher), 26(equal) and 38(lower) samples each for three classes. For Leadership, we had 149 samples with 108(not-leader) and 41(leader) samples for the two classes. For both the tasks, we extracted 28 textual features. We used the one-vs-rest scheme for multi-class problem. For each task, we evaluated the framework as follows: i. First, we randomly separate the dataset into training set(p) and test set(1-p). ii. In the training set, we use 10-fold cross validation to select proper parameters. iii. We iterate the above procedure for 100 times, and accuracy is evaluated on the predictions in all iterations. iv. We select different p (from 0.25 to 0.9) and observe the change of accuracy. We compared the accuracy achieved using Sparse Logistic Regression with SVM(with RBF Kernel) among

1296

