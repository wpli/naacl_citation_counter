tion according to a bigram model in the discriminative learning. While some of this information is implicitly found in the lexical features, collecting frequency counts from a large training set is much quicker than running costly structured optimization. Rather the discriminative training can weigh the different empirical probabilities according to their discriminative power. Indeed we find that these features are important in practice and can result in high accuracy even after training on a small training set.

the argument. Argument indices are determined by their order in the text. The order of events is taken to be the order of their verbs in the text. Linkage Extraction. We focus on a subset of linkage relations, which are relevant for temporal relations. We use Pitler and Nenkova's (2009) explicit discourse connectives classifier to identify temporal discourse linkers, discarding all other discourse linkers. Once a discourse linker has been detected, we heuristically extract its arguments (namely the pair of verbs it links) according to a deterministic extraction rule defined over the parse tree. We find 28 distinct connectives in our training set, where the 5 most common linkers "until," "then," "before," "when" and "as" cover over 95% of the instances. We extract 36756 such linkages from the corpus, 0.5 linkages per recipe on average. Temporal and Textual Ordering. In order to confirm that temporal and textual order of recipes are generally in agreement, we manually examine the first 20 recipes in our development set. One recipe was excluded as noise6 , resulting in 19 recipes and 353 events. We identify the sources of misalignment between the linear order and the temporal order of the events.7 13 events (3.7%) did not have any clear temporal orderings. These consisted of mostly negations and modalities (e.g., "do not overbrown!"), sub-section headings (e.g., "Preparation") or other general statements that do not constitute actions or states. For the remaining 340 events, we compare their linear and the temporal orderings. We estimate the frequency of sub-sequences that contradict the temporal order and confirm that they occur only infrequently. We find that most disagreements fall into these two categories: (1) disjunctions between several events, only one of which will actually take place (e.g., "roll Springerle pin over dough, or press mold into top"); (2) a pair, or less commonly a triplet, of events are expressed in reverse order. For instance, "place on greased and floured cookie sheet," where greasing and flouring should occur before the placing action. We note that assuming the alignment of the temporal and textual order
This did not result from an extraction problem, but rather from the recipe text itself being too noisy to interpret. 7 Events are parsed manually so to avoid confounding the results with the parser's performance.
6

6

The Recipe Dataset

Data and Preprocessing. The data is extracted from a recipe repository found on the web.3 The recipes are given as free text. To extract event types we run the Stanford CoreNLP4 pipeline of a tokenizer, POS tagger, a lexical constituency parser (the englishPCFG parsing model) and extract typed Stanford dependencies (de Marneffe and Manning, 2008). As is common with web extractions, the recipes contain occasional spelling, grammatical and formatting errors. The corpus consists of 139 files, 73484 recipes, 1.02M events (13.8 events per recipe on average) and 11.05M words.5 Event Extraction. We focus on verbal events and do not extract nominal and adjectival argument structures, which are not as well supported by current parsing technology. Any verb is taken to define an event, aside from modal verbs, auxiliaries and secondary verbs. A secondary verb (e.g., "let," "begin") does not describe an action in its own right, but rather modifies an event introduced by another verb. We identify these verbs heuristically using a list given in Dixon (2005, p. 490­491) and a few simple rules defined over parse trees. E.g., from the sentence "you should begin to chop the onion," we extract a single event with a predicate "chop." Arguments are taken to be the immediate dependents of the predicate that have an argument dependency type (such as direct or indirect objects) according to the extracted Stanford dependencies. For prepositional phrases, we include the preposition as part of
3 4 5 http://www.ffts.com/recipes.htm http://nlp.stanford.edu/software/corenlp.shtml

Links to the original recipes, the preprocessed recipes and all extracted events can be found in http://homepages. inf.ed.ac.uk/oabend/event_order.html.

1166

