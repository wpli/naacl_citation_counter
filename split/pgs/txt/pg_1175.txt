Evidence

Sparse Training Matrix |R| Facts First-order Formulae

Low-rank Logic Embeddings k |P| k |R|

Completed Matrix |R|

|P| KB

|P|

x, y : co-founder-of(x, y )  company/founders(y, x) x, y : review-by(x, y )  author/works written(y, x) x, y : daughter-of(x, y )  person/parents(x, y )

Figure 1: Injecting Logic into Matrix Factorization: Given a sparse binary matrix consisting of observed facts over

entity-pairs P and predicates/relations R, matrix factorization is used to learn k -dimensional relation and entity-pair embeddings that approximate the observed matrix. In this paper we use additional first-order logic formulae over entities and relations to learn the embeddings such that the predictions (completed matrix) also satisfy these formulae.

3

Injecting Logic Into Factorization

Matrix factorization is capable of learning complex dependencies between relations, but requires observed facts as training signal. However, often we either do not have this signal because the relations of interest do not have pre-existing facts, or this signal is noisy due to alignment errors or mismatches when linking knowledge base entities to mentions in text. To overcome this problem we investigate the use of first-order logic background knowledge (e.g. implications) to aid relation extraction. One option is to rely on a fully symbolic approach that exclusively uses first-order logic (Bos and Markert, 2005; Baader et al., 2007; Bos, 2008). In this case incorporating additional background knowledge is trivial. However, it is difficult to generalize and deal with noise and uncertainty in language when relying only on manual rules. In contrast, matrix factorization methods can overcome these shortcomings, but it is not clear how they can be combined with logic formulae. In this section, we propose to inject formulae into the embeddings of relations and entity-pairs, i.e., estimate the embeddings such that predictions based on them conform to given logic formulae (see Figure 1 for an overview). We refer to such embeddings as low-rank logic embeddings. Akin to matrix factorization, inference of a fact at test time still amounts to an efficient dot product of the corresponding relation and entity-pair embeddings, and logical inference is not needed. We present two techniques for injecting logical background knowledge, pre-factorization

inference (§3.1) and joint optimization (§3.2), and demonstrate in subsequent sections that they generalize better than direct logical inference, even if such inference is performed on the predictions of the matrix factorization model. 3.1 Pre-Factorization Inference Background knowledge in form of first-order formulae can be seen as hints that can be used to generate additional training data (Abu-Mostafa, 1990). For pre-factorization inference we first perform logical inference on the training data and add inferred facts as additional training data. For example, for a formula F = x, y : rs (x, y )  rt (x, y ), we add an additional observed cell rt (x, y ) for any (x, y ) for which rs (x, y ) is observed in the distant supervision training data. This is repeated until no further facts can be inferred. Subsequently, we run matrix factorization on the extended set of observed cells. The intuition is that the additional training data generated by the formulae provide evidence of the logical dependencies between relations to the matrix factorization model, while at the same time allowing the factorization to generalize to unobserved facts and to deal with ambiguity and noise in the data. No further logical inference is performed during or after training of the factorization model as we expect that the learned embeddings encode the given formulae. 3.2 Joint Optimization One drawback of pre-factorization inference is that the formulae are enforced only on observed atoms,

1121

