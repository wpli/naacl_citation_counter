Figure 2: Average Recall Performance across all Reports from a 1,000 document subset of the ACL Anthology

Figure 3: Average Recall Performance across all reports from the full ACL Anthology

al., 2013) ­ the current state-of-the-art system. Due to the slow running time of PMTLM, we restricted our preliminary experiment to just 1,000 documents of the ACL Anthology, and Figure 2 shows the average recall performance across all reports. Surprisingly, PMTLM performed worst. Note: the authors of PMTLM compared their system to LinkLDA for a different task (predicting research area) but did not compare to LinkLDA during their analysis of citation prediction performance. Thus, it was not previously asserted that PMTLM would outperform LinkLDA. As we can see, LDA-Bayes, despite being simple, performs well. As mentioned, LDA-Bayes explicitly captures the prior probability of each source being cited (via maximum-likelihood estimate), whereas LinkLDA and PMTLM approximates this during inference. We believe this contributes towards the performance differences. It was expected that when run on the entire ACL corpus, WSIC and our Logic-Expanded systems would have sufficient data to learn authors' citing preferences and would outperform the other generative models. As shown in Figure 3 and 4, our flagship Logit-Expanded system greatly outperformed all other systems, while our baseline LDA-Bayes continued to offer strong results. Note, the full recall performance results include returning 12,265 sources, but we only show the performance for returning the first 200 returned sources. Further, Table 4 shows the same experimental results but for the performance when returning just the first 50 pre80

dicted sources per report.
Table 4: Performance of each system, averaged across all reports while returning the top 50 predicted sources for each. 125 topics were used for every system.
Logit-Expanded LDA-Bayes WSIC LinkLDA LDA-Bayes (uniform prior) recall .647 .496 .442 .431 .309 precision .016 .012 .011 .011 .007 fscore .031 .024 .021 .021 .014

Again, we further see how effective it is to have a model influenced by a source's prior probability, for when we change LDA-Bayes such that P (SourceCited) is uniform for all sources, performance falls greatly ­ represented as LDA (uniform prior). We analyzed the benefits of each feature of LogitExpanded in 2 ways: (1) starting with the fullfeature set experiment (whose results we showed), we evaluate each feature by running an experiment whereby the said feature is removed; and (2) starting with our LDA-Bayes baseline as the only feature for our Logit-Expanded system, we evaluate each feature by running an experiment whereby the said feature is paired with LDA-Bayes as the only two features used. For both of these approaches, we measure performance by looking at recall, precision, and f-score when returning the first 50 predicted sources. The results are shown in Table 5; technique (1) is shown in column removal, and (2)

