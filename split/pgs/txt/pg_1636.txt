0.7 Cumulative Relative Frequency 0.6 0.5 0.4 0.3 0.2 0.1 0 0 2 4 6 8 10 Rank 12 BCF BayesCat Strudel 14 16 18 20

journey move hundred current reproduce BCF salmon tuna goldfish BayesCat fish radio goldfish Strudel train house apartment finger BCF BayesCat Strudel avoid cut quick claw tent ski peg eye ear spider finger toe hair

salmon

mile strong lobster fish salmon clock ship car tip painful curtain hut leg hair tail hand

Figure 4: Number of times the correct target concept was placed within the top 20 ranks by BCF, BayesCat, and Strudel.

Table 3: Model output on the concept prediction task for salmon (top) and finger (bottom): the top part of each table shows the true concept (left) and the context provided to the model as input (right). The bottom part of the table shows the five most highly ranked concepts (left to right) for each model. prediction task harder. Example output for all three models is shown in Table 3. The models take context features "journey move hundred mile strong " and "avoid cut quick claw tip " as input and are expected to predict salmon and finger, respectively. Unlike Strudel, BCF and BayesCat rank salmon almost correctly and the other high ranked concepts are reasonable in the given context as well. For the second example, only Strudel predicts the correct concept correctly, but again the top-ranked concepts of the other two models are reasonable in the given context. 4.3 Experiment 3: Evaluation of Feature Types

perform comparably given that they learn from exactly the same data and exploit local co-occurrence relations in similar ways. BayesCat produces better average rank scores than BCF, while achieving lower precision scores. This can be explained by the fact that BCF assigns low ranks to correct concepts more reliably than BayesCat. Figure 4 shows the relative cumulative frequencies of the ranks assigned by the three models. We display the top ranks 1 through 20 (out of 492). As can be seen, BCF performs slightly better than BayesCat. Pairwise differences between the systems are all statistically significant (p 0.01); using a one-way ANOVA with post-hoc Tukey HSD test). Note that performance decreases for the Bayesian models in the -tgt condition, i.e., when occurrences of the target concept are removed from the context. Strudel is less affected by this given its pattern-based learning mechanism which is not prone to associating target word types with themselves. However, repetitions are a natural phenomenon from a cognitive standpoint and it seems reasonable to consider multiple occurrences of a concept as a canonical feature of the learning environment. Overall, the precision scores may seem low. However, the models rank a set of 492 target concepts; a random baseline would achieve a pr@1 of only 0.002%. In addition, the target concepts we are considering are by design highly confusable: they were selected so that they form categories and are thus bound to share some features which makes the 1582

In this suite of experiments we evaluate two aspects of the feature types induced by our model: (1) Are they relevant to their associated category? and (2) Do they form a coherent class? Our evaluation followed the intrusion paradigm originally introduced to assess the output of topic models (Chang et al., 2009). We performed two intrusion studies using Amazon's Mechanical Turk crowd-sourcing platform. In the feature intrusion study, participants were shown examples of categories and their feature types both of which were represented as word clusters (see Figure 6 top). They were asked to detect the feature type which did not belong to the category. If a model creates relevant feature types, we would expect participants to be able to identify the intruder relatively easily. We also conducted a word intrusion

