tmod subj dobj prep

prep pobj det amod

pobj

John Smith married Mary Brown in Baltimore yesterday after a long courtship person person location
Figure 1: Example sentence, and extraction (the nodes connected through solid dependency edges).
subj dobj

 married  person person
Figure 2: Example pattern that encodes a wedding event between two people.

news articles published on the same day, and involving the same set of entities.  Two extractions are co-occurrent if there is at least one EEC that contains both of them. N EWS S PIKE produces extractions from the input documents using R E V ERB (Fader et al., 2011). The EECs are generated from the titles and all the sentences of the first paragraph of the documents published on the same day. From each EEC, potentially one paraphrase cluster may be generated. The model is a factor graph that captures several additional heuristics. Integer Lineal Programming (ILP) is then used to find the Maximum a Posteriori (MAP) solution for each set of patterns, and model parameters are trained using a labeled corpus that contains 500 of these sets. Regarding H EADY, it only considers titles and first sentences for pattern extraction and trains a two-layer Noisy-OR Bayesian Network, in which the hidden nodes represent possible event types, and the observed nodes represent the textual patterns. A maximum-likelihood model is the one in which highly co-occurring patterns are generated by the same latent events. The output is a global soft clustering, in which two patterns may also be clustered together even if they never co-occur in any EEC, as long as there is a chain of co-occurring patterns generated by the same hidden node. H EADY was evaluated using three different extraction methods: a heuristic-based pattern extractor, a sentence compression algorithm and a memory-based method. While this model produces a soft clustering of patterns, H EADY was evaluated only on a headline generation task and not intrinsically w.r.t. the quality of the clustering itself. Neural networks and distributed representations Another related field aims to learn continuous vector representations for various abstraction levels of

dated e2 , which can be observed involving the same pairs of entities, but which carry a different meaning. As discussed below, relying on the temporal dimension (given by the publication date of the input documents) is one way to overcome this problem. Event patterns and Open-IE Although some earlier work uses the temporal dimension of text as filters to improve precision of relational pattern clusters, N EWS S PIKE (Zhang & Weld, 2013) and H EADY (Alfonseca et al., 2013; Pighin et al., 2014) fully rely on it as its main supervision signal. In order to compare the two approaches, we will start by defining some terms:  An event pattern encodes an expression that describes an event. It can be either a linear surface pattern or a lexico-syntactic pattern, and can possibly include entity-type restrictions on the arguments. For example, Figure 2 represents a binary pattern that corresponds to a wedding event between two people.  An extraction is a pattern instance obtained from an input sentence, involving specific entities. For example, the subgraph represented with solid dependency edges in Figure 1 is an extraction corresponding to the pattern in Figure 2.  An Extracted Event Candidate Set (EECSet (Zhang & Weld, 2013), or just EEC for brevity) is the set of extractions obtained from 1142

