ble 3). Results are higher (0.65) with during instances than with before and after instances (0.41 and 0.45). These results are intuitive: certain events such as press and write require participants to be located where the event occurs only during the event. 5.1 Feature Ablation and Detailed Results

The weighted F-measure using lexical features is the same than with the most frequent per temporal anchor baseline (0.50). F-measures go up with before (0.21 vs. 0.32, 52.38%) and after (0.28 vs. 0.47, 67.85%) instances, but slightly down with during instances (0.65 vs. 0.63, -3.08%). Complementing lexical features with syntactic and semantic features brings the overall weighted Fmeasure slightly up: 0.53 with syntactic and 0.52 with semantic features (+0.03 and +0.02, 6% and 4%). Before instances benefit the most from syntactic features (0.32 vs. 0.41, 28.13%), and after instances benefit from semantic features (0.47 vs. 0.49, 4.26%). During instances do not benefit from semantic features, and only gain 0.01 F-measure (1.59%) with syntactic features. Finally, combining lexical, syntactic and semantic features obtains the best overall results (weighted F-measure: 0.55 vs. 0.53 and 0.52, 3.77% and 5.77%). We note, however, that before instances do not benefit from including semantic features (same F-measure, 0.41), and the best results for after instances are obtained with lexical and semantic features (0.49 vs. 0.45, 8.16%),

ments appearing in the same or previous sentences; posterior work obtained better results for the same task (Gerber and Chai, 2012; Laparra and Rigau, 2013). The SemEval-2010 Task 10: Linking Events and their Participants in Discourse (Ruppenhofer et al., 2009) targeted cross-sentence missing numbered arguments in PropBank and FrameNet. We have previously proposed an unsupervised framework to compose semantic relations out of previously extracted relations (Blanco and Moldovan, 2011; Blanco and Moldovan, 2014a), and a supervised approach to infer additional argument modifiers (ARGM) for verbs in PropBank (Blanco and Moldovan, 2014b). Unlike the current work, these previous efforts (1) improve the semantic representation of verbal and nominal predicates, or (2) infer relations between arguments of the same predicate. None of them target temporally-anchored spatial knowledge or account for uncertainty. Attaching temporal information to semantic relations is uncommon. In the context of the TAC KBP temporal slot filling track (Garrido et al., 2012; Surdeanu, 2013), relations common in information extraction (e.g., SPOUSE, COUNTRY OF RESIDENCY) are assigned a temporal interval indicating when they hold. The task proved very difficult, and the best system achieved 48% of human performance. Unlike this line of work, the approach presented in this paper starts from semantic role representations, targets temporally-anchored LOCATION relations, and accounts for degrees of uncertainty (certYES / certNO vs. probYES / probNO). The task of spatial role labeling (Haji c et al., 2009; Kolomiyets et al., 2013) aims at thoroughly representing spatial information with so-called spatial roles, i.e., trajector, landmark, spatial and motion indicators, path, direction, distance, and spatial relations. Unlike us, the task does not consider temporal spans nor certainty. But as the examples throughout this paper show, doing so is useful because (1) spatial information for most objects changes over time, and (2) humans sometimes can only state that an object is probably located somewhere. In contrast to this task, we infer temporally-anchored spatial knowledge as humans intuitively understand it, and purposely avoid following any formalism.

6 Related Work
Tools to extract the PropBank semantic roles we infer from have been studied for years (Carreras and M` arquez, 2005; Haji c et al., 2009; Lang and Lapata, 2010). These systems only extract semantic links between predicates and their arguments, not between arguments of predicates. In contrast, this paper complements semantic role representations with spatial knowledge for numbered arguments. There have been several proposals to extract semantic links not annotated in well-known corpora such as PropBank (Palmer et al., 2005), FrameNet (Baker et al., 1998) or NomBank (Meyers et al., 2004). Gerber and Chai (2010) augment NomBank annotations with additional numbered argu459

