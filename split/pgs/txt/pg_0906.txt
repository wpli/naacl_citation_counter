cepts, such as metal to iron (line U4 in Figure 1) ­ that increase its confidence in the user's answer. Relation extraction systems such as NELL (Carlson et al., 2010) use ontologies to predetermine valid relation types and arguments, then scan text to fill the ontology with facts. Open Information Extraction (Etzioni et al., 2011) avoids fixed ontologies with domain-independent linguistic features, distant supervision, and redundancy, but requires web-scale text and doesn't improve with interaction. Like Open IE, we extract relations without predetermined types, but are the first to do so from dialog. K NOWBOT is an open dialog system, which means a user utterance may progress the dialog task even if its underlying action is not explicitly represented in a dialog model. This lets K NOWBOT quickly bootstrap domain knowledge from users without significant engineering overhead. Dialogdriven extraction produces effective relations without annotation, improves after each interaction, acquires relations useful on a particular task, and embeds relations in a rich dialog context. Users successfully correct the system in approximately 50% of dialogs even without a predetermined dialog model. A baseline query expansion (Bast et al., 2007) strategy that bases decisions on the acquisition of new keywords instead of new relations results in only a 5% success rate. In comparison to paraphrase relations from general knowledge bases, relations acquired by our method are more effective as domain knowledge, demonstrating that we successfully learn from real users. Our contributions include: 1. The first end-to-end system to construct knowledge graphs for question-answering through conversational dialog. 2. A generalizable method to represent the meaning of user utterances without a dialog model when task progression can be computed as a function of extracted relations. 3. A novel data set of real user dialogs in which users correct a QA system's answer, together with knowledge graphs representing the important concepts and relations in each question, labeled with rich dialog features. 852

2

Conversational extraction for QA

Our QA task consists of 107 science questions from the 4th grade New York Regents exam (Clark et al., 2014).1 Each question has four possible answers. We convert each of the four question-answer pairs into a true/false question-answer statement using a small number of pattern-based transformation rules. Just as 4th graders read their textbooks for answers, we collect S CITEXT (Clark et al., 2014), a corpus of unlabeled true-false natural language sentences from science textbooks, study guides, and Wikipedia Science. Each question-answer statement is associated with a subset of true/false support sentences from S CITEXT based on positive word overlap between the question-answer pair and the support sentence. The degree to which a S CITEXT sentence supports a question-answer pair is the sentence's alignment score (section 2.3). Initially, the alignment score depends on keyword overlap alone, but S CITEXT needs domain knowledge to answer our questions. For example, the correct question-answer statement to What form of energy causes an ice cube to melt? (A) mechanical (B) magnetic (C) sound (D) heat is Q(D) , "Heat is a form of energy and heat causes an ice cube to melt." To better align Q(D) to the S CITEXT sentence "A snowball melting in your hand is an example of heat energy," we need to know that snowballs are made of ice. Figure 2 illustrates this example. To construct a knowledge base with which to use S CITEXT, we extract concepts (section 2.1) from questions and S CITEXT sentences, then use relations (section 2.2) between concepts to determine which question-answer statement Qi is most highly aligned with a supporting S CITEXT sentence. 2.1 Concepts A concept keyword in a sentence or user utterance is any non-stopword of at least three characters. Stopwords are domain-independent, lowinformation words such as "the." A concept is a set of concept keywords with a common root, e.g. {melts, melted, melting} or {heat, heats, heated}. We use the Porter algorithm for stemming (Porter, 1997). Question concepts ap1 Our dialogs, extractions, and tools are available at www.cs.washington.edu/research/nlp/knowbot

