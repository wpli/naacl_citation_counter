4.2

RPROP

The resilient backpropagation algorithm (RPROP) proposed by Riedmiller and Braun (1993) is a gradient-based optimization algorithm that emprirically learns the step size without taking the slope into account, making it highly robust and avoiding the need for a learning rate. If the gradient switches algebraic sign compared to the previous iteration, the last step is reverted and the step size reduced. If the sign remains the same, the step size is increased. Formally, given a set of parameters  and an objective function O(), in iteration t each parameter    is updated according to  (t-1) (t)  (t-1) , if  ·  < 0    (t) + (t) , else if (t) > 0 (t+1)   = (t) - (t) , else if (t) < 0       (t) , else
) where  := O( denotes the derivative of the  objective function. The step size (t) > 0 grows or decreases depending on the sign of the gradient:  + (t-1) , if (t-1) · (t) > 0   ·    (t-1) (t) (t) =  - · (t-1) , if  ·  < 0   (t-1)  , else (t)
(t)

their update step based on the slope of the gradient, which we believe to be misleading given the complex topology of the feature space in MT.

5
5.1

Training
Maximum Expected B LEU

Following (He and Deng, 2012), we want to optimize a maximum expected B LEU objective. We denote the universe of possible sentences in the source language as F and in the target language as E. The expected B LEU score under parameter set  with respect to the joint probability distribution p (·, ·) is defined as 


=
F F E E

p (E, F ) (E )

(6)

Here,  (E ) is the B LEU score for target sentence E (assuming the reference translation to be part of the mapping  ) and we use the notation · to denote the expectation. Enumerating all possible source and target sentences F , E is infeasible. Therefore, we estimate the empirical expectation on a corpus C  E × F. We denote the source sentences in C as CF and the size of the corpus as N = |C|. The joint probability p (E, F ) is decomposed with the help of the Bayes Theorem, resulting in: 


The strength parameters 0 <  - < 1   + usually have little impact and are fixed to  - = 0.5 and  + = 1.2 throughout this work. The RPROP algorithm is simple and easy to implement. It has proven effective for a number of tasks, e.g. in (Wiesler et al., 2013; Heigold et al., 2011; Lavergne et al., 2011; Hahn et al., 2011). Different from growth transformation (cf. Sec. 4.1), it does not assume a probability distribution and performs its updates without a sum-to-one constraint. Compared to SGD and AdaGrad, RPROP's practical advantage is the absence of a learning rate that needs to be tuned. Further, we see its theoretical advantage in the empirically learned step size. In the first iterations, RPROP's updates are considerably smaller than with the other strategies, resulting in a more careful exploration of the search space. In higher iterations, the update steps for good features keep growing and we observe an exponential increase of the objective function. In contrast, GT, SGD, and AdaGrad determine the size of 1519

=
F CF

p(F )
E E (F )

p (E |F ) (E )

(7)

F For p(F ) = N N we assume the empirical distribution within the training corpus, where NF is the count of sentence F . The summation over all E  E is sampled with a subset E (F ) of the most likely hypotheses with respect to the parameterized probability p (E, F ), which in practice is an n-best list generated by the decoder. Iterating over the corpus C = {(E1 , F1 ), . . . , (En , Fn ), . . . , (EN , FN )} finally results in





1 = N

N

p (E |Fn ) (E )
n=1 E E (Fn )

We use the same unclipped sentence-level B LEU-4 score with smoothed 3-gram and 4-gram precisions as in (He and Deng, 2012), which we denote as  ) with respect to the reference  (E ) = B LEU(E, En  translation En .

