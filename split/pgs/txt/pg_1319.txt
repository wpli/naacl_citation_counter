4

Evaluation

Two experiments are reported in this paper: comparing the MDS methods and tuning the density threshold. For both experiments, we use the DUC2004(task 2)1 dataset, which is annotated manually for generic MDS. We adopted ROUGE (Lin, 2004) version 1.5.52 and take F-measure of ROUGE-1, ROUGE-2 and ROUGE-SU as our evaluation metrics. In pre-processing, we use the Porter Stemmer3 in sentence segmenting, stop-word removing and word stemming. Note that our MDS method is purely unsupervised, and uses no training or development data. 4.1 The MDS Methods

Table 1: Experimental results of the MDS methods on DUC04. System ROUGE-1 ROUGE-2 ROUGE-SU DUC04Best 0.38224 0.09216 0.13233 Centroid 0.36728 0.07379 0.12511 ClusterHITS 0.36463 0.07632 ­ SNMF ­ 0.08400 0.12660 RTC 0.37475 0.08973 ­ FGB 0.38724 0.08115 0.12957 AASum 0.41150 0.09340 0.13760 LexRank 0.37842 0.08572 0.13097 CSFO 0.38900 ­ ­ WCS 0.39872 0.09611 0.13532 DPSC 0.39075 0.09376 0.14000

We selected three categories of baselines4 : (1) DUC04 MDS methods: DUC04Best (Conroy et al., 2004). (2) Clustering-based MDS methods: Centroid (Radev et al., 2004), ClusterHITS (Wan and Yang, 2008), SNMF (Wang et al., 2008), RTC (Cai and Li, 2013), FGB (Wang et al., 2011), and AASum (Canhasi and Kononenko, 2013). (3) Other state-of-the-art MDS methods: LexRank (graph-based method) (Erkan and Radev, 2004), CSFO (optimization-oriented method) (Lin and Bilmes, 2011) and WCS (aggregation-oriented method) (Wang and Li, 2012). For our DPSC method, we adopt the following settings: (1) Density threshold is set 0.22 as it is empirically found as optimal in Section 4.2 in the DUC04 dataset. (2) Term weighting scheme is set Boolean. In our experiments, Boolean is found outperforming tf and tfisf in sentence representation, this is because term repetition happens less frequently in short text units like sentences than that in documents. Experimental results of the MDS methods are presented in Table 1. Note the ROUGE values of some MDS methods are not reported in the literatures and marked with - in Table 1. According to Table 1, DPSC outperforms DUC04Best, which ignores the cross-sentence information to solve the diversity problem. DPSC
1 2

outperforms most clustering-based methods except for AASum, which performs slightly better than DPSC on ROUGE-1. AASum is a very complex MDS method which fully exploits the advantages of clustering and the flexibility of matrix factorization. A weakness of the approach is that the number of archetypes must be predefined, and a postprocessing module is required to reduce redundancy (Canhasi and Kononenko, 2013). DPSC also outperforms LexRank and CSFO, and yields close results compared with WCS. According to Table 1, DPSC performs slightly worse than WCS. The marginal performance gain of WCS comes from the aggregation strategy, namely, multiple MDS systems are required. As a comparison, DPSC is a pure and simple MDS method, exhibiting much lower complexity. DPSC method is also advantageous on usability, because it does not involve any external resources such as Wordnet and Wikipedia or very complex natural language processing algorithms such as sentence parsing. Moreover, DPSC is a very fast MDS method. Thus it can be easily reproduced and deployed in real environment. 4.2 Density Threshold Following (Rodriguez and Laio, 2014), we design an experiment on DUC04 dataset to investigate how the density threshold influences quality of the summaries. We tune the density threshold by varying it from 0.10 to 0.40(see the X-axis in Figure 1). Figure 1 shows that on the specific dataset (i.e., DUC04), DPSC reaches the best ROUGE score

http://duc.nist.gov/duc2004/tasks.html Options used: -a -c 95 -b 665 -m -n 4 -w 1.2 3 http://tartarus.org/martin/PorterStemmer/ 4 Interested readers can refer to details in the references.

1265

