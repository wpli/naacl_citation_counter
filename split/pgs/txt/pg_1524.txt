prior. We compare our proposed method "Co" to four different baselines that also use solely a bilingual dictionary. For all methods (baselines and proposed), we use Equation (2) to estimate the expected word frequencies. The baseline "Wu et al." refers to the method proposed in (Wu et al., 2008). The baseline "Freq" sets the probability p(e|f ) to be proportional to the word frequency in the training data. Analogously, the baseline "Uniform" assumes a uniform probability over all translations of f . For measuring the performance of each text classifier we use precision and recall. The break-even point9 and the f1-measure of our proposed method and all baselines are shown in Table 1. As can be seen, our method performs favorable for the NEWS and TWEETS corpora. For the WEB corpora pair and our proposed method is at par with the baseline "Wu et al.", and looses slightly to the "Uniform" baseline. For reference, we also show the upper bounds "CN/JA only" and "EN only" that train and test in the same source and target language, respectively.10 We also analyzed the contribution of using the word translation probabilities learned in Section 3.2. The method "Co (freq)" is the same as our proposed method, except that the translation probabilities p(f |e) are not estimated using the method described in Section 3.2, but instead simply uses the word-frequency distribution. Analogously, the method "Co (uni)" is the same as our proposed method, except that p(f |e) is set to the uniform probability for all translations of e. Limiting the discussion to break-even points, we see, in Table 1, an improvement of around 2 percent points for NEWS, but only minor changes in performance for the other two corpora (WEB and TWEETS). Finally, we give an example which shows the translation probabilities for the word (restrict, restrain, custody) for two different source documents in NEWS. The first source document F1 reports a military action, and is labeled as "foreign policy". The second document F2 is a news article about terror, and is labeled as "not foreign policy". The results shown in Table 2, confirm our intuition,
9 10

that the translation "custody" is more likely in documents related to crime.
p(e|f, F1 ) p(e|f, F2 ) e = restrict 0.33 0.02 e = restrain 0.10 0.00 e = custody 0.57 0.98

Table 2: Shows the translation probabilities for the source word f = , within document F1 (military related, class is "foreign policy") and document F2 (terror related, class is not "foreign policy").

5 Conclusions
In contrast, to most previous work, we focused on the word translation problem, rather than the domain-adaptation problem for cross-lingual text classification. We have proposed a probabilistic model that allows us to estimate word-translation probabilities that are conditioned on the whole source document. Our experiments on three different pairs of corpora, show that our estimated translation probabilities can improve text classification accuracy, and that our estimated word translation probabilities are able to reflect the topic of a text.

References
Chih-Chung Chang and Chih-Jen Lin. 2011. LIBSVM: A library for support vector machines. ACM Transactions on Intelligent Systems and Technology, 2:27:1­ 27:27. Software available at http://www.csie. ntu.edu.tw/cjlin/libsvm. Ronan Collobert, Jason Weston, L´ eon Bottou, Michael Karlen, Koray Kavukcuoglu, and Pavel Kuksa. 2011. Natural language processing (almost) from scratch. The Journal of Machine Learning Research, 12:2493­ 2537. Arthur P Dempster, Nan M Laird, Donald B Rubin, et al. 1977. Maximum likelihood from incomplete data via the em algorithm. Journal of the Royal statistical Society, 39(1):1­38. Jagadeesh Jagarlamudi and Jianfeng Gao. 2013. Modeling click-through based word-pairs for web search. In Proceedings of the ACM SIGIR Conference, pages 483­492. ACM. P. Koehn and K. Knight. 2000. Estimating word translation probabilities from unrelated monolingual corpora using the em algorithm. In Proceedings of the National Conference on Artificial Intelligence, pages 711­715. Association for the Advancement of Artificial Intelligence.

That is the point where precision and recall are equal. These results were acquired using cross-validation.

1470

