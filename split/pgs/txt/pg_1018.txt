So similar and yet incompatible: Toward automated identification of semantically compatible words
Germ´ an Kruszewski and Marco Baroni Center for Mind/Brain Sciences (University of Trento, Italy) (german.kruszewski|marco.baroni)@unitn.it

Abstract
We introduce the challenge of detecting semantically compatible words, that is, words that can potentially refer to the same thing (cat and hindrance are compatible, cat and dog are not), arguing for its central role in many semantic tasks. We present a publicly available data-set of human compatibility ratings, and a neural-network model that takes distributional embeddings of words as input and learns alternative embeddings that perform the compatibility detection task quite well.

edness, namely compatibility, that we define, for our current purposes, as follows: Linguistic expressions w1 and w2 are compatible iff, in a reasonably normal state of affairs, they can both truthfully refer to the same thing. If they cannot, then they are incompatible. We realize that the notion of a "reasonably normal sate of affairs" is dangerously vague, but we want to exclude science-fiction scenarios in which dogs mutate into cats. And we use thing as a catchall term for anything words (or other linguistic expressions) can refer to (entities, events, collections, etc.). The notions of compatibility and incompatibility have been introduced in theoretical semantics before (Cruse, 1986; Murphy, 2010). The definition that we give here for compatibility is related, but different from the one by Cruse. For example, subsuming pairs are out of the scope of compatibility under his definition, whereas we include them. Murphy defines incompatibility similarly to us, but she does not define compatibility. We are not aware, on the other hand, of any earlier systematic attempt to study the phenomenon empirically, nor to model it computationally. In general, compatible terms will be semantically related (dog and animal). However, relatedness does not suffice: many semantically related, even very similar terms are not compatible (dog and cat). Relatedness is not even a necessary condition: A husband can be a hindrance in an all-too-normal state of affairs, but the concepts of husband and hindrance are not semantically close. Moreover, compatibility does not reduce to (a set of) more commonly studied semantic relations. While it relates to hy-

1

Introduction

Vectors encoding distributional information extracted from large text corpora provide very effective estimates of semantic similarity or, more generally, relatedness between words (Clark, 2015; Erk, 2012; Turney and Pantel, 2010). Semantic relatedness is undoubtedly a core property of word understanding, and indeed current vector-based distributional semantic models (DSMs) provide an impressive approximation to human judgments in many tasks (Baroni et al., 2014). However, relatedness alone is too general a notion to truly capture the nuances of human conceptual knowledge. The terms animal, puppy, and cat are all closely related to dog, but the nature of their relation is very different, each affording different inferences: If you tell me that Fido is a dog, I will also conclude that he's an animal, that he is not a cat, and that he might or might not be a puppy. The previous examples hint at a fundamental semantic property that is only partially linked to relat964

Human Language Technologies: The 2015 Annual Conference of the North American Chapter of the ACL, pages 964­969, Denver, Colorado, May 31 ­ June 5, 2015. c 2015 Association for Computational Linguistics

