(LDA) model on Spanish and French morphological tagging and find them to yield similar performance.1 Neural networks have been used by Collobert and Weston (2008) to train embeddings for POS tagging as well as other NLP tasks. These embeddings ­ henceforth CW embeddings ­ are trained by building a neural network that given contexts of a word as input is trained to discriminate between the correct center word and a random word. The proposed training algorithm is reported to need several days or even weeks, but has been reimplemented by Al-Rfou et al. (2013), who induced embeddings for the Wikipedias of more than 100 languages. Turian et al. (2010) find that the performance of Brown clusters is competitive with more training intensive embeddings like CW. In our experiments, we find that MarLiN clusters slightly outperform CW. We do not evaluate bag-of-words models such as WORD 2 VEC (Mikolov et al., 2013), because the ordering of words is essential for finding morphological properties. Accumulated tag counts (ACT) are a form of taskspecific sparse representation. The unlabeled corpus is first annotated by a tagger; for each occurring word form, the number of times a specific tag was assigned can then be used as a representation. Goldberg and Elhadad (2013) and (Sz´ ant´ o and Farkas, 2014) show that using such information in the wordpreterminal emission probabilities of PCFGs can improve parsing accuracy. Specifically, Sz´ ant´ o and Farkas (2014) show that this approach performs as well as an MA in some cases. We find MAs to be more effective than the accumulated count embeddings; this is not a contradiction as we try to improve the performance of the tagger itself.

they represent different families: Germanic (English, German), Romance (Latin, Spanish), Slavic (Czech) and Finno-Ugric (Hungarian) and different degrees of morphological complexity and syncretism. For example, English and Spanish rarely mark case while the other languages do; and as an agglutinative language, Hungarian features a low number of possible readings for a word form while languages like German can have more than 40 different readings for a word form. An additional criterion was to have a sufficient amount of labeled OOD data. The data sets also feature an interesting selection of domain differences. For example, for Latin we have texts from different epochs while the English data contains canonical and non-canonical text. Labeled Data. This section describes the annotation and conversion we performed to create consistent ID and OOD data sets.2 No conversion was required for Hungarian, English and Latin as the data is already annotated in a consistent way. For Hungarian we use the (multi-domain) Szeged Dependency Treebank (Vincze et al., 2010). We use the part that was used in the SPMRL 2013 shared task (Seddah et al., 2013) as ID data (news-wire) and an excerpt from the novel 1984 and a Windows 2000 manual as OOD data. For Latin we use the PROIEL treebank (Haug and Jøhndal, 2008). It consists of data from the Vulgate (bible text,  380 AD), Commentarii de Bello Gallico ( 50 BC), Letters from Cicero to his friend Atticus ( 50 BC) and The Pilgrimage of Aetheria ( 380 AD). We use the biggest text source (Vulgate) as ID data and the remainder as OOD data. For English we use the SANCL shared task data (Petrov and McDonald, 2012), which consists of Ontonotes 4.0 as ID data and five OOD domains from the Google Web treebank: Yahoo! Answers, weblogs, news groups, business reviews and emails. For Czech we use the part of the Prague Dependency Treebank (PDT) (B¨ ohmov´ a et al., 2003) that was used in the CoNLL 2009 shared tasks (Haji c et al., 2009) as ID data. We use the Czech part of the Multext East (MTE) corpus (Erjavec, 2010) as OOD data. MTE consists of translations of the
Table 5 of the appendix provides a structured overview over the domains and resources used for each language. The appendix can be found at http://cistern.cis.lmu.de/ marmot/naacl2015/appendix.pdf.
2

4

Data Preparation

Our test suite consists of data sets for six different languages: Czech (cs), English (en), German (de), Hungarian (hu), Spanish (es) and Latin (la). Czech, German, Hungarian and Latin are morphologically rich. We chose these languages because
The authors claim that LDA Gibbs sampling is faster than the induction of Brown clusters because it only depends linearly on the number of clusters. We, however, could not train their models on our bigger data sets as the sampling depends linearly on the number of tokens.
1

529

