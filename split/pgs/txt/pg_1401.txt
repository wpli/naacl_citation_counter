is less than the threshold, implying a significant relevance between the words constituting the pair, we store the words. We then add the stored words to the source utterance, avoiding duplicates with words already in the source utterance, until its length is the same as that of the target utterance. Words are added in a reversed order of their appearance, i.e., we give priority to words that appeared in the later part of the discourse, in light of the previously mentioned assumption. If, after adding all stored words to the source utterance, the length of the source utterance is still less than the length of the target utterance, we repeat the process with word pairs between Sn-1 and Sn-2 , and so forth. This "crawling-up" is necessary because Sn is often short or semantically trivial that further comparison of Sn with other previous utterances fails to capture the contextually important words that are continuously discussed in the previous part of the conversation. The procedure ends when there are no more pairs whose p-value is less than the threshold, or the source utterance has the same length as the target utterance. Note that, for training, we limit the application of our model only to the cases where source utterances are shorter than target utterances, since adding words in the opposite case will exacerbate the difficulty of alignment. In the test setting, however, we do not know the length of the actual target utterance, and thus selectively apply our model based on the absolute length of the source utterance, where the threshold is set to the average length of the source utterance throughout the training data. Also, since it is evident that we are not dealing with grammatically well-formed utterances whose ordering should matter, we opt not to use the reordering table (Bisazza et al., 2011). 3.3 Token-Based Model The assumption behind the pair-based approach is that a topic of a conversation is something that continues to be discussed throughout the conversation, i.e. something that gets reflected/matched in the later part of the conversation. Finding collocated words using significant test does just that. However, there may be a trade-off here in terms of representing the diversity of context; for example, there may be a characteristic word that is not directly reflected/matched in the later part of the conversation. 1347

That provides the motivation for our token-based approach, using tf-idf. This approach follows a similar manner of adding words to the source utterance until its length is equal to the target utterance, but differs in that it picks contextually important words by examining individual tokens, rather than pairs of words, using tf-idf. For idf, the total number of documents was set to the number of conversations in our training data. Also, instead of crawling up the conversation from the source utterance, it scans through the entire conversation and selects characteristic words within the given scope of the conversation. This is intended to reflect that there could be words that are highly relevant to the overall topic of the conversation, yet not very close to the current source utterance. For example, in the following conversation, both (S3 ) and (S4 ) lack any element characteristic of the conversation that leads to the final response (S5 ), while "NBA" or "fans" in (S1 ) and (S2 ) is indicative of the topic of the conversation, and will be relevant to words like "LeBron" or "dominating" in the target utterance. A: Well, the NBA season is near again.(S1 ) B: Yeah! So excited for all the NBA fans!(S2 ) A: I'm not. (S3 ) B (source) : How come? (S4 ) A (target) : It's just gonna be LeBron dominating again. (S5 ) Although we examine the entire conversation, words that are too far from the source utterance (for example, 50 utterances apart) will rarely have much semantic impact to the current topic. Thus, it is necessary to keep the size of the conversation reasonably small, and we restrict it to be at most 8 utterances.

4
4.1

Experiment
Setting

We first built our baseline model following the procedure proposed by Ritter et al. (2011). In accordance with the paper, we also filtered out the phrase table by Fisher's Exact Test. We then implemented our model using Moses (Koehn et al., 2007) toolkit with KenLM (Heafield, 2011) as the language model in 5-gram setting. In accordance with the baseline, we built our training, tuning, and test data set from

