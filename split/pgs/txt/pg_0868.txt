Table 4: Extrating the polarity score given polarity information of a mention-pair (u, v ). To be brief, we use the shorthand notation pv predv and pu predu . 1{·} is an indicator function. spol (u, v ) is a binary vector of size three. therefore, etc.) if there are any. To avoid sparsity, we only keep the mention roles (only subj or obj; no exact strings are kept). Two triple-pairs are considered different if they have different predicates, different roles, different coreferred argument-pairs, or different discourse connectives. The co-occurrence counts extracted in this form correspond to Type 2 schemas in Table 2. During inference, we match (2) a Type 2 schema for Sgiga (u, v )  S (predu (m = u, a = au )|predv (m = u, a = av ), cn). Our method is related, but different from the proposal in Balasubramanian et al. (2012), who suggested to extract triples using an OpenIE system (Mausam et al., 2012). We extracted triples by starting from a mention, then extract the predicate and the other argument. An OpenIE system does not easily provide this ability. Our Gigaword counts are gathered also in a way similar to what has been proposed in Chambers and Jurafsky (2009), but we gather much larger amounts of data. 4.2 Wikipedia Disambiguated Co-occurence Given the co-occurrence information, we get a score vector Swiki (u, v ) corresponding to Type 1 Predicate Schemas, and hence S (u, v )wiki  S (predv (m = u, a = av )). 4.3 Web Search Query Count

  1{Po(pu ) = + AND Po(pv ) = +} OR 1{Po(pu ) = - AND Po(pv ) = -}  1{Po(pu ) = + AND Po(pv ) = +} spol (u, v ) =  1{Po(pu ) = - AND Po(pv ) = -}

Our third source of score vectors is web queries that we implement using Google queries. We extract a score vector Sweb (u, v )  S (predv (m = u, a = av )) (Type 1 Predicate Schemas) by querying for 1) "u av " 2) "u predv " 3) "u predv av " 4) "av u"11 . For each variation of nouns (plural and singular) and verbs (different tenses) we create a different query and average the counts over all queries. Concatenating the counts (each is a separate dimension) would give us the score vector Sweb (u, v ). 4.4 Polarity of Context

One of the problems with blindly extracting triple counts is that we may miss important semantic information. To address this issue, we use the publicly avaiable Illinois Wikifier (Cheng and Roth, 2013; Ratinov et al., 2011), a system that disambiguates mentions by mapping them into correct Wikipedia pages, to process the Wikipedia data. We then extract from the Wikipedia text all entities, verbs and nouns, and gather co-occurrence statistics with these syntactic variations: 1) immediately after 2) immediately before 3) before 4) after. For each of these variations, we get the probability and count9 of a pair of words (e.g. probability10 /count for "bend" immediately following "limb") as separate dimensions of the score vector.
We use the log (.) of the counts here. Conditional probability of "limb" immediately following the given verb "bend".
10 9

Another rich source of information is the polarity of context, which has been previously used for Winograd schema problems (Rahman and Ng, 2012). Here we use a slightly modified version. The polarity scores are used for Type 1 Predicate Schemas and therefore we want to get Spol (u, v )  S (predv (m = u, a = av )). We first extract polarity values for Po(predu ) and Po(predv ) by repeating the following procedures for each of them: · We extract initial polarity information given the predicate (using the data provided by Wilson et al. (2005)). · If the role of the mention is object, we negate its polarity. · If there is a polarity-reversing discourse connective (such as "but") preceding the predicate, we reverse the polarity. · If there is a negative comparative adverb (such as "less", "lower") we reverse the polarity.
We query this only when av is an adjective and predv is a to-be verb.
11

814

