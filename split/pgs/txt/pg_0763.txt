puted based on the BLEU against professional translations. Each tick represent a single translation and depicts the BLEU score using two colors. The tick is black if its BLEU score is higher than the median and it is red otherwise. Good translators tend to produce consistently good translations and bad translators rarely produce good translations. 5.2 Evaluating Rankings

Ranking workers using a model In addition to ranking workers by comparing them against a gold standard, we also attempt to automatically predict their ranks with a model. We use the linear regression model to score each translation and rank workers by their model predicted performance. The model predicted performance of the worker w is: perf ormance(w) =
tTw

After we rank workers, we keep top-ranked workers and select the best translation only from their translations. For both ranking approaches, we vary the number of good workers that we retain. We report both rankings' correlation with the gold standard ranking. Since the top worker threshold is cov (x, y ; w) (x, y ; w) = (1) varied and since we change the value of k in first cov (x, x; w)cov (y, y ; w) k sentence ranking, we have a different test set in different settings. Each test set excludes any items where cov is weighted covariance: which were used to rank the workers, or which did wi (xi - m(x; w))(yi - m(y ; w)) not have any translations from the top workers accov (x, y ; w) = i cording to our rankings. i wi (2) 5.4.1 Gold standard and Baseline and m is weighted mean: We evaluate ranking quality using the weighted wi x i Pearson correlation () compared with the gold stanm(x; w) = i (3) dard ranking of workers. To establish the gold stanw i i dard ranking, we score each Turker based on the 5.3 Automatically Ranking Translators BLEU score comparing all of his or her translations We introduce two approaches to rank workers using to the corresponding professional references. We use the ranking by the MERT model devela small portion of the work that they submitted. The oped by Zaidan and Callison-Burch (2011) as basestrategy is to filter out bad workers, and to select the best translation from translations provided by the re- line. It achieves a correlation of 0.73 against the gold maining workers. We propose two different ranking standard ranking. methods: 5.4.2 Ranking workers using their first k translations Ranking workers using their first k translations Without using any model, we rank workers using We rank the Turkers using their first few translations by comparing their translations against the pro- their first k translations. We select best translation fessional translations of those sentences. Ranking of each source sentence from the top ranked worker workers on gold standard data would allow us to dis- who translated that sentence. Table 2 shows the results of Pearson correlations card bad workers. This is similar to the idea of a for different value of k . As k increases, our rankings qualification test in MTurk. 709

We use weighted Pearson correlation (Pozzi et al., 2012) to evaluate our ranking of workers against gold standard ranking. Since workers translated different number of sentences, it is more important to rank the workers who translated more sentences correctly. Taking the importance of workers into consideration, we set a weight to each worker using the number of translations he or she submitted when calculating the correlation. Given two lists of worker scores x and y and the weight vector w, the weighted Pearson correlation  can be calculated as:

score(t) |Tw |

(4)

where Tw is the set of translations completed by the worker w and score(t) is the model predicted score for translation t. 5.4 Experiments

