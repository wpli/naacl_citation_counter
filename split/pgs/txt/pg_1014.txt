Figure 5: Colloc3-Syll based grammars scores on the CSJ dataset, comparing results without prosodic annotation, with those obtained by automatic prosodic boundaries that maximize precision, added at different levels in the grammar.

6

Discussion and Conclusions

We have investigated the use of prosodic boundary information for unsupervised word discovery in a multilingual setting. We showed that prosodic boundaries can improve word segmentation across both languages even when automatically determined boundaries are used. We also illustrated that the way in which to integrate prosody into word segmentation is not homogeneous across corpora, both in terms of the level of collocation where these boundaries are introduced, and in terms of the balance between precision and recall, when it comes to using automatic boundaries. For the first issue, the results on BU suggest that W ord or Colloc1 would be the best level, those on LUCID show that either Colloc2 or Colloc3 would give the best performance, while the scores on CSJ favors Colloc1 or Colloc2. But, if we were to discard the results on BU, due to its heavy oversegmentation and its small size, and use the collocation level giving the most balanced scores on the other two datasets, it appears that Colloc2 would be the common denominator. Besides giving the most balanced token scores it also gives the most balanced boundary scores, striking a good compromise between the under-segmentation produced by adding the prosody at lower levels and the oversegmentation tendency for boundaries introduced at

higher levels. To investigate the second issue, a closer look to the tables presenting the evaluation of the automatic boundaries (Table 1 and Table 2) is needed. The best word segmentation scores on BU were obtained for the maxF score system, but we can observe that the condition also has a high precision (.705). At the same time, the best score on CSJ was obtained for the maxP recision system, the maxF score system (with a precision of .533) giving no improvement over the baseline (see Figure 2). Furthermore, maxRecall, which has very low precisions, seems to behave similar to, or below the baseline, for both datasets. Thus, it appears that a relatively high precision for the prosodic boundaries is needed to obtain improvements in word segmentation and, once this condition is fulfilled, any increase in recall would increase the gain over the baseline. Further evidence supporting this can be found when performing a word-based evaluation of the automatic prosodic boundaries obtained. For the BU and CSJ corpora, we computed the percentage of word boundaries found, out of the total word boundaries in the corpora, and the proportion of incorrect word boundaries from the total number of boundaries found (see Table 3). It shows that the systems that bring improvements over the baseline (maxF score and maxP recision for BU, and maxP recision for CSJ) have a relatively low rate of false alarms (lower than 6%). At the same time, the increase in performance can be obtained even without a high coverage of the corpus, the maxP recision models achieving this with a coverage lower than 10%. Since all the resuls reported in this paper were obtained using the state-of-the-art Adaptor Grammar model, Colloc3 - Syll, we also verified that our results are generalizable across different models. We created several AG models, by varying the following settings in the grammar: using either one or three collocation levels, and having knowledge or not of the syllabic structure. This gave us, besides the already tested Colloc3 - Syll model, three new models: Colloc3 - noSyll, Colloc - Syll and Colloc - noSyll, which were all tested on the CSJ. When evaluating the token F-score obtained using these models, we can see improvements for all the models, regardless of the nature of the prosodic

960

