vector, and   R is a learning factor. We try three different values for  , which lead to the following learning algorithms: · Perceptron:  = 1 · MIRA:  = max 0, · Forced-MIRA:  =
^) 1-w·(u-v ^ ||2 ||u-v

gap distance. Formally: Sim(R, C ) =
(a,b)su(R)su(C ) 2 distR (a,b)+distC (a,b) 1 distR (a,b)

(a,b)su(R)

^) 1-w·(u-v ^ ||2 ||u-v

Where function distH (a, b) returns the skip distance between tokens "a" and "b" in headline H , and su(H ) returns all skip-bigrams in headline H . With the objective of having a metric capable of detecting abstract concepts in phrases and comparing headlines at a semantic level, we resort to Latent Semantic Indexing (LSI) (Deerwester et al., 1990). We use the method for extracting latent concepts from our training corpus so as to be able to represent text in an abstract latent space. We then compute the similarity of a headline with respect to a news article by calculating the cosine similarity of their vector representations in latent space. 7.2 Baselines In order to have a point of reference for interpreting the performance of our model, we implement four baseline models. We arbitrarily decide to make all the baselines generate, if possible, nine-token-long headlines, where the last token must always be a period. This follows from the observation that good headlines must contain about eight tokens (Banko et al., 2000). The implemented baselines are the following: Chunked first sentence: the first eight tokens from the article, plus a period at the end. Hidden Markov Model: as proposed by Zajic et al. (2002), but adapted for producing eight-token sentences, plus an ending period. Word Graphs: as proposed by Filippova (2010). This is a state-of-the-art multi-sentence compression algorithm. To ensure it produces headlines as output, we keep the shortest path in the graph with length equal to or greater than eight tokens. An ending period is appended if not already present. Note that the original algorithm would produce the topk shortest paths and keep the one with best average edge weight, not caring about its length. Keywords: the top eight keywords in the article, as ranked by TF-IDF weighting, sorted in descending order of relevance. This is not a real baseline

The first value is a simple averaged perceptron as presented by Collins (2002), the second value is a Margin Infused Relaxed Algorithm (MIRA) as presented by Crammer and Singer (2003), and the third value is a slight variation to the MIRA update. We propose it for making the algorithm acknowledge that the objective feature vector u cannot be produced from document x, and thus force an update at every step. The reason for this is that if w · u > ^ , then MIRA sets  = 0, because an error was w·v not made (i.e. the human-generated headline got a higher score than all of the others). Nevertheless, we observed in our experiments that this behaviour biases the process towards learning weights that exploit patterns that can occur in human-generated titles, but are almost never observed in the titles that can be generated by our model, which hinders the quality of the final headlines.

7
7.1

Automatic evaluation set-up
Evaluation metrics

For performing an automatic evaluation of the headlines generated by our system we follow the path taken by related work such as Zajic et al. (2004) and use a subset of the ROUGE metrics for comparing candidate headlines with reference ones, which have been proven to strongly correlate with human evaluations (Lin, 2003; Lin, 2004). We decide to use as metrics ROUGE-1, ROUGE2, and ROUGE-SU. We also propose as an experimental new metric a weighted version of ROUGESU, which we name ROUGE-WSU. The rationale of our proposal is that ROUGE-SU gives the same importance to all skip-bigrams extracted from a phrase no matter how far apart they are. We address the problem by weighting each shared skip-gram between phrases by the inverse of the token's average 138

