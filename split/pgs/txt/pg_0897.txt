terpreting the semantic structure of a sentence. Supervised semantic parsing requires a target logical form for each sentence, which is costly (Zettlemoyer et. al, 2012). Unsupervised methods rely on accurate dependency parsing, and the semantics learned with unsupervised methods are not directly grounded in a domain (Poon et al., 2009). Our approach does not require a logical form or accurate parse in order to train the model. Another aspect of semantic interpretation involves language grounding, which links natural language to representations of entities in the (often physical) world directly. Matuszek et al. (2012) propose a joint language/perception model to learn attribute names in a physical environment. Barnard et al. (2003) learn interpretation of segments of images in words with a number of models. Liu et al. (2014) label the referential entities in a collaborative discourse with graph mapping. All of these approaches work in scenarios in which the number of entities is limited. This is different from the case of a complex problem-solving domain in which there could be infinitely many combinations of entities and surface forms of the problem-solving artifact. Thus, building an entity graph to model the relationships between entities would be intractable. Grounding based on semantic interpretation using our approach will address this problem since it first narrows down the category of entity for a noun phrase and then grounds within a family of factorized vectors. 2.2 Language Understanding in Tutorial Dialogue Systems

language understanding component that has been used in multiple dialogue systems (Zinn et al., 2000; Litman, 2004; VanLehn et al., 2002). CARMEL uses a semantic interpretation framework that performs semantic interpretation with semantic constructor functions during syntactic parsing. The semantic interpretation employs encoded domain-specific semantic knowledge and a frame-based representation. Dzikovska et al. (2007) proposed an approach that divides the logical form representation of utterances and the knowledge representation ontology in order to make a NLU component adaptable for multiple domains. The logical form representation contains high-level word sense and semantic role labels. Then, a contextual interpreter is employed for mapping between the logical form and the domain ontology. This work still relies on an open domain parser to generate the logical forms. Different from all of the approaches mentioned above, AutoTutor (Graesser et al., 2004) uses latent semantic analysis (LSA) to evaluate students' utterances by comparing them to a handcrafted expected answer. LSA represents semantics as a high-dimensional vector and computes similarity between pieces of text. As a bag-of-words approach, LSA does not capture the kind of semantic structure that facilitates specific language grounding in an environment.

3 Corpus of Complex Problem Solving Dialogue
Complex problem solving is defined within the psychology literature as the process of reaching a goal state by applying multiple problem solving skills, when the desired goal state cannot simply be reached by applying one from a set of existing solution patterns (Greiff et al., 2013; Mayer et al., 2006; Funke, 2010). Dialogue surrounding complex problem solving is therefore grounded within a problem-solving artifact that could have infinitely many surface forms. The complex problemsolving domain that is the focus of this paper is computer programming, specifically Java programming, and the corpus under consideration reflects textual tutorial dialogue exchanged between two humans in support of that problem solving.

All dialogue systems employ some form of semantic interpretation. Within tutorial dialogue, some dialogue interpretation relies on a manually defined domain-specific grammar and lexicon (Lemon et al., 2001, Evens et al., 2005). CIRCSIMTutor (Evens et al., 2005), a tutorial dialogue system in the domain of cardiovascular physiology, uses a set of finite state transducers and a domainspecific lexicon. Such domain-specific grammars are successful within well-formed domains but become unwieldy in larger or ill-defined domains. Another approach is to employ an open-domain parser in combination with domain-specific knowledge. CARMEL (Rosé, 2000) is a natural

843

