kens with their standard forms. In contrast, parsertargeted normalization must attend to both of the tasks, as well as the task of restoring dropped tokens. Despite the differences, there are a few common threads that appear in each evaluation. Most notably, the results suggest that the decision of most recent Twitter normalization work to focus on word replacement was not entirely without merit, as the high frequency of token replacements translated into high overall importance for all tasks. Similarly, the focus on slang was also somewhat reasonable, as failing to handle slang terms had a significant impact on parsing and speech synthesis, though it had little impact on entity recognition. Nonetheless, the results in Section 4 clearly suggest that handling these cases represent only a small fraction of the actions necessary to produce performance comparable to what would be seen on formal text. Another similarity among all instances was the lack of importance of certain categories. For instance, punctuation addition was not important for any of the three tasks. While Zhang et al. had hypothesized that punctuation addition would be important for dependency parsing, the results given here suggest that the overall impact is minor. Similarly, contraction standardization was not shown to be important in any of the evaluations. Contraction normalization is more representative of how the normalization task was seen prior to the rise of social media normalization, as it represents a fairly minor normalizing action that might still be performed on formal text. Since contractions likely appear in a variety of forms in the data used to train NLP tools, it is unsurprising that these tools are comparatively robust to contraction differences than to cases that are less typically encountered.

that recent work has suggested may have been unjustly ignored. To understand the effects of each edit, we conducted ablation studies that examined results on three different downstream tasks: dependency parsing, named entity recognition, and text-to-speech synthesis. We found that while some normalization edits were universally important (or unimportant) for the production of accurate results, many differences persist. These results suggest that, for best results, how the normalization task is performed should not be agnostic of the downstream application. Further, our results support the suggestion that in order for downstream applications to produce accurate results, in most cases it is necessary to take a broad view of the normalization task the looks beyond simple word replacements.

Acknowledgments
The authors would like to thank Benny Kimelfeld for his comments on an early draft of this work. We also thank our anonymous reviewers for their constructive comments and feedback, and Stephanie Mcneish, Lacy Corlis, and Kaila Milos C. Factolerin for their assistance with annotation and evaluation.

References
AiTi Aw, Min Zhang, Juan Xiao, and Jian Su. 2006. A phrase-based statistical model for sms text normalization. In ACL, pages 33­40. Tyler Baldwin and Joyce Chai. 2011. Beyond normalization: Pragmatics of word form in text messages. In IJCNLP, pages 1437­1441, Chiang Mai, Thailand, November. Asian Federation of Natural Language Processing. Richard Beaufort, Sophie Roekhaut, Louise-Am´ elie Cougnon, and C´ edrick Fairon. 2010. A hybrid rule/model-based finite-state framework for normalizing sms messages. In ACL, pages 770­779. Alan W. Black and Keiichi Tokuda. 2005. The blizzard challenge - 2005: evaluating corpus-based speech synthesis on common datasets. In INTERSPEECH, pages 77­80. Monojit Choudhury, Rahul Saraf, Vijit Jain, Animesh Mukherjee, Sudeshna Sarkar, and Anupam Basu. 2007. Investigation and modeling of the structure of texting language. IJDAR, 10(3-4):157­174.

6

Conclusion

In this work, we presented an in-depth look at the effects of the normalization of Twitter data. To do so, we introduced a taxonomy of normalization edits based on an examination of our Twitter dataset and inspiration from previous work. The taxonomy allowed for normalization edits to be examined systematically at different levels of granularity, and enabled an examination of the effects of not only token replacements, but the token additions and removals 428

