tweets, which is estimated by an unsupervised topic model.3 We also consider two state-of-the-art rankers: RankBoost (Freund et al., 2003) and LambdaMART (Burges, 2010). Finally, we use a position baseline that ranks sentences based on their position in the article, and a rating baseline that ranks comments based on positive user ratings. We evaluate using normalized discounted cumulative gain at top 3 returned results (NDCG@3). Sentences are considered relevant if they have ROUGE-2 scores larger than 0.0 (computed against human abstracts), and comments are considered relevant if they are editor's picks.4 Figure 3 demonstrates that our joint learning model uniformly outperforms all the other comparisons for both ranking tasks. In general, supervised learning based approaches (e.g. our method, Yang et al. (2011), RankBoost, and LambdaMART) produce better results than unsupervised method (e.g. Gao et al. (2012)).5

Figure 3: Evaluation of sentence and comment ranking
on the four datasets by using normalized discounted cumulative gain at top 3 returned results (NDCG@3). Our joint learning based approach uniformly outperforms all the other comparisons.

5.2

Leveraging User Comments

In this section, we test if our system can leverage comments to produce better article-based summaries for event timelines. We collect gold-standard timelines for each of the four events from the corresponding Wikipedia page(s), NYT topic page, or BBC news page. We consider two existing timeline creation systems that only utilize news articles, and a timeline generated from single-article human abstracts: (1) C HIEU AND L EE (2004) select sentences with high
We thank Zi Yang and Peng Li for providing the code. We experiment with all articles for sentence ranking, and NYT comments (with editor's picks) for comment ranking. 5 Similar results are obtained with mean reciprocal rank.
4 3

"interestingness" and "burstiness" using a likelihood ratio test to compare word distributions of sentences with articles in neighboring days. (2) YAN ET AL . (2011) design an evolutionary summarization system that selects sentences based on on coverage, coherence, and diversity. (3) We construct a timeline from the human A BSTRACTs provided with each article: we sort them chronologically according to article timestamps and add abstract sentences into each daily summary until reaching the word limit. We test on five variations of our system. The first two systems generate article summaries with no comment information by optimizing Squal (S ; T ) using a greedy algorithm: BASIC ignores event threading; T HREAD considers the threads. T HREAD +O PTTFIDF , T HREAD +O PTWordNet and T HREAD +O PTWordVec (see Section 4.3) leverage user comments to generate article summaries as well as comment summaries based on alternating optimization of Equation 3. Although comment summaries are generated, they are not used in the evaluation. For all systems, we generate daily article summaries of at most 100 words, and select 5 comments for the corresponding comment summary. We employ ROUGE (Lin and Hovy, 2003) to automatically evaluate the content coverage (in terms of ngrams) of the article-based timelines vs. goldstandard timelines. ROUGE-2 (measures bigram overlap) and ROUGE-SU4 (measures unigram and skip-bigrams separated by up to four words) scores are reported in Table 4. As can be seen, under the alternating optimization framework, our systems, employing both articles and comments, consistently yield better ROUGE scores than the three baseline systems and our systems that do not leverage comments. Though constructed from single-article abstracts, baseline A BSTRACT is found to contain redundant information and thus limited in content coverage. This is due to the fact that different media tend to report on the same important events. 5.3 Evaluating Socially-Informed Timelines We evaluate the full article+comment-based timelines on Amazon Mechanical Turk. Turkers are presented with a timeline consisting of five consecutive days' article summaries and four variations of the accompanying comment summary:

1061

