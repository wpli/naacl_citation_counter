subject to their weights . We add a constraint corresponding to the compression rate, i.e., the number of scenes to be selected and enforce their linear order by disallowing non-consecutive combinations. We use GLPK6 to solve the linear problem.

clubs her over the head contains the relation clubs(MAN,CATHERINE). Pronouns are resolved to their antecedent using the Stanford coreference resolution system (Lee et al., 2011). Sentiment We labeled lexical items in screenplays with sentiment values using the AFINN-96 lexicon (Nielsen, 2011), which is essentially a list of words scored with sentiment strength within the range [-5, +5]. The list also contains obscene words (which are often used in movies) and some Internet slang. By summing over the sentiment scores of individual words, we can work out the sentiment of an interaction between two characters, the sentiment of a scene (see Equation (17)), and even the sentiment between characters (e.g., who likes or dislikes whom in the movie in general). Main Characters The progress term in our summarization objective crucially relies on characters and their importance (see the weight wc,s in Equation (4)). Previous work (Weng et al., 2009; Lin et al., 2013) extracts social networks where nodes correspond to roles in the movie, and edges to their co-occurrence. Leading roles (and their communities) are then identified by measuring their centrality in the network (i.e., number of edges terminating in a given node). It is relatively straightforward to obtain a social network from a screenplay. Formally, for each movie we define a weighted and undirected graph: G = {C, E }, : C = {c1 , . . . cn }, E = {(ci , c j , w)|ci , c j  C, w  N>0 } where vertices correspond to movie characters7 , and edges denote character-to-character interactions. Figure 5 shows an example of a social network for "The Silence of the Lambs". Due to lack of space, only main characters are displayed, however the actual graph contains all characters (42 in this case). Importantly, edge weights are not normalized, but directly reflect the strength of association between different characters. We do not solely rely on the social network to identify main characters. We estimate P(c  main(M )), the probability of c being a leading character in movie M , using a Multi Layer
7 We

5

Implementation

In this section we discuss several aspects of the implementation of the model presented in the previous section. We explain how interactions are extracted and how sentiment is calculated. We also present our method for identifying main characters and estimating the weights ws,c and wc,s in the bipartite graph. Interactions The notion of interaction underlies many aspects of the model defined in the previous section. For instance, interaction counts are required to estimate the weights ws,c in the bipartite graph of the progression term (see Equation (5)), and in defining diversity (see Equations (15)­(17)). As we shall see below, interactions are also important for identifying main characters in a screenplay. We use the term interaction to refer to conversations between two characters, as well as their relations (e.g., if a character kills another). For conversational interactions, we simply need to identify the speaker generating an utterance and the listener. Speaker attribution comes for free in our case, as speakers are clearly marked in the text (see Figure 1). Listener identification is more involved, especially when there are multiple characters in a scene. We rely on a few simple heuristics. We assume that the previous speaker in the same scene, who is different from the current speaker, is the listener. If there is no previous speaker, we assume that the listener is the closest character mentioned in the speaker's utterance (e.g., via a coreferring proper name or a pronoun). In cases where we cannot find a suitable listener, we assume the current speaker is the listener. We obtain character relations from the output of a semantic role labeler. Relations are denoted by verbs whose ARG0 and ARG1 roles are character names. We extract relations from the dialogue but also from scene descriptions. For example, in Figure 1 the description Suddenly, [...] he
6 https://www.gnu.org/software/glpk/

assume one node per speaking role in the script.

1071

