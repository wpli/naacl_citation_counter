to enforce posterior agreement between the two models. Specifically, they add a KL-projection step after the E-step of the EM algorithm which returns the posterior q(z | x) closest in KL-Divergence to an E-step posterior, but which also upholds certain constraints. The particular constraints they suggest encode alignment agreement in expectation between the two models' posteriors. For details, the reader can refer to (Ganchev et al., 2008). Similarly to ABA, with their suggested alignment agreement constraints PostCAT cannot be applied without parallel data and it is unclear how to extend it to fertility based models (however, it does seems possible to apply other constraints using the general posterior regularization framework). We compare MIR against ABA and PostCAT in Section 5. 4.2 Non-Parallel Data Baseline: bi-EM Mylonakis et al. (2007) cast the two directional models as a single joint model by reparameterization and normalization. That is, both directional models, consisting of a t-table only, are reparameterized as: t1 ( f | e ) = e , f f e , f t2 (e | f ) = e , f e e , f (6)

hinting that a closed-form solution for the maximizer is unlikely. The probability estimate that they use in the M-step appears to maximize an approximation of their M-step objective which omits the normalization factors in Eq. 7. Nevertheless, bi-EM attains improved results compared to standard EM on both POS-tagging and monotone noun sequence translation without parallel data. We compare MIR against bi-EM in Sec. 6.

5

Experiments with Parallel Data

In this section, we compare MIR against standard EM training and ABA on Czech-English and Chinese-English word alignment and translation. 5.1 Implementation and Code For ABA2 and PostCAT3 training we used the authors' implementation, which supports the HMM model. Vanilla EM training was done using GIZA++,4 which supports all IBM models as well as HMM. Our method MIR was implemented on top of GIZA++.5 5.2 Data We used the following parallel data to train the word alignment models: Chinese-English: 287K sentence pairs from the NIST 2009 Open MT Evaluation constrained task consisting of 5.3M and 6.6M tokens, respectively. Czech-English: 85K sentence pairs from the News Commentary corpus, consisting of 1.6M and 1.8M tokens, respectively. Sentence length was restricted to at most 40 tokens. 5.3 Word Alignment Experiments

They then maximize the likelihood of observed monolingual sequences from both languages: max L1 ({f n }; ) + L2 ({en }; )


(7)

where, for example: L1 ({f n }; ) = log
n

p(f n ) p(f n | e) p(e)
n e

= log = log
n e

p(e)
m

n t1 ( fm

| e)

Here, p(e) denotes the probability of e according to a fixed source language model. Once training of  is complete, we can decode an observed target sequence f , by casting  back in terms of t1 and apply the Viterbi decoding algorithm. To solve for  in Eq. 7, Mylonakis et al. (2007) propose bi-EM, an iterative EM-style algorithm. The objective function in their M-step is not concave, 613

We obtained HMM alignments by running either 5 or 10 iterations (optimized on a held-out validation set) of both IBM Model 1 and HMM. We obtained IBM Model 4 alignments by continuing with 5 iterations of IBM Model 3 and 10 iterations of IBM
http://cs.stanford.edu/~pliang/software/ cross-em-aligner-1.3.zip 3 http://www.seas.upenn.edu/~strctlrn/CAT/CAT. html 4 http://code.google.com/p/giza-pp/ 5 https://github.com/vaswani/MIR_ALIGNMENT
2

