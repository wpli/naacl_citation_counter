dience that can be assumed by the writer of a tweet is the non-linguistic content of the event being hashtagged. We begin by describing our corpus and our method of calculating linguistic content (by computing entropy within a simple n-gram model). We then investigate gradual changes in word-by-word information content as the event goes on (testing adaptation driven by contextual mutual information in Equation 2, replicating Genzel and Charniak 2002) and rapid changes in the total information content of tweets in response to important in-game events (testing adaptation driven by non-linguistic information in Equation 2). We end by considering control analyses that provide evidence against alternative accounts of our results.

Our tweet corpus was compiled from the "gardenhose" Twitter search API, which returns a subset of all relevant tweets. Our searches captured approximately 4% of all relevant tweets; Twitter reported 420,329 relevant tweets during Game 1 of the World Series3 , and our dataset contained 17,538 tweets during the same time period. We address potential confounds from this sampling process in Section 5.2. 2.2 Entropy Computation

2
2.1

Corpus and Methods
#Worldseries Corpus

Our current analysis looked at tweets during the 2014 World Series, a series of seven baseball games in late October 2014. We obtained these tweets by searching publicly-available tweets through the Twitter API, using an adaptation of SeeTweet (Doyle, 2014) to compile tweets containing the hashtag #WorldSeries. To synchronize tweets with game events, we used the Major League Baseball Advance Media XML repository,1 which contains pitch-by-pitch data including the ongoing state of the game and timestamps at the start of each atbat. Using this timestamp information, we binned tweets by at-bats so that they could be co-registered with other in-game statistics. These bins extend from the time of the first pitch in an at-bat to the beginning of the next at-bat, and thus provide time for reactions to the events of the at-bat.2 The mean atbat length was 2.76 minutes, and there were 512 total at-bats. We limited our analysis to tweets timestamped during one of these at-bats, resulting in a total corpus of 109,207 tweets. Each game had its first pitch at approximately 0008 UTC, and lasted between three and four hours.
http://gd2.mlb.com/components/game/mlb/ We tested a series of potential offset times in case Twitter and MLB used different clocks or at-bats were not long enough to capture reactions. We did not adjust the times as there was no significant increase in the correlation between Leverage Index (Sect. 5.1) and tweet rate for these offsets.
2 1

Estimating the linguistic information content of each tweet is a key task in this work. Social media text has been described as "bad language" (Eisenstein, 2013): It can be difficult to model due to its idiosyncratic abbreviations, typographic errors, and other non-standard forms. Relevant to our goal of assessing information content, it can also be difficult to create an appropriate training corpus for language models, since the vocabulary and composition of tweets of change rapidly (Eisenstein, 2013). We attempted to minimize these difficulties in two ways. First, we estimated language models with domain-specific corpora. In particular, for tweets from each game we used a training corpus consisting of the tweets from all the other games. This training set provided a vocabulary and structure that was similar in topic and style to the test set. We removed all punctuation and emoji except word-initial @ and #, which refer to users and hashtags, respectively. Usernames were replaced with [MENTION] to reduce sparsity; hashtags were not altered, as these often function as words or phrases within the tweet's syntax. Words with fewer than 5 occurrences in the training corpus were marked as outof-vocabulary items. We estimated trigram models using a modification of NLTK (Bird, 2006)4 with Witten-Bell smoothing, and estimated per-word and total entropy for each tweet from these models. Second, we included tweet length (in characters) as an alternative metric of information content (see Section 5.2). Unless information rate varies syshttp://Twitter.com/TwitterData/status/ 524972545930301440 4 Smoothing on n-gram models in NLTK can be inaccurate (see http://github.com/nltk/nltk/issues/367), so we used a modified version courtesy of B. C. Roy (personal communication).
3

1589

