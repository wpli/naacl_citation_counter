3

The IR Framework

Existing training methods for the unsupervised dependency task, such as Blunsom and Cohn (2010), Gillenwater et al. (2011), and Tu and Honavar (2012), are hypothesis-oriented search with the EM algorithm or its variants: training is to move from a point which represents a model hypothesis to another point. This approach is feasible for optimising models using simple features since existing dynamic programming algorithms can compute expectations, which are sums over all possible parses, or to find the best parse in the whole parse space with low complexities. However, the complexity increases rapidly if rich, complex features are used. One way to reduce the computational cost is to use approximation methods like sampling as in Blunsom and Cohn (2010). 3.1 Treebank-oriented Greedy Search Believing that the difficulty of using EM is from the fact that treebanks are `hidden', leading to the need of computing sum (or max) overall possible treebanks, we propose a greedy local search scheme based on another training philosophy: treebankoriented search. The key idea is to explicitly search for concrete treebanks which are used to train parsing models. This scheme thus allows supervised parsers to be trained in an unsupervised parsing setting since there is a (automatically annotated) treebank at any time. Given S a set of raw sentences, the search space consists of all possible treebanks D = {d(s)|s  S} where d(s) is a dependency tree of sentence s. The target of search is the optimal treebank D that is as good as human annotations. Greedy search with this philosophy is as follows: starting at an initial point D1 , we pick up a point D2 among its neighbours N(D1 ) such that D2 = arg max fD1 (D)
DN(D1 )

Semi-supervised parsing using reranking (McClosky et al., 2006). This reranking is indeed onestep greedy local search. In this scenario, N(D1 ) is the Cartesian product of k -best lists generated by a k -best parser, and fDi (D) is a reranker. Unsupervised parsing with hard-EM (Spitkovsky et al., 2010b) In hard-EM, the target is to maximise the following objective function with respect to a parameter set  L(S|) =
sS dDep(s)

max log P d

(2)

where Dep(s) is the set of all possible dependency structures of s. The two EM steps are thus · Step 1: Di+1 = arg maxD Pi (D) · Step 2: i+1 = arg max P (Di+1 ) In this case, N(Di ) is the whole treebank space and fDi (D) = Pi (D) = Parg max P (Di ) (D). 3.2 Iterated Reranking

(1)

where fD1 (D) is an objective function measuring the goodness of D (which may or may not be conditioned on D1 ). We then continue this search until some stop criterion is satisfied. The crucial factor here is to define N(Di ) and fDi (D). Below are two special cases of this scheme. 653

We instantiate the greedy search scheme by iterated reranking which requires two components: a k -best parser P , and a reranker R. Firstly, D1 is used to train these two components, resulting in P1 and R1 . The parser P1 then generates a set of lists of k candidates k D1 (whose Cartesian product results in N(D1 )) for the set of training sentences S . The best candidates, according to reranker R1 , are collected to form D2 for the next iteration. This process is halted when a pre-defined stop criterion is met.1 It is certain that we can, as in the work of Spitkovsky et al. (2010b) and many bootstrapping approaches, employ only parser P . Reranking, however, brings us two benefits. First, it allows us to employ very expressive models like the -order generative model proposed by Le and Zuidema (2014). Second, it embodies a similar idea to co-training (Blum and Mitchell, 1998): P and R play roles as two views of the data.
It is worth noting that, although N(Di ) has the size O(kn ) where n is the number of sentences, reranking only needs to process O(k × n) parses if these sentences are assumed to be independent.
1

